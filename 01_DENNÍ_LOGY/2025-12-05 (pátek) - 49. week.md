RIP Patrik Hezucky
---
---
WebovÃ¡ apka:
ğŸŒ™

# ğŸ“ŠDP-700: Microsoft Fabric Data Engineering

Professional Certification Mastery - Complete Learning Hub

â° Your Exam:Â **December 31, 2025**  
ğŸ“… 26 days to master DP-700

ğŸ“Š DashboardğŸ—ºï¸ Learning RoadmapğŸ“š Theoryâš¡ RTI Deep DiveğŸ’» LanguagesğŸ”§ Toolsâ“ Quiz Bank (200+)ğŸ› ï¸ Hands-On LabsğŸ“ˆ Progress

## ğŸ“š Core Theory: Domain 1 - Implement & Manage

### Fabric Architecture Hierarchy

Tenant (Organization) â”œâ”€ Fabric (1 per tenant) â”‚ â”œâ”€ Capacity (Compute Resources) â† MAIN COST DRIVER â”‚ â”œâ”€ Workspace (Logical Separation) â”‚ â”‚ â”œâ”€ Items (Pipelines, Notebooks, Lakehouses, etc.) â”‚ â”‚ â””â”€ Domains (Governance Layer) â”‚ â””â”€ OneLake (Unified Data Lake - 1 per Fabric)

**ğŸ”´ CRITICAL CONCEPT:**Â All data in Fabric = Delta Parquet internally. Whether you use Lakehouse (Spark), Warehouse (T-SQL), or Eventhouse (KQL), the underlying storage format is always Delta Parquet in OneLake.

### Security & Governance Model

|Level|Scope|Example|
|---|---|---|
|**Workspace Admin**|All items in workspace|Who manages pipelines, notebooks, etc.|
|**Item Level**|Specific Lakehouse, Warehouse, etc.|Read/Edit permissions on one Lakehouse|
|**Object Level (SQL)**|Table, View, Stored Procedure|T-SQL GRANT/DENY on specific tables|
|**Row/Column Security**|Specific rows or columns in data|Sales staff see only their region's data|

### Endorsement & Certification

- **Promoted:**Â Verified by creator - recommended for use
- **Certified:**Â Officially approved - high-trust seal
- **Sensitivity Labels:**Â GDPR/compliance tagging (Public, Internal, Confidential, Highly Restricted)

## ğŸ“š Domain 2 - Ingest & Transform Data

### Loading Patterns

1

Â **Full Load:**Â All data from scratch. When: Initial ingestion or when incremental tracking unavailable.

2

Â **Incremental Load:**Â Only new/changed data. Tracked via: Timestamp, Change Table, or Watermark (last processed ID).

3

Â **SCD Type 1:**Â Overwrite old records (no history kept).

4

Â **SCD Type 2:**Â Keep history (old records marked inactive, new records created with date ranges).

### Dimensional Modeling (Star Schema)

FACT TABLES (Metrics) â”œâ”€ OrderFact â”‚ â”œâ”€ OrderID (FK) â”‚ â”œâ”€ CustomerID (FK) â”‚ â”œâ”€ Quantity (metric) â”‚ â””â”€ Revenue (metric) DIMENSION TABLES (Descriptive) â”œâ”€ CustomerDim (ID, Name, City, Country) â”œâ”€ ProductDim (ID, ProductName, Category, Price) â””â”€ TimeDim (DateID, Year, Month, Quarter)

## ğŸ“š Domain 3 - Monitor & Optimize

### Monitoring Checklist

- Pipeline execution status (Success/Failure/In Progress)
- Eventstream latency (time from source to sink)
- Notebook job duration & resource usage
- Query performance (P95 latency, throughput)
- Semantic model refresh time

### Optimization Techniques

- **Partitioning:**Â Split large tables by date/region/category
- **Indexing (SQL):**Â Clustered on PK, non-clustered on FK
- **V-ORDER:**Â Delta optimization for query performance
- **VACUUM & OPTIMIZE:**Â Delta table maintenance
- **Caching:**Â Shortcut caching for external data