Learning from Will. 

# KQL Databáze
## Připojení ze zdrojů, které streamujeme v reálném čase:
	
	Například:
		- Jednorázově se souborem to můžeme udělat 999-krát
		- Z Azure Delta Lake storage (ADLs)
		- Z Amozonu: bucket
		- Přes OneLake
		- Z Event Hubů: webové aplikace, zařízení, senzory nebo jiné systémy
		- Přes Eventhouse
			- Rozdíly:
				- Event Hubs je vstupní bránou pro eventové datové proudy v Azure/Fabric.
				- Eventhouse je koncept nebo úložiště dat eventů, které využívá Event Hubs pro ingest.

---

## Rozdíl mezi view (pohledem) a materialized view:

	- View neukládá data, je vždy aktuální, ale může být výkonově pomalejší, protože dotaz se spouští při každém přístupu.
    
	- Materialized view ukládá výsledky dotazu fyzicky, což zlepšuje rychlost čtení, ale data mohou být zastaralá, pokud nejsou pravidelně aktualizována.
    
	- Materialized view vyžaduje úložný prostor, zatímco view funguje téměř bez nároku na disk.
    
	- Obnova materialized view může být provedena automaticky nebo manuálně v různých intervalech.

## Klíčové fungování aktualizace materializovaných pohledů ve Fabric:

	- Automatický refresh na základě závislostí mezi tabulkami a pohledy (lineage).
    - Možnost manuálního refresh příkazem REFRESH MATERIALIZED LAKE VIEW.
    - Podpora eventstreamu k vyvolání aktualizace při příchodu nových dat.
    - Orchestrace v pipelinech s možností API volání pro spouštění refresh.
    - Optimalizace refresh procesu na změněná data, ne celé datasetu.V Microsoft 


Fabric lze mít materializované pohledy (Materialized Lake Views, MLV) v KQL databázi, které jsou automaticky spravovány a aktualizovány systémem. Fabric sleduje závislosti mezi tabulkami a pohledy, takže pokud dojde k aktualizaci zdrojové tabulky (např. v Bronze vrstvě), automaticky se spustí aktualizace závislých materializovaných pohledů v Silver a Gold vrstvách, což zajišťuje jejich konzistenci. Tento proces je řízen pomocí plánovaných refresh cyklů a lineárního sledování závislostí (DAG), kde se aktualizují jen nové nebo změněné části dat, nikoli celý pohled pokaždé.

Refresh materializovaného pohledu lze také vyvolat manuálně pomocí Spark SQL příkazu, a navíc je možné využít eventstream nebo pipeline orchestrace, která detekuje příjezdy nových dat (eventy) a spouští refresh, což může být ovládáno například přes API či Fabric Pipelines či Data Activator. Tímto způsobem lze nastavit aktualizaci materializovaného pohledu v reálném čase nebo podle potřeby. Celý proces je monitoringovaný, logovaný a optimalizovaný, aby se minimalizovaly náklady a doba zpracování.

---
---
# Další video a notebook v ipynb

Odkaz do Obsidianu -> [[obsidian://open?vault=data-engineering-journey-2026-2.0&file=GetDataFromKaggle-PowerBi%20connection%20modes%20(inc%20DirectLake).ipynb]]

---
---
A další:

https://youtu.be/wAayC-J9TsU?si=2zVKGGFcyJFKsjwp
	
	![[00 Schema validation of incoming files with GX.ipynb]]
	![[01 Spark DF validation with GX.ipynb]]
	![[03 Semantic model validation with GX.ipynb]]