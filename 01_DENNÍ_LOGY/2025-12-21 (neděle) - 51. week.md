


Repeat

❓A company uses Microsoft Fabric for data engineering workflows and notices Spark jobs are slow due to suboptimal resource allocation.

You need to enhance Spark job efficiency by adjusting environment settings.

What action should be taken?

	Enable dynamic allocation of executors.

TRY PRACTICE FIRST MICROSOFT TEST:

# DP-700 Practice Assessment – Výsledek (21. 12. 2025)

- **Datum pokusu:** 21. 12. 2025
- **Název:** Practice Assessment for Exam DP-700: Implementing Data Engineering Solutions Using Microsoft Fabric
- **Délka pokusu:** 44 minut
- **Skóre:** 46 %
- **Cílový benchmark:** Opakovaně dosáhnout alespoň 80 % a více

## Výkon podle sekcí

- **Implement and manage an analytics solution** – aktuálně slabší oblast, zaměřit se na architekturu, deployment pipelines, bezpečnost a governance ve Fabricu.
- **Ingest and transform data** – aktuálně slabší oblast, procvičit ingestion patterns, Data Factory/Dataflows, medallion architekturu a transformace do Lakehouse/DW.
- **Monitor and optimize an analytics solution** – aktuálně slabší oblast, projít monitoring, Real-Time hub, alerty, optimalizaci výkonu (Delta, Spark, SQL).


