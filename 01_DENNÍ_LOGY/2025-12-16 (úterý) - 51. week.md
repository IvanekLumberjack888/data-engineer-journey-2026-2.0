# PraktickÃ¡ pÅ™Ã­prava (QUIZ)

	V rÃ¡mci optimalizace vÃ½konu ÄtenÃ­ v Lakehouse pro sÃ©mantickÃ½ model v reÅ¾imu Direct Lake je potÅ™eba zajistit, aby data byla uloÅ¾ena ve formÃ¡tu V-Order. KterÃ½ z nÃ¡sledujÃ­cÃ­ch zpÅ¯sobÅ¯ konfigurace V-Order zajistÃ­, Å¾e VÅ ECHNY budoucÃ­ zÃ¡pisy do konkrÃ©tnÃ­ tabulky `FactSales` budou VÅ½DY pouÅ¾Ã­vat V-Order, bez ohledu na nastavenÃ­ Spark session v notebooku, kterÃ½ zÃ¡pis provÃ¡dÃ­?

		ğŸ‘“ SpuÅ¡tÄ›nÃ­ pÅ™Ã­kazu ALTER TABLE ğŸ‘€
	
	 Analytik sleduje vÃ½kon KQL dotazÅ¯ v Eventhouse a vÅ¡imne si, Å¾e dotaz, kterÃ½ hledÃ¡ chybovÃ© zprÃ¡vy, je vÃ½raznÄ› pomalÃ½. Dotaz vypadÃ¡ takto: `Logs | where Timestamp > ago(7d) and Message contains "error"`. JakÃ¡ optimalizace by s nejvÄ›tÅ¡Ã­ pravdÄ›podobnostÃ­ pÅ™inesla nejvÄ›tÅ¡Ã­ zrychlenÃ­ tohoto dotazu?

		ğŸ‘“ ZmÄ›nÃ­m operÃ¡tor 'contains' na 'has' ğŸ‘€
		ProtoÅ¾e contains to prohledÃ¡vÃ¡ i podÅ™etÄ›zce.
		 TÃ­m pÃ¡dem je has rychlejÅ¡Ã­. ğŸª“

	 SpoleÄnost chce delegovat sprÃ¡vu pracovnÃ­ch prostorÅ¯ patÅ™Ã­cÃ­ch do oddÄ›lenÃ­ 'Finance' na vedoucÃ­ho tohoto oddÄ›lenÃ­, ale zÃ¡roveÅˆ si chce centrÃ¡lnÃ­ IT (Fabric Admin) ponechat plnou kontrolu nad celÃ½m tenantem. JakÃ¡ kombinace rolÃ­ a konceptÅ¯ v Fabric toto nejlÃ©pe umoÅ¾Åˆuje?

		To bylo lehkÃ½: DomÃ©na Finance a Domain Admin bude CFO

	 PÅ™i pouÅ¾itÃ­ OneLake zkratek (shortcuts) na data v Amazon S3 je aktivovÃ¡no keÅ¡ovÃ¡nÃ­ pro zlepÅ¡enÃ­ vÃ½konu. Soubor `transactions_2025-12-10.parquet` o velikosti 500 MB byl naÄten a uloÅ¾en do keÅ¡e. Co se stane, pokud k tomuto souboru nikdo nepÅ™istoupÃ­ po dobu 30 hodin a potÃ© je znovu dotÃ¡zÃ¡n?

		Taky easy: Uplynulo 24h, takÅ¾e znova naÄÃ­st z Amazon S3 a
		 znovu ten soubor bude uloÅ¾en do cache.

	 Data Pipeline v Fabric obsahuje aktivitu Notebook, kterÃ¡ selhÃ¡vÃ¡. Kde by mÄ›l data engineer jako prvnÃ­ hledat podrobnou chybovou zprÃ¡vu a stav bÄ›hu jednotlivÃ½ch Spark Ãºloh spuÅ¡tÄ›nÃ½ch tÃ­mto notebookem?

		 Taky easy: Monitoring Hub. Detali se rozklikne a
		 vÃ­dÃ­me pak detail selhÃ¡nÃ­ a pak vÃ­c ve Spark History Server

	 BÄ›hem streamovÃ¡nÃ­ dat pomocÃ­ Eventstreamu do Lakehouse tabulky si vÅ¡imnete v `Data Insights`, Å¾e metrika `IncomingMessages` ukazuje stabilnÃ­ tok 1000 zprÃ¡v za minutu, ale metrika `OutgoingMessages` je trvale na nule. V `Runtime logs` nejsou Å¾Ã¡dnÃ© chybovÃ© hlÃ¡Å¡ky. Co je nejpravdÄ›podobnÄ›jÅ¡Ã­ pÅ™Ã­Äinou tohoto chovÃ¡nÃ­?

		To znamenÃ¡, Å¾e v Eventstreamu je 'drsnÃ½ filtr' proto ğŸ…¾ï¸

	 TÃ½m vyvÃ­jÃ­ streamovacÃ­ Å™eÅ¡enÃ­ pro analÃ½zu uÅ¾ivatelskÃ½ch seancÃ­ na webu. CÃ­lem je pro kaÅ¾dÃ©ho uÅ¾ivatele agregovat poÄet kliknutÃ­ v rÃ¡mci jednÃ© nÃ¡vÅ¡tÄ›vy. NÃ¡vÅ¡tÄ›va je definovÃ¡na jako sekvence akcÃ­, kterÃ¡ je ukonÄena, pokud uÅ¾ivatel nevykazuje Å¾Ã¡dnou aktivitu po dobu 30 minut. KterÃ½ typ okennÃ­ funkce v Eventstreams je pro tento scÃ©nÃ¡Å™ nejvhodnÄ›jÅ¡Ã­?

		Hopping/Session/Sliding/Tumbling? hadej PEPO
		 ğŸ¯SESSION s timeouten neaktivity na 30 sekund

	 Dataflow Gen2, kterÃ© provÃ¡dÃ­ komplexnÃ­ transformace (nÄ›kolik spojenÃ­ a agregacÃ­) na 20 milionech Å™Ã¡dkÅ¯ z Azure SQL databÃ¡ze, bÄ›Å¾Ã­ velmi pomalu. JakÃ¡ optimalizaÄnÃ­ technika by s nejvÄ›tÅ¡Ã­ pravdÄ›podobnostÃ­ pÅ™inesla nejvÃ½znamnÄ›jÅ¡Ã­ zrychlenÃ­?

		To je jasnÃ½: POVOLIT (Enable Staging) stejdÅ¾ing :D

	