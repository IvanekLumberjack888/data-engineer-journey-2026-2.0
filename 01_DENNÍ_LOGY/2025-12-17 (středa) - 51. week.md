Dal코칤 p콏칤prava:

# Praktick치 p콏칤prava (QUIZ)

ZPO캛츼TKU ST콎EDN칈 OBT칈콯NOST PAK P콎ITVRZEN칈.

	 仇늈 jak칠m sc칠n치콏i je nejvhodn캩j코칤 pou쮂셦 vlastn칤 Spark Pool (Custom Spark Pool) nam칤sto v칳choz칤ho Starter Poolu v Microsoft Fabric?

		Pokud p콢jde o tr칠nov치n칤 ML modelu.
		Je t콏eba nav칳코it jak uzly (Node size).
		A je pot콏eba v칤ce pam캩ti/GPU. 游댛 OPTIMIZED

	仇뉾ter칠 z n치sleduj칤c칤ch nastaven칤 se NIKDY neukl치d치 do Git repozit치콏e p콏i zapnut칠 spr치v캩 verz칤 (Version Control) pro Fabric workspace?

		 Pl치ny automatick칠ho obnobov치n칤 dat (Refresh schedules) pro s칠mantick칳 model.

	仇뉷atov칳 in쬰n칳r nasazuje zm캩ny z v칳vojov칠ho (DEV) do testovac칤ho (TEST) prost콏ed칤 pomoc칤 Deployment Pipelines. Po nasazen칤 zjist칤, 쬰 data v tabulk치ch Data Warehouse v TEST prost콏ed칤 chyb칤. Co je nejpravd캩podobn캩j코칤 p콏칤캜inou?

		P콏ece Deployment Pipelines p콏en치코칤 pouze definice a sch칠mata objekt콢, nikoliv samotn치 data v tabulk치ch.

	仇뉽ak칳 je hlavn칤 rozd칤l mezi opr치vn캩n칤mi 'ReadData' a 'ReadAll' p콏i sd칤len칤 Data Warehouse na 칰rovni polo쬶y (item-level sharing)?


		'ReadData' umo쮄갓je 캜ten칤 dat pouze p콏es T-SQL endpoint, zat칤mco 'ReadAll' p콏id치v치 mo쬹ost 캜ten칤 podkladov칳ch soubor콢 v OneLake (nap콏. pro Spark)

	仇뉽ak칳 je hlavn칤 rozd칤l mezi orches춼tra캜n칤m n치strojem Data Pipeline a orches춼trac칤 pomoc칤 Fabric Notebooku?

		Data-pipeline nab칤z칤 vizu치ln칤 low-code rozhran칤, zat칤mco orchestrace v notebooku je code-first p콏칤stup v Pythonu.

	仇늈ytv치콏칤te datovou pipeline, kter치 m치 na캜칤tat denn칤 p콏칤r콢stky dat z rela캜n칤 datab치ze do Delta tabulky v Lakehouse. Zdrojov치 tabulka m치 sloupec `LastModifiedDate`. Jak칳 p콏칤stup zvol칤te pro efektivn칤 na캜칤t치n칤?

		 Easy: Incremental load s pou쬴t칤m 'MERGE' operace v PySparku, kter치 porovn치 z치znamy podle 'LastModifiedDate'

	仇늃콏i implementaci dimenzion치ln칤ho modelu chcete zachovat kompletn칤 historii zm캩n v atributech z치kazn칤ka (nap콏. zm캩na adresy). Kter칳 typ Slowly Changing Dimension (SCD) a jak칳 kl칤캜 mus칤te pou쮂셦?

		SCD Type 2 s pou쬴t칤m surrogate (n치hradn칤ho) kl칤캜e jako prim치rn칤ho kl칤캜e.

	 仇늈 jak칠 situaci je vhodn캩j코칤 pou쮂셦 Dataflow Gen2 nam칤sto Copy aktivity v Data Pipeline pro transformaci dat?

		Kdy transformaci prov치d칤 business analytik, kter칳 je zvykl칳 na rozhran칤 Power Query a pot콏ebuje data profilovat a 캜istit pomoc칤 v칤ce n캩 300 vestav캩n칳ch funkc칤.

	仇뉽ak칳 je z치sadn칤 rozd칤l mezi pou쬴t칤m Shortcuts a Mirroring pro integraci extern칤ch dat do Fabricu?

		Mirroring replikuje data do Fabriku pro analytick칠 칰캜ely s n칤zkou latenc칤. Zat칤mco Shortcuts pouze vytv치콏칤 logick칳 odkaz bez kop칤rov치n칤 dat.

	仇늈 Eventstreamu pot콏ebujete spo캜칤tat pr콢m캩rnou teplotu za ka쬯ou uplynulou hodinu, p콏i캜em v칳po캜et se m치 prov칠st v쬯y po skon캜en칤 hodinov칠 periody. Kter칳 typ okenn칤 funkce v transformaci 'Group By' je pro tento 칰캜el nejvhodn캩j코칤?

		Tumbling window - rozd캩luje datov칳 proud na pevn칠 - po sob캩 jdouc칤 nep콏ekr칳vaj칤c칤 se intervaly. Ide치ln칤 pro periodick칠 reporty jako pr콢mer/hodina.