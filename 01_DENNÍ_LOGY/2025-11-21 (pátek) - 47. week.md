# Kurz od Willa. Lehce proklikaný:

# Microsoft Fabric for Power BI developers – 3,5 hodiny zdarma

## Pro koho je kurz určen a hlavní zaměření

- Zaměřeno **primárně na Power BI developery**, ale podstatné informace získá každý, kdo chce pochopit ekosystém Fabric.
    
- Cílem je **usnadnit přechod z Power BI do prostředí Fabric** a naučit všechny klíčové koncepty nové platformy.
    

---

## Timeline/Obsah kurzu (podle časových značek):

- 00:00:00 – Úvod do kurzu
    
- 00:02:23 – Rozdíly mezi Power BI a Fabric architekturou
    
- 00:17:31 – Kapacity (capacities), workspaces, access control
    
- 00:32:56 – Dataflow, pipeline, notebooky, mirroring a shortcuts
    
- 01:04:15 – Data warehouse, lakehouse, KQL database
    
- 01:34:41 – Stavba semantic modelů (Direct Lake vs Import vs Direct Query)
    
- 01:51:45 – End-to-end strategie datové validace
    
- 02:43:45 – Stavba end-to-end řešení ve Fabric
    
- 03:10:11 – Kariérní tipy a možnosti v oblasti Fabric
    

---

## Nejzásadnější kapitoly a shrnutí obsahu:

1. **Power BI vs. Fabric architektura**
    
    - Power BI architektura je orientovaná na rychlou vizualizaci, Fabric architektura umožňuje full-stack zpracování dat (sběr, uložení, transformace, governance) na jednom místě.
        
    - Fabric rozšiřuje možnosti analytických i inženýrských úloh i správu dat a bezpečnosti.
        
2. **Kapacity, workspace, řízení přístupů**
    
    - Fabric vyžaduje naplánování a správu „capacit“ (F-SKU), což jsou výpočetní jednotky pro běh všech Fabric služeb.
        
    - Workspaces jsou logické celky pro pořádek a zabezpečení – doporučuje pečlivě řešit jejich strukturu kvůli správě práv a jednoduché orientaci v projektech.
        
3. **Možnosti načítání dat a orchestrace**
    
    - Dataflow: No-code/low-code ETL s Power Query rozhraním; vhodné na jednoduché transformace a propojení na více datových zdrojů.
        
    - Data pipelines: Orchestrace složitějších datových workflow, možnost řízení běhu, větvení, chybových větví atd.
        
    - Notebooks: Skriptování (Python, Spark) pro pokročilé datové transformace, datové vědce a inženýry.
        
    - Mirroring: Replikace databází (např. Azure SQL) pro near real-time synchronizaci bez plné ETL pipeline.
        
    - Shortcuts: Virtuální zástupci dat, kdy se nekopírují, jen zpřístupní napříč workspaces nebo s integrací externích cloudů.
        
4. **Typy úložišť ve Fabric**
    
    - **Lakehouse**: Kombinace tabulek (Delta Lake) a souborů (parquet, CSV, JSON), podporuje strojové/AI/ML workflow.
        
    - **Data warehouse**: Transakční SQL DB s podporou rozšířeného zabezpečení, analytiky, object/row/column-level security.
        
    - **KQL database**: Specializované na stream/real-time data a práci s událostmi (telemetrie, IoT, logování).
        
5. **Semantic modely a připojení**
    
    - Podpora přímého napojení na (Direct Lake), importního nebo Direct Query režimu.
        
    - Přímý přístup z Power BI a dalších nástrojů na data z Fabric, s možností ladit výkon, refresh a fallback logiku.
        
6. **Strategie datové validace**
    
    - Jak zavést validaci na různých úrovních pipeline a vrstvy architektury (files, tables, semantic modely).
        
    - Přehled nástrojů a open-source knihoven (Great Expectations, Pandera) pro validaci.
        
    - Význam dokumentace, auditních logů a centrálního monitoringu kvality.
        
7. **End-to-end řešení a architektury**
    
    - Reálný scénář: Od vstupu dat až po koncovou vizualizaci, s validacemi a monitoringem kvality na všech stupních.
        
    - Ukázka různých strategií pro volbu data stores (Lakehouse, WH, KQL DB) podle typu dat a uživatelských rolí
        
    - Dopady na governance, bezpečnost a škálování.
        
8. **Kariérní kapitola**
    
    - Možnosti posunu do rolí Analytics Engineer, Data Engineer, Data Scientist.
        
    - Rozdíly v kompetencích a potřebných dovednostech.
        
    - Doporučené certifikace (např. DP-600 pro Analytics Engineer, DP-203 pro Data Engineer).
        
    - Doporučení k samostudiu, kurzy, role komunity.
        

---

## Praktická doporučení a tipy

- **Plánujte workspace logicky** podle rolí, datových vrstev (bronze/silver/gold), případně i Dev/Test/Prod.
    
- Pokud začínáte, kombinujte nejvíc low-code/no-code (Dataflow, Data Pipeline GUI), pro složitější úlohy přejděte na Notebooks a Source Control.
    
- Používejte shortcuts místo kopírování dat.
    
- Zaměřte se na řízení přístupů přes bezpečnostní skupiny (Azure/Entra ID), ne individuální účty.
    
- Validujte data v každé fázi pipeline – škálujte případně pomocí 1 nástroje (např. Great Expectations).
    
- Analyzujte kapacitní požadavky (nároky na F-SKU), zejména pro větší řešení.
    
- Využívejte komunitu, sdílené šablony a open-source notebooky pro urychlení startu.
    

---

**Kdyby tě zajímaly konkrétní implementační detaily z některé kapitoly (například workspace design, validace nebo architektury), můžu dodat ještě podrobné shrnutí/ukázku ve formě poznámek nebo markdown!**

1. [https://www.youtube.com/watch?v=hwwU8V48g-4&list=PLug2zSFKZmV0Yaya7NxRQfrrPtfF2vj0K&index=6](https://www.youtube.com/watch?v=hwwU8V48g-4&list=PLug2zSFKZmV0Yaya7NxRQfrrPtfF2vj0K&index=6)