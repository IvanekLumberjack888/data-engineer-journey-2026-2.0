**PodrobnÃ½ studijnÃ­ prÅ¯vodce**,Â **KvÃ­z s klÃ­Äem odpovÄ›dÃ­**,Â **EsejistickÃ© otÃ¡zky**Â aÂ **KomplexnÃ­ slovnÃ­Äek pojmÅ¯**.

--------------------------------------------------------------------------------

# ğŸ“š PodrobnÃ½ StudijnÃ­ PrÅ¯vodce DP-700

Tento prÅ¯vodce slouÅ¾Ã­ k revizi a syntÃ©ze informacÃ­ z VaÅ¡eho 20dennÃ­ho studijnÃ­ho plÃ¡nu, zamÄ›Å™enÃ©ho na tÅ™i hlavnÃ­ domÃ©ny zkouÅ¡ky DP-700:Â **Implementace, Ingest a Transformace, a Monitoring s OptimalizacÃ­**.

## I. ZÃ¡klady a Architektura (Implementing & Managing)

### A. Hierarchie a ZÃ¡kladnÃ­ Koncepty

1.Â **Fabric Hierarchie:**Â Platforma je hierarchicky strukturovÃ¡na.

Â Â Â Â â—¦Â **Tenant:**Â VaÅ¡e organizace (nejvyÅ¡Å¡Ã­ ÃºroveÅˆ).

Â Â Â Â â—¦Â **Capacity:**Â UrÄuje dostupnÃ½ vÃ½poÄetnÃ­ vÃ½kon (**Compute Units - CU**) a fakturaci (F-SKUs).

Â Â Â Â â—¦Â **Workspace:**Â LogickÃ½ kontejner pro Fabric objekty (items), kde probÃ­hÃ¡ spoluprÃ¡ce.

2.Â **OneLake (Unified Data Lake):**Â PÅ¯sobÃ­ jako jednotnÃ© datovÃ© jezero pro celou organizaci.

Â Â Â Â â—¦Â KlÃ­ÄovÃ½ princip:Â **JedinÃ¡ kopie dat**Â (_single copy of data_) pro odstranÄ›nÃ­ datovÃ½ch sil a duplicit.

Â Â Â Â â—¦Â StandardnÃ­ formÃ¡t pro tabulkovÃ¡ data jeÂ **Delta Parquet**Â (podporuje ACID transakce a verzovÃ¡nÃ­).

3.Â **Shortcuts a Mirroring (Virtualizace):**

Â Â Â Â â—¦Â **Shortcuts:**Â VirtuÃ¡lnÃ­ odkazy na data v jinÃ½ch umÃ­stÄ›nÃ­ch (internÃ­ch nebo externÃ­ch jako ADLS Gen2, Amazon S3, Google Cloud Storage)Â **bez replikace dat**.

Â Â Â Â â—¦Â **Database Mirroring:**Â VytvÃ¡Å™Ã­Â **near real-time repliku**Â podporovanÃ½ch databÃ¡zÃ­ (Azure SQL, Snowflake) do formÃ¡tu Delta Parquet, minimalizujÃ­cÃ­ ETL.

### B. Å˜Ã­zenÃ­ a ZabezpeÄenÃ­ (Governance & Security)

1.Â **Access Control:**Â VÅ¾dy se Å™Ã­dÃ­Â **Principem nejmenÅ¡Ã­ch prÃ¡v**Â (_Principle of Least Privilege_).

Â Â Â Â â—¦Â **Workspace Role:**Â Å˜Ã­dÃ­ pÅ™Ã­stup na Å¡irokÃ© Ãºrovni.Â **Viewer**Â mÅ¯Å¾e ÄÃ­st data pÅ™es SQL endpoint, ale nemÅ¯Å¾e spouÅ¡tÄ›t pipelines.

Â Â Â Â â—¦Â **Item-level Access:**Â PÅ™Ã­stup ke konkrÃ©tnÃ­ poloÅ¾ce (napÅ™. Data Warehouse).

2.Â **GranulÃ¡rnÃ­ ZabezpeÄenÃ­ (Warehouse/SQL Endpoint):**

Â Â Â Â â—¦Â **Row-Level Security (RLS):**Â Omezuje pÅ™Ã­stup k datÅ¯m na zÃ¡kladÄ› Å™Ã¡dkÅ¯ (implementace pomocÃ­Â **Table-Valued Function (TVF)**Â aÂ **Security Policy**Â v T-SQL).

Â Â Â Â â—¦Â **Column-Level Security (CLS):**Â Omezuje pÅ™Ã­stup k definovanÃ½m sloupcÅ¯m (implementace pomocÃ­Â `GRANT SELECT (sloupce)`Â v T-SQL).

Â Â Â Â â—¦Â **Dynamic Data Masking (DDM):**Â Maskuje citlivÃ© informace (napÅ™. email, plat) na ÃºrovniÂ **vÃ½sledku dotazu**, aniÅ¾ by mÄ›nilo podkladovÃ¡ data;Â **neÅ¡ifruje**Â data a lze jej obejÃ­t.

3.Â **Governance (Endorsements):**Â PomÃ¡hÃ¡ identifikovat dÅ¯vÄ›ryhodnÃ¡ data.

Â Â Â Â â—¦Â **Promoted:**Â DoporuÄeno tvÅ¯rcem poloÅ¾ky (nÃ­zkÃ¡ ÃºroveÅˆ dÅ¯vÄ›ry).

Â Â Â Â â—¦Â **Certified:**Â SplÅˆuje firemnÃ­ standardy kvality, vyÅ¾aduje schvÃ¡lenÃ­.

Â Â Â Â â—¦Â **Master Data:**Â JÃ¡dro datovÃ©ho zdroje s nejvyÅ¡Å¡Ã­ dÅ¯vÄ›ryhodnostÃ­.

--------------------------------------------------------------------------------

## II. Ingest a Transformace (Ingesting & Transforming)

### A. Architektura Data Store

|   |   |   |   |
|---|---|---|---|
|ÃšloÅ¾iÅ¡tÄ›|PrimÃ¡rnÃ­ zamÄ›Å™enÃ­|PrimÃ¡rnÃ­ Jazyk|KlÃ­ÄovÃ© Vlastnosti|
|**Lakehouse**|FlexibilnÃ­ ELT, NestrukturovanÃ¡ data, ML/Data Science|PySpark/Spark SQL|MÃ¡ sekciÂ **Files**Â (surovÃ¡ data) aÂ **Tables**Â (Delta tabulky). Podporuje pouzeÂ **Read-Only SQL Analytics Endpoint**.|
|**Data Warehouse (DW)**|BI Reporting, Gold Layer, TabulkovÃ¡ data|T-SQL|PodporujeÂ **Multi-table transactions**. Podporuje Stored Procedures, Views, Schemas.|
|**Eventhouse (KQL DB)**|Real-time event data, Time-series, Logy|KQL|OptimalizovÃ¡no pro rychlÃ© dotazy. Spravuje se pomocÃ­Â **Retention**Â aÂ **Caching**Â policies.|

### B. Ingestion a Orchestrace

1.Â **Data Pipelines:**Â PrimÃ¡rnÃ­ nÃ¡stroj proÂ **Orchestraci**Â a hromadnÃ½ pÅ™esun dat (Batch ETL/ELT).

Â Â Â Â â—¦Â KlÃ­ÄovÃ¡ aktivita:Â **Copy Data**Â (pro ingest z 100+ zdrojÅ¯).

Â Â Â Â â—¦Â PokroÄilÃ© vzorce:Â **Metadata-Driven Pipelines**Â se sklÃ¡dajÃ­ zÂ **Lookup**Â (naÄtenÃ­ metadat) aÂ **ForEach**Â (iterace).

Â Â Â Â â—¦Â Lze spouÅ¡tÄ›t i pÅ™esÂ **Invoke Pipeline**Â (Parent-Child arch.).

2.Â **Dataflows Gen2 (DFG2):**Â **Low-Code/No-Code**Â ETL, pohÃ¡nÄ›nÃ© Power Query (M language).

Â Â Â Â â—¦Â IdeÃ¡lnÃ­ pro analytiky a pro pÅ™Ã­stup kÂ **On-Premise Sources**Â pÅ™es Data Gateway.

Â Â Â Â â—¦Â KlÃ­ÄovÃ© pro scÃ©nÃ¡Å™e, kterÃ© vyÅ¾adujÃ­Â **minimalizovat vÃ½vojovÃ© ÃºsilÃ­**Â (_minimize development effort_).

3.Â **Notebooks (Spark/PySpark):**Â **Full Code**Â Å™eÅ¡enÃ­ (Python/Spark SQL).

Â Â Â Â â—¦Â IdeÃ¡lnÃ­ pro: komplexnÃ­ custom transformace, integraci s API, velkÃ½ objem dat a Data Science/ML.

Â Â Â Â â—¦Â **notebookutils**Â je klÃ­ÄovÃ¡ knihovna pro internÃ­ Fabric Ãºkoly (napÅ™. orchestrace jinÃ½ch notebookÅ¯, ÄtenÃ­ secretÅ¯).

4.Â **Loading Patterns:**

Â Â Â Â â—¦Â **Incremental Load:**Â Implementuje se v Lakehouse primÃ¡rnÄ› pomocÃ­Â **Delta MERGE INTO**Â (pro UPSERT operace â€“ insert, update, delete v jednom).

Â Â Â Â â—¦Â **Full Load:**Â PÅ™epÃ­Å¡e cÃ­lovou tabulku (napÅ™.Â `mode("overwrite")`).

### C. Dimensional Modeling (DW/Lakehouse)

â€¢Â **SCD Type 2:**Â Typ pomalu se mÄ›nÃ­cÃ­ dimenze, kterÃ½ sledujeÂ **celou historii**Â zmÄ›n atributu (vytvoÅ™Ã­ novÃ½ Å™Ã¡dek sÂ `ValidFrom`/`ValidTo`Â neboÂ `IsCurrent`Â flagem).

â€¢Â **Surrogate Keys (NÃ¡hradnÃ­ klÃ­Äe):**Â PouÅ¾Ã­vajÃ­ se mÃ­stoÂ **Natural Keys**Â (zdrojovÃ© ID) pro podporu sledovÃ¡nÃ­ historie a relacÃ­ s Fact tabulkami.

--------------------------------------------------------------------------------

## III. Monitoring a Optimalizace

### A. Monitoring a Debugging

1.Â **Monitoring Hub:**Â CentrÃ¡lnÃ­ mÃ­sto pro sledovÃ¡nÃ­ stavuÂ **vÅ¡ech bÄ›hÅ¯**Â (Pipelines, Notebooks, Dataflows, Semantic Model Refreshes).

2.Â **Capacity Metrics App:**Â Power BI report pro Capacity Admins, slouÅ¾Ã­ k monitorovÃ¡nÃ­ spotÅ™ebyÂ **CU (Capacity Units)**, identifikaci nadmÄ›rnÃ© spotÅ™eby a detekciÂ **Throttlingu**Â (snÃ­Å¾enÃ­ vÃ½konu pÅ™i pÅ™etÃ­Å¾enÃ­).

3.Â **Pipeline Debugging:**Â PanelÂ **Inputs/Outputs**Â v detailu bÄ›hu je klÃ­ÄovÃ½ pro ladÄ›nÃ­ dynamickÃ½ch vÃ½razÅ¯ a chyb.

4.Â **Data Warehouse Monitoring:**Â **Query Activity tab**Â aÂ **Query Insights**Â view sledujÃ­ dlouho bÄ›Å¾Ã­cÃ­ a Äasto spouÅ¡tÄ›nÃ© T-SQL dotazy.

5.Â **Spark Monitoring:**Â Pro detailnÃ­ diagnostiku vÃ½konu (skew) se pouÅ¾Ã­vÃ¡Â **Spark History Server**.

### B. Optimalizace Dat

1.Â **Delta Lake ÃšdrÅ¾ba (Lakehouse):**

Â Â Â Â â—¦Â **OPTIMIZE****:**Â SlouÅ¾Ã­ keÂ **kompakci**Â malÃ½ch souborÅ¯ Parquet do optimÃ¡lnÃ­ velikosti, ÄÃ­mÅ¾ zlepÅ¡uje vÃ½kon ÄtenÃ­.

Â Â Â Â â—¦Â **VACUUM****:**Â Fyzicky maÅ¾e starÃ© soubory, kterÃ© jiÅ¾ nejsou odkazovÃ¡ny transakÄnÃ­m logem (uvolnÄ›nÃ­ mÃ­sta).

2.Â **V-Order:**Â ProprietÃ¡rnÃ­ optimalizace aplikovanÃ¡ na Delta soubory, zlepÅ¡ujÃ­cÃ­ vÃ½kon ÄtenÃ­, zvlÃ¡Å¡tÄ› proÂ **Direct Lake**.

3.Â **Spark Pools:**Â **Custom Spark Pool**Â se pouÅ¾Ã­vÃ¡ pro nÃ¡roÄnÃ© a velkÃ© joby, i kdyÅ¾ mÃ¡ delÅ¡Ã­ start-up Äas neÅ¾Â **Starter Pool**.Â **High Concurrency**Â umoÅ¾Åˆuje vÃ­ce jobÅ¯m sdÃ­let stejnou Spark Session.

### C. Real-Time a BI Integrace

1.Â **Eventstreams:**Â Low-Code nÃ¡stroj pro streamovanÃ¡ data, podporuje agregace pÅ™esÂ **Time Windows**Â (napÅ™.Â **Tumbling Window**Â pro pevnÃ© nepÅ™ekrÃ½vajÃ­cÃ­ se intervaly).

2.Â **KQL (Kusto Query Language):**Â Read-only jazyk pro Eventhouse.Â **Materialized Views**Â se pouÅ¾Ã­vajÃ­ k uklÃ¡dÃ¡nÃ­ pÅ™edpoÄÃ­tanÃ½ch agregacÃ­ pro rychlÃ½ reporting.

3.Â **Direct Lake:**Â NovÃ½ reÅ¾im pÅ™ipojenÃ­ proÂ **Semantic Models**Â (Power BI), kterÃ½ kombinuje rychlost Importu a aktuÃ¡lnost Direct Query. Data Äte pÅ™Ã­mo z Delta Parquet souborÅ¯ v OneLake.

Â Â Â Â â—¦Â KlÃ­ÄovÃ¡ funkce:Â **Fallback**Â (pÅ™epnutÃ­) na Direct Query, pokud Direct Lake nemÅ¯Å¾e zpracovat dotaz (napÅ™. kvÅ¯li nepodporovanÃ½m View nebo DAX).

--------------------------------------------------------------------------------

# ğŸ§  KvÃ­z (10 KrÃ¡tkÃ½ch OtÃ¡zek)

## OdpovÄ›zte na kaÅ¾dou otÃ¡zku v rozsahu 2â€“3 vÄ›t s ohledem na informace ve zdrojÃ­ch.

1.Â **PopiÅ¡te vztah mezi Tenant, Capacity a Workspace v hierarchii Microsoft Fabric.**

2.Â **JakÃ¡ je hlavnÃ­ architektonickÃ¡ vÃ½hoda pouÅ¾Ã­vÃ¡nÃ­ OneLake, pokud jde o sprÃ¡vu dat v rÃ¡mci organizace?**

3.Â **JakÃ½ je kritickÃ½ rozdÃ­l mezi Data Warehouse a Lakehouse, pokud jde o podporu transakcÃ­?**

4.Â **VysvÄ›tlete, jakÃ½ je ÃºÄel Shortcut Cache a u jakÃ½ch externÃ­ch zdrojÅ¯ se primÃ¡rnÄ› pouÅ¾Ã­vÃ¡.**

5.Â **V jakÃ©m scÃ©nÃ¡Å™i byste upÅ™ednostnili Dataflow Gen2 pÅ™ed Notebookem (PySpark) pro ETL/ELT a proÄ?**

6.Â **K Äemu slouÅ¾Ã­ knihovna**Â **notebookutils**Â **a jakÃ¡ je jedna jejÃ­ klÃ­ÄovÃ¡ funkce?**

7.Â **JakÃ½ Delta Lake pÅ™Ã­kaz je klÃ­ÄovÃ½ pro implementaci inkrementÃ¡lnÃ­ho naÄÃ­tÃ¡nÃ­ (Incremental Load) v Lakehouse a co provÃ¡dÃ­?**

8.Â **VysvÄ›tlete hlavnÃ­ rozdÃ­l mezi Row-Level Security (RLS) a Dynamic Data Masking (DDM).**

9.Â **KterÃ½ Fabric nÃ¡stroj musÃ­ pouÅ¾Ã­t Capacity Admin, aby monitoroval spotÅ™ebu CU a detekoval throttling?**

10.Â **PopiÅ¡te klÃ­Äovou vÃ½hodu Direct Lake mÃ³du pro Power BI Semantic Models a co je to Fallback funkce?**

--------------------------------------------------------------------------------

## âœ… KlÃ­Ä OdpovÄ›dÃ­

1.Â **PopiÅ¡te vztah mezi Tenant, Capacity a Workspace v hierarchii Microsoft Fabric.**Â **Tenant**Â je nejvyÅ¡Å¡Ã­ ÃºroveÅˆ, kterÃ¡ pÅ™edstavuje organizaci. KaÅ¾dÃ½ Tenant hostujeÂ **Capacities**, kterÃ© alokujÃ­Â **Compute Units (CU)**Â a definujÃ­ vÃ½poÄetnÃ­ vÃ½kon.Â **Workspaces**Â jsou kolaborativnÃ­ kontejnery, kterÃ© Å¾ijÃ­ uvnitÅ™ Capacity a drÅ¾Ã­ vÅ¡echny Fabric poloÅ¾ky (items).

2.Â **JakÃ¡ je hlavnÃ­ architektonickÃ¡ vÃ½hoda pouÅ¾Ã­vÃ¡nÃ­ OneLake, pokud jde o sprÃ¡vu dat v rÃ¡mci organizace?**Â HlavnÃ­ vÃ½hodou OneLake je, Å¾e funguje jako jednotnÃ© datovÃ© jezero a prosazuje principÂ **jedinÃ© kopie dat**Â (_single copy of data_). To pomÃ¡hÃ¡ eliminovat datovÃ¡ sila a duplicity (replikaci dat), kterÃ© jsou bÄ›Å¾nÃ© ve starÅ¡Ã­ch architekturÃ¡ch.

3.Â **JakÃ½ je kritickÃ½ rozdÃ­l mezi Data Warehouse a Lakehouse, pokud jde o podporu transakcÃ­?**Â **Data Warehouse**Â podporujeÂ **multi-table transactions**Â (transakce napÅ™Ã­Ä vÃ­ce tabulkami), kterÃ© zajiÅ¡Å¥ujÃ­ konzistenci dat, coÅ¾ je klÃ­ÄovÃ© pro Gold vrstvu.Â **Lakehouse**Â tuto funkci v souÄasnosti nepodporuje, coÅ¾ znamenÃ¡, Å¾e transakÄnÃ­ integrita se musÃ­ Å™eÅ¡it na Ãºrovni jednÃ© tabulky (Delta) nebo pomocÃ­ orchestrace.

4.Â **VysvÄ›tlete, jakÃ½ je ÃºÄel Shortcut Cache a u jakÃ½ch externÃ­ch zdrojÅ¯ se primÃ¡rnÄ› pouÅ¾Ã­vÃ¡.**Â **Shortcut Cache**Â je nastavenÃ­ na Ãºrovni Workspace, kterÃ© uklÃ¡dÃ¡ Äasto pÅ™Ã­stupnÃ¡ data z externÃ­ch cloudovÃ½ch ÃºloÅ¾iÅ¡Å¥ lokÃ¡lnÄ› v OneLake. HlavnÃ­m ÃºÄelem je snÃ­Å¾it nÃ¡klady na egress (poplatky za odchozÃ­ data), a primÃ¡rnÄ› se pouÅ¾Ã­vÃ¡ proÂ **Amazon S3**Â aÂ **Google Cloud Storage**.

5.Â **V jakÃ©m scÃ©nÃ¡Å™i byste upÅ™ednostnili Dataflow Gen2 pÅ™ed Notebookem (PySpark) pro ETL/ELT a proÄ?**Â Dataflow Gen2 (DFG2) byste upÅ™ednostnili ve scÃ©nÃ¡Å™Ã­ch, kterÃ© vyÅ¾adujÃ­Â **low-code/no-code**Â pÅ™Ã­stup a potÅ™ebujÃ­Â **minimalizovat vÃ½vojovÃ© ÃºsilÃ­**. DFG2 je takÃ© ideÃ¡lnÃ­ pro pÅ™Ã­stup kÂ **on-premise zdrojÅ¯m**Â prostÅ™ednictvÃ­m Data Gateway, coÅ¾ Notebooky bez dalÅ¡Ã­ch krokÅ¯ nezvlÃ¡dajÃ­.

6.Â **K Äemu slouÅ¾Ã­ knihovna**Â **notebookutils**Â **a jakÃ¡ je jedna jejÃ­ klÃ­ÄovÃ¡ funkce?**Â `notebookutils`Â je vestavÄ›nÃ½ Python balÃ­k, kterÃ½ zefektivÅˆuje bÄ›Å¾nÃ© Ãºlohy v Notebooku. Jedna klÃ­ÄovÃ¡ funkce jeÂ **orchestrace jinÃ½ch notebookÅ¯**Â (napÅ™. pomocÃ­Â `notebookutils.notebook.run_multiple`), dÃ¡le slouÅ¾Ã­ ke ÄtenÃ­ secretÅ¯ (credentials) nebo operacÃ­m se souborovÃ½m systÃ©mem.

7.Â **JakÃ½ Delta Lake pÅ™Ã­kaz je klÃ­ÄovÃ½ pro implementaci inkrementÃ¡lnÃ­ho naÄÃ­tÃ¡nÃ­ (Incremental Load) v Lakehouse a co provÃ¡dÃ­?**Â KlÃ­ÄovÃ½ pÅ™Ã­kaz jeÂ **Delta MERGE INTO**. Tento pÅ™Ã­kaz provÃ¡dÃ­Â **UPSERT**Â operaci, coÅ¾ znamenÃ¡, Å¾e dokÃ¡Å¾e v jedinÃ© operaci zpracovat vloÅ¾enÃ­ novÃ½ch Å™Ã¡dkÅ¯, aktualizace existujÃ­cÃ­ch Å™Ã¡dkÅ¯ a mazÃ¡nÃ­ zÃ¡znamÅ¯ v cÃ­lovÃ© Delta tabulce.

8.Â **VysvÄ›tlete hlavnÃ­ rozdÃ­l mezi Row-Level Security (RLS) a Dynamic Data Masking (DDM).**Â **Row-Level Security (RLS)**Â **omezuje pÅ™Ã­stup**Â k datÅ¯m na zÃ¡kladÄ›Â **Å™Ã¡dkÅ¯**Â (napÅ™. uÅ¾ivatel vidÃ­ jen svÃ© zÃ¡znamy).Â **Dynamic Data Masking (DDM)**Â pouzeÂ **maskuje**Â zobrazenÃ­ citlivÃ½ch dat (napÅ™. hvÄ›zdiÄkami) na Ãºrovni vÃ½sledku dotazu, ale neomezuje pÅ™Ã­stup k datÅ¯m a neÅ¡ifruje je.

9.Â **KterÃ½ Fabric nÃ¡stroj musÃ­ pouÅ¾Ã­t Capacity Admin, aby monitoroval spotÅ™ebu CU a detekoval throttling?**Â Capacity Admin musÃ­ pouÅ¾Ã­t nÃ¡strojÂ **Capacity Metrics App**. Tato aplikace poskytuje detailnÃ­ Power BI report, kterÃ½ sleduje spotÅ™ebuÂ **Capacity Units (CU)**, pomÃ¡hÃ¡ identifikovat pÅ™etÃ­Å¾enÃ­ a detekuje, kdy dochÃ¡zÃ­ kÂ **Throttlingu**Â (snÃ­Å¾enÃ­ vÃ½konu).

10.Â **PopiÅ¡te klÃ­Äovou vÃ½hodu Direct Lake mÃ³du pro Power BI Semantic Models a co je to Fallback funkce?**Â KlÃ­Äovou vÃ½hodouÂ **Direct Lake**Â je, Å¾e kombinuje rychlost Import mÃ³du s aktuÃ¡lnostÃ­ Direct Query, protoÅ¾e Äte dataÂ **pÅ™Ã­mo z Delta Parquet souborÅ¯ v OneLake**Â bez nutnosti refreshÅ¯.Â **Fallback**Â je automatickÃ¡ funkce, kdy se Direct Lake pÅ™epne do reÅ¾imu Direct Query, pokud narazÃ­ na nepodporovanou operaci (napÅ™. View nebo komplexnÃ­ DAX).

--------------------------------------------------------------------------------

# ğŸ“ EsejistickÃ© OtÃ¡zky

## NÃ¡sledujÃ­cÃ­ch pÄ›t otÃ¡zek vyÅ¾aduje syntÃ©zu znalostÃ­ z vÃ­ce oblastÃ­ Fabric a simulujÃ­ scÃ©nÃ¡Å™e zkouÅ¡ky DP-700.

1.Â **Architektura Gold Vrstvy:**Â NavrhnÄ›te kompletnÃ­ architekturu Gold vrstvy pro finanÄnÃ­ reporting v Microsoft Fabric, kterÃ¡ vyuÅ¾Ã­vÃ¡ DW a Semantic Model. PopiÅ¡te, jak zajistÃ­teÂ **Multi-table Transaction Consistency**, implementujeteÂ **Row-Level Security (RLS)**Â a jakou roli hrajeÂ **Direct Lake**Â v nÃ¡slednÃ©m BI reportingu, vÄetnÄ› popisu moÅ¾nÃ½ch limitÅ¯ a jejich Å™eÅ¡enÃ­.

2.Â **End-to-End InkrementÃ¡lnÃ­ Pipeline:**Â NavrhnÄ›teÂ **Metadata-Driven Data Pipeline**Â pro inkrementÃ¡lnÃ­ ingest 50 tabulek ze zdrojovÃ© databÃ¡ze do Lakehouse Bronze vrstvy. PopiÅ¡te klÃ­ÄovÃ© aktivity orchestrace (**Lookup/ForEach**), jak implementujeteÂ **UPSERT**Â logiku v Lakehouse Silver vrstvÄ› a jakÃ© nÃ¡stroje (Notebook vs. Pipeline Copy Data) pouÅ¾ijete pro efektivnÃ­ pÅ™esun dat.

3.Â **Real-Time AnalÃ½za a Validace Kvality:**Â PopiÅ¡te, jak byste navrhli real-time Å™eÅ¡enÃ­ pro monitoring telemetrie ze senzorÅ¯ v Eventhouse. VysvÄ›tlete roliÂ **Eventstreams**Â a jak byste vyuÅ¾iliÂ **Materialized Views**Â pro zrychlenÃ­ dashboardingu. DÃ¡le navrhnÄ›te, jak zajistitÂ **validaci schÃ©matu a obsahu**Â pÅ™Ã­chozÃ­ch streamovanÃ½ch dat pomocÃ­ code-based Å™eÅ¡enÃ­ (Spark) a jak byste logovali chyby (Failure Strategy).

4.Â **Optimalizace a Throttling:**Â VÃ¡Å¡ produkÄnÃ­ systÃ©m trpÃ­ nepravidelnÃ½mÂ **Throttlingem**Â a pomalÃ½m bÄ›hem Spark NotebookÅ¯. Jako Data Engineer, jakÃ© dva hlavnÃ­ nÃ¡stroje pouÅ¾ijete proÂ **monitoring spotÅ™eby CU a diagnostiku vÃ½konu Sparku**? DetailnÄ› popiÅ¡te kroky, kterÃ© provedete proÂ **optimalizaci Delta tabulek**Â v Lakehouse a vysvÄ›tlete funkciÂ **V-Order**Â v kontextu ÄtenÃ­ dat.

5.Â **CI/CD a SprÃ¡va Schematu:**Â NavrhnÄ›te kompletnÃ­ CI/CD strategii pro Fabric Å™eÅ¡enÃ­, kterÃ© zahrnujeÂ **Data Warehouse (schema) a Data Pipelines (kÃ³d)**, s pÅ™echodem mezi Dev, Test a Prod Workspace. VysvÄ›tlete, jakÃ¡ je roleÂ **Git Integration**Â a jak se liÅ¡Ã­ odÂ **Deployment Pipelines**. Jak zajistÃ­te, Å¾e schÃ©ma Data Warehouse je verzovÃ¡no a nasazeno pomocÃ­ standardizovanÃ©ho artefaktu (**DACPAC**)?

--------------------------------------------------------------------------------

# ğŸ“‡ SlovnÃ­Äek KlÃ­ÄovÃ½ch PojmÅ¯ (Glossary)

## Tento slovnÃ­Äek obsahuje klÃ­Äovou anglickou terminologii (Core Terms a FrÃ¡ze) z oblastÃ­ DP-700 pokrytÃ½ch ve zdrojÃ­ch, s ÄeskÃ½m vysvÄ›tlenÃ­m a citacÃ­.

|   |   |   |
|---|---|---|
|Pojem (English)|Definice (Czech)|Reference|
|**Capacity**|VÃ½poÄetnÃ­ vÃ½kon (CU - Capacity Units), kterÃ½ urÄuje dostupnou rychlost zpracovÃ¡nÃ­ dat a fakturaci v rÃ¡mci Fabric.||
|**Compute Units (CU)**|Jednotky pÅ™edstavujÃ­cÃ­ vÃ½poÄetnÃ­ vÃ½kon, jejichÅ¾ spotÅ™ebu je nutnÃ© sledovat (napÅ™. pomocÃ­ Capacity Metrics App).||
|**Throttling**|SnÃ­Å¾enÃ­ vÃ½konu nebo odmÃ­tÃ¡nÃ­ Ãºloh systÃ©mem, pokud je kapacita (CU) dlouhodobÄ› pÅ™etÃ­Å¾enÃ¡.||
|**OneLake**|JednotnÃ© datovÃ© jezero ve Fabric, kterÃ© zajiÅ¡Å¥uje princip jedinÃ© kopie dat (_single copy of data_) a uklÃ¡dÃ¡ data ve formÃ¡tu Delta Parquet.||
|**Delta Parquet**|OtevÅ™enÃ½ standardnÃ­ formÃ¡t pro tabulkovÃ¡ data v OneLake, kterÃ½ podporuje ACID transakce, verzovÃ¡nÃ­ a zajiÅ¡Å¥uje interoperabilitu mezi enginy.||
|**Shortcuts**|VirtuÃ¡lnÃ­ odkazy na data uloÅ¾enÃ¡ jinde (internÄ› v Fabric nebo externÄ› â€“ S3/ADLS Gen2) bez nutnosti fyzickÃ© replikace.||
|**SQL Analytics Endpoint**|Read-only T-SQL rozhranÃ­, kterÃ© umoÅ¾Åˆuje dotazovat data (Tables) v Lakehouse pomocÃ­ T-SQL.||
|**Multi-table Transaction**|Transakce napÅ™Ã­Ä vÃ­ce tabulkami, kterou podporuje Data Warehouse, ale ne Lakehouse, a zajiÅ¡Å¥uje tak konzistenci dat.||
|**Copy Data Activity**|KlÃ­ÄovÃ¡ aktivita v Data Pipeline, kterÃ¡ slouÅ¾Ã­ primÃ¡rnÄ› pro hromadnÃ½ pÅ™esun dat (ingest) z mnoha zdrojÅ¯ do Fabric data stores.||
|**Data Gateway**|On-premise komponenta, kterÃ¡ je nutnÃ¡ pro pÅ™ipojenÃ­Â **Dataflows Gen2**Â (a ve ScÃ©nÃ¡Å™Ã­ch Copy Data) k datovÃ½m zdrojÅ¯m umÃ­stÄ›nÃ½m v lokÃ¡lnÃ­ sÃ­ti organizace.||
|**Metadata-Driven**|Vzorec orchestrace, kdeÂ **Data Pipeline**Â pouÅ¾Ã­vÃ¡ aktivityÂ **Lookup**Â aÂ **ForEach**Â k dynamickÃ©mu zpracovÃ¡nÃ­ mnoha datovÃ½ch sad na zÃ¡kladÄ› metadat.||
|**Full Load**|Strategie naÄÃ­tÃ¡nÃ­ dat, pÅ™i kterÃ© je celÃ¡ cÃ­lovÃ¡ tabulka pÅ™i kaÅ¾dÃ©m spuÅ¡tÄ›nÃ­ pÅ™epsÃ¡na (overwrite).||
|**Incremental Load**|Strategie naÄÃ­tÃ¡nÃ­ dat, pÅ™i kterÃ© se pÅ™enÃ¡Å¡ejÃ­ a zpracovÃ¡vajÃ­ pouze zmÄ›nÄ›nÃ¡ data (insert, update, delete) od poslednÃ­ho bÄ›hu.||
|**MERGE INTO (Delta)**|Delta Lake pÅ™Ã­kaz pouÅ¾Ã­vanÃ½ v Lakehouse pro efektivnÃ­ implementaciÂ **UPSERT**Â operacÃ­ (vloÅ¾enÃ­/aktualizace/mazÃ¡nÃ­).||
|**SCD Type 2**|Typ pomalu se mÄ›nÃ­cÃ­ dimenze, kterÃ½ udrÅ¾ujeÂ **Ãºplnou historii**Â zmÄ›n dimenzÃ­ vytvoÅ™enÃ­m novÃ©ho Å™Ã¡dku s ÄasovÃ½mi razÃ­tky (`ValidFrom`,Â `ValidTo`).||
|**Tumbling Window**|Typ ÄasovÃ©ho okna pouÅ¾Ã­vanÃ©ho vÂ **Eventstreams**Â pro agregaci streamovanÃ½ch dat v pevnÃ½ch,Â **nepÅ™ekrÃ½vajÃ­cÃ­ch se**Â ÄasovÃ½ch intervalech.||
|**KQL**|**Kusto Query Language**, jazyk dotazÅ¯ pouze pro ÄtenÃ­ (_read-only request language_) pouÅ¾Ã­vanÃ½ pro filtrovÃ¡nÃ­, analÃ½zu a vizualizaci dat vÂ **Eventhouse**Â (KQL DatabÃ¡ze).||
|**Materialized View**|PÅ™edpoÄÃ­tanÃ½ pohled na KQL DatabÃ¡zi, kterÃ½ uchovÃ¡vÃ¡ agregovanÃ© vÃ½sledky, slouÅ¾Ã­cÃ­ k dramatickÃ©mu zrychlenÃ­ real-time dashboardÅ¯ a Äasto spouÅ¡tÄ›nÃ½ch dotazÅ¯.||
|**Dynamic Data Masking (DDM)**|BezpeÄnostnÃ­ funkce, kterÃ¡ maskuje citlivÃ¡ data na ÃºrovniÂ **vÃ½sledku dotazu**Â pro neoprÃ¡vnÄ›nÃ© uÅ¾ivatele, aniÅ¾ by data Å¡ifrovala.||
|**Row-Level Security (RLS)**|BezpeÄnostnÃ­ funkce, kterÃ¡Â **omezuje pÅ™Ã­stup**Â uÅ¾ivatelÅ¯ k datÅ¯m na zÃ¡kladÄ›Â **Å™Ã¡dkÅ¯**.||
|**Capacity Metrics App**|Power BI aplikace pro Capacity Admins, urÄenÃ¡ ke sledovÃ¡nÃ­ spotÅ™eby CU, nÃ¡kladÅ¯ a detekciÂ **throttlingu**.||
|**V-Order**|ProprietÃ¡rnÃ­ optimalizace Delta souborÅ¯ v Lakehouse/DW, kterÃ¡ zlepÅ¡uje vÃ½kon ÄtenÃ­, zvlÃ¡Å¡tÄ› u Semantic Models vyuÅ¾Ã­vajÃ­cÃ­chÂ **Direct Lake**.||
|**OPTIMIZE**|PÅ™Ã­kaz pro ÃºdrÅ¾bu Delta tabulek (v Lakehouse), kterÃ½ provÃ¡dÃ­Â **kompakci**Â malÃ½ch Parquet souborÅ¯ a zvyÅ¡uje rychlost ÄtenÃ­.||
|**VACUUM**|PÅ™Ã­kaz pro ÃºdrÅ¾bu Delta tabulek (v Lakehouse), kterÃ½ fyzicky maÅ¾e starÃ© soubory, kterÃ© uÅ¾ nejsou potÅ™eba pro time travel (uvolÅˆuje tak mÃ­sto v ÃºloÅ¾iÅ¡ti).||
|**DACPAC**|Artefakt (soubor), do kterÃ©ho se kompilujÃ­ zmÄ›ny schÃ©matu Data Warehouse provedenÃ© vÂ **SQL Database Project**Â (VS Code) pro automatizovanÃ© nasazenÃ­.||
|**Direct Lake**|NovÃ½ reÅ¾im pÅ™ipojenÃ­ Power BI, kterÃ½ kombinuje rychlost Importu s aktuÃ¡lnostÃ­ Direct Query ÄtenÃ­m dat pÅ™Ã­mo z Delta souborÅ¯ v OneLake.||
|**Fallback**|AutomatickÃ¡ funkce v reÅ¾imuÂ **Direct Lake**, kdy se systÃ©m pÅ™epne na Direct Query, pokud narazÃ­ na nepodporovanou operaci (napÅ™. sloÅ¾itÃ½ DAX nebo View).||
