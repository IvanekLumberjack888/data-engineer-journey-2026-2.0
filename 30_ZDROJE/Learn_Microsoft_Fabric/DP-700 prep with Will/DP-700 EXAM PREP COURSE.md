# ğŸš€ Introduction

# DP-700 EXAM PREP COURSE | Video 1 of 11 (Ãšvod) â€“ Learn Microsoft Fabric with Will

**Tato lekce zahajuje novou sÃ©rii, kterÃ¡ tÄ› mÃ¡ pÅ™ipravit na DP-700 certifikaci Microsoft Fabric Data Engineer. NajdeÅ¡ zde podrobnÃ½ pÅ™ehled, co tÄ› na tÃ©to cestÄ› ÄekÃ¡ a proÄ mÃ¡ smysl do toho jÃ­t.**

---

## Struktura videa

- Ãšvod do sÃ©rie (0:00)
    
- ProÄ teÄ? Voucher na zkouÅ¡ku (1:05)
    
- ProÄ se snaÅ¾it o DP-700? (2:54)
    
- Co obsahuje DP-700 certifikaÄnÃ­ zkouÅ¡ka? (4:50)
    
- SrovnÃ¡nÃ­ DP-700 vs DP-600 (11:30)
    
- OficiÃ¡lnÃ­ zdroje ke studiu (12:25)
    
- PlÃ¡n celÃ© sÃ©rie na YouTube (14:00)
    
- PlÃ¡n DP-700 Bootcamp ve Fabric Dojo (14:20)
    
- ÄŒastÃ© dotazy k certifikaci (15:15)
    
- ZÃ¡vÄ›reÄnÃ© myÅ¡lenky (17:47)
    

---

## ProÄ jÃ­t do DP-700 a co to pro tebe znamenÃ¡?

- Od 14. ledna 2025 je DP-700 zkouÅ¡ka v ostrÃ©m provozu, vÄetnÄ› **slevovÃ©ho voucheru 50%** (po splnÄ›nÃ­ podmÃ­nek).
    
    - PodmÃ­nky pro voucher: buÄ DP-203 certifikace, nebo dokonÄenÃ­ Fabric learning path, pÅ™Ã­padnÄ› ÃºÄast na Å¾ivÃ©m nebo online DP-700 Å¡kolenÃ­.
        
    - Voucher platÃ­ pouze do 31.3. nebo do rozdÃ¡nÃ­ (20 000 ks).
        

## Co ti dÃ¡ DP-700 certifikace?

- Strukturu pro studium a uÄenÃ­.
    
- VyÅ¡Å¡Ã­ Å¡ance zÃ­skÃ¡nÃ­ prÃ¡ce, ale samotnÃ¡ certifikace nenÃ­ zÃ¡rukou zamÄ›stnÃ¡nÃ­.
    
- UplatnÄ›nÃ­ ve firemnÃ­ch konzultacÃ­ch, lepÅ¡Ã­ finanÄnÃ­ ohodnocenÃ­.
    
- Data engineering je zÃ¡kladem modernÃ­ho BI/AI rozhodovÃ¡nÃ­.
    
- PoÅ¾adavky na data inÅ¾enÃ½ry stoupajÃ­, plat je nadprÅ¯mÄ›rnÃ½.
    

---

## Jak vypadÃ¡ DP-700 zkouÅ¡ka?

- 50â€“60 otÃ¡zek, z toho cca 10 v case study.
    
- TÅ™i vyvÃ¡Å¾enÃ© oblasti (domÃ©ny):
    
    - Implementace a sprÃ¡va analytickÃ©ho Å™eÅ¡enÃ­
        
    - Ingest (naÄÃ­tÃ¡nÃ­) & transformace dat
        
    - Monitoring a optimalizace analytickÃ©ho Å™eÅ¡enÃ­
        

## PÅ™ehled domÃ©n

## 1. Implementace, sprÃ¡va a governance:

- NastavenÃ­ workspace (vÄetnÄ› sprÃ¡vy tenant).
    
- Version control, deployment pipelines.
    
- Access control: workspace, item, detailnÄ› (Å™Ã¡dkovÃ¡, objektovÃ¡, sloupcovÃ¡ bezpeÄnost, dynamic data masking).
    
- SprÃ¡va datovÃ© governance: certifikace, endorsement, sensitivity labels.
    
- Orchestrace: jakÃ© orchestration patterny, aktivity a postupy vyuÅ¾Ã­vat v praxi.
    

## 2. Ingest & Transformace:

- RÅ¯znÃ© typy ingestion (pipeline, data flow, notebook, event stream).
    
- RozhodovÃ¡nÃ­ â€kdy pouÅ¾Ã­t coâ€œ.
    
- PlnÃ© vs inkrementÃ¡lnÃ­ naÄÃ­tÃ¡nÃ­ â€“ znalost Spark SQL, PySpark, Delta package.
    
- PrÃ¡ce s datovÃ½mi ÃºloÅ¾iÅ¡ti: lakehouse, warehouse, eventhouse.
    
- Streaming data: zdroje (Azure Event Hubs, IoT Hub), transformace v eventhouse, analÃ½za pomocÃ­ KQL.
    
- NutnÃ¡ sluÅ¡nÃ¡ znalost TSQL, KQL, PySpark.
    
- DP-700 vyÅ¾aduje hlubÅ¡Ã­ porozumÄ›nÃ­ kÃ³du: nejen syntax, ale i rozhodovÃ¡nÃ­ â€proÄ nÄ›co pouÅ¾Ã­tâ€œ, dopady na vÃ½kon.
    

## 3. Monitoring & Optimalizace:

- Monitoring: lakehouse, warehouse query, event stream, pipeline.
    
- Error handling: debugovÃ¡nÃ­ PySpark jobÅ¯, pipeline runÅ¯.
    
- Optimalizace: napÅ™. tabulka v bronze vrstvÄ›, optimalizace medailon architektury, refaktorace KQL skriptÅ¯ â€” jak zrychlit kÃ³d a nastavenÃ­ v praxi.
    

---

## SrovnÃ¡nÃ­ DP-700 vs DP-600

|Vlastnost|DP-700|DP-600|
|---|---|---|
|HlubÅ¡Ã­ detail|Orchestrace, inkrementÃ¡lnÃ­ loading,|ZÃ¡klady orchestrace|
||eventhouse, streaming, hlubÅ¡Ã­ PySpark||
|Monitoring & optimalizace|DetailnÃ­, Å¡irÅ¡Ã­ rozsah|SpÃ­Å¡ zÃ¡kladnÃ­|
|Error handling|VÃ½raznÄ› pokroÄilejÅ¡Ã­|ZÃ¡klady|
|NovÃ© tÃ©mata|KQL, hlubÅ¡Ã­ PySpark, eventhouse|KQL, PySpark (po zmÄ›nÄ› 11/2024)|

---

## OficiÃ¡lnÃ­ zdroje ke studiu

- DP-700 Study Guide (studijnÃ­ prÅ¯vodce)
    
- Dokumentace Microsoft Fabric
    
- Exam Experience & Sandbox (pro ty, kdo jdou poprvÃ© na Microsoft certifikaci â€“ rÅ¯znÃ© typy otÃ¡zek v testu)
    
- SamostudijnÃ­ moduly (nutnÃ© pro voucher, ale nejsou dostateÄnÃ© na sloÅ¾enÃ­ zkouÅ¡ky â€” pouÅ¾ij jako start, ne hlavnÃ­ obsah)
    
- **YouTube sÃ©rie** a **Fabric Dojo**: mnoho tutoriÃ¡lÅ¯, Å¾ivÃ© sezenÃ­, Q&A, pÅ™Ã­klady â€hands-onâ€œ.
    

---

## DoporuÄenÃ½ zpÅ¯sob pÅ™Ã­pravy

- Kombinovat studijnÃ­ pÅ™Ã­ruÄku, dokumentaci, YouTube sÃ©rii, hands-on tutoriÃ¡ly.
    
- AktivnÄ› se ÃºÄastnit diskuzÃ­, Å¾ivÃ½ch lekcÃ­ ve Fabric Dojo.
    
- OvÄ›Å™ovat si znalosti v praxi, klÃ¡st dÅ¯raz na vzÃ¡jemnÃ© propojovÃ¡nÃ­ sluÅ¾eb Fabric.
    
- ÄŒÃ­m vÃ­ce praktickÃ½ch projektÅ¯ v poslednÃ­m roce, tÃ­m kratÅ¡Ã­ pÅ™Ã­prava (1â€“3 mÄ›sÃ­ce), zaÄÃ¡teÄnÃ­ci 3â€“6+ mÄ›sÃ­cÅ¯.
    

---

## ÄŒastÃ© otÃ¡zky

- **Jak poznÃ¡m, Å¾e jsem pÅ™ipraven/a?**  
    ZatÃ­m nejsou k dispozici oficiÃ¡lnÃ­ practice testy. Sleduj videa, dokumentaci, testuj v praxi. SÃ¡m poznÃ¡Å¡, zda tomu rozumÃ­Å¡ do hloubky.
    
- **StaÄÃ­ tento kurz ke zkouÅ¡ce?**  
    Kurz je â€hyperkondenzovanÃ½â€œâ€“ pouÅ¾Ã­vaj takÃ© dokumentaci, studuj rÅ¯znÃ© pÅ™Ã­stupy a vysvÄ›tlenÃ­ od jinÃ½ch profesionÃ¡lÅ¯.
    

---

## ZÃ¡vÄ›reÄnÃ© tipy

- Sleduj dalÅ¡Ã­ videa v sÃ©rii.
    
- PÅ™ihlas se do Fabric Dojo pro dalÅ¡Ã­ podporu a Q&A.
    
- Kombinuj zdroje a hlavnÄ› prakticky testuj zÃ­skanÃ© znalosti.
    
- SprÃ¡vnÃ¡ pÅ™Ã­prava, time management a zkuÅ¡enost se strukturou Microsoft certifikacÃ­ vÃ½raznÄ› zvyÅ¡ujÃ­ Å¡anci uspÄ›t.
    

---

**Odkazy a dalÅ¡Ã­ obsah**

- Skool.com/FabricDojo â€“ placenÃ¡ komunita, Å¾ivÃ© lekce, hands-on tutoriÃ¡ly
    
- YouTube Channel: Learn Microsoft Fabric with Will
    
- DP-700 study guide, online dokumentace, practice exam sandbox
    

---

_Tento markdown je podrobnÃ½m pÅ™ehledem z ÃºvodnÃ­ho videa DP-700 sÃ©rie. HodÃ­ se uloÅ¾it jako poznÃ¡mky nebo podklad pro vlastnÃ­ studium._[youtube](https://www.youtube.com/watch?v=XECqSfKmtCk)â€‹

1. [https://www.youtube.com/watch?v=XECqSfKmtCk](https://www.youtube.com/watch?v=XECqSfKmtCk)

---
---

# ğŸš€ Workspace settings

# Workspace Settings v Microsoft Fabric | DP-700 EXAM PREP (Video 2/11)

**TÃ©mata videa na zÃ¡kladÄ› timeline:**

- Spark Settings a tvorba vlastnÃ­ch Spark poolÅ¯
    
- Domains
    
- OneLake & OneLake File Explorer
    
- Shortcuts & Shortcut Caching
    
- NastavenÃ­ pro Apache Airflow Job
    

---

## 1. Spark Settings

**Starter Pool (vÃ½chozÃ­ Spark cluster):**

- **RychlÃ½ start:** Spark cluster je dostupnÃ½ neustÃ¡le (start pod 10 sekund), dokud se nespustÃ­ kÃ³d, neplatÃ­Å¡ nic navÃ­c.
    
- **AutoÅ¡kÃ¡lovÃ¡nÃ­:** 1â€“10 uzlÅ¯ podle pouÅ¾itÃ© SKU, dynamickÃ¡ alokace executorÅ¯ (Java VM prochÃ¡zejÃ­cÃ­ data v partition).
    
- **DistribuovanÃ© vÃ½poÄty:** Å kÃ¡lovatelnost pÅ™es vÃ­ce uzlÅ¯, paralelismus pÅ™es vÃ­ce executorÅ¯.
    
- **Limity starter poolu:**
    
    - **Velikost dat:** Nad urÄitou velikost uÅ¾ starter pool nemusÃ­ staÄit, je vhodnÃ© vytvoÅ™it custom pool.
        
    - **Konkurence:** VÄ›tÅ¡Ã­ poÄet uÅ¾ivatelÅ¯/jobÅ¯ znamenÃ¡ nutnost custom poolu.
        
    - **VysokÃ¡ variabilita jobÅ¯:** RÅ¯znÄ› nÃ¡roÄnÃ© Ãºlohy â€“ rozdÄ›lit do vÃ­ce custom poolÅ¯.
        
    - **SpecifickÃ¡ prÃ¡ce:** Data scientist, ML training â€“ vhodnÃ© pouÅ¾Ã­vat custom spark pool.
        

**Custom Spark Pool:**

- V workspace settings lze kromÄ› starter poolu vytvoÅ™it vlastnÃ­ pool (zmÄ›na node size, autoscale, executor range).
    
- VlastnÃ­ pool zpomalÃ­ startup na nÄ›kolik minut (vÃ­ce jako klasickÃ½ Spark).
    
- Po zapnutÃ­ â€manage private endpointsâ€œ ve Fabric nelze pouÅ¾Ã­vat starter pool v tenantovi.
    

**NastavenÃ­ poolÅ¯:**

- Workspace -> Spark settings -> vytvoÅ™it pool, nastavit parametry.
    
- **Environment:** speciÃ¡lnÃ­ Fabric asset, kde lze nastavit Spark konfigurace a instalovat Python knihovny.
    
    - Environment lze pouÅ¾Ã­t jako default workspace environment nebo i pro individuÃ¡lnÃ­ job/notebook.
        
    - VÃ½hoda: git integrace, moÅ¾nost verzovÃ¡nÃ­ v kontrolnÃ­m systÃ©mu.
        
    - NevÃ½hoda: nelze pouÅ¾Ã­t napÅ™Ã­Ä workspace, musÃ­ se duplikovat.
        

**Job-level konfigurace:**

- Lze vytvoÅ™it vÃ­ce environmentÅ¯ a pÅ™iÅ™adit k rÅ¯znÃ½m notebookÅ¯m/jobÅ¯m.
    
- OptimÃ¡lnÃ­ konfigurace pro rÅ¯znÃ© Ãºkoly.
    

---

## 2. DalÅ¡Ã­ Spark settingy workspace:

- **Reserve maximum cores:** MÅ¯Å¾eÅ¡ rezervovat maximÃ¡lnÃ­ poÄet jader pro job (â€pessimistickÃ© plÃ¡novÃ¡nÃ­â€œ â€“ zvyÅ¡uje stabilitu, omezuje dostupnost zdrojÅ¯ pro jinÃ© joby).
    
- **High concurrency:** PovolenÃ­ vÃ­cenÃ¡sobnÃ½ch Spark session pro jednoho uÅ¾ivatele nebo pipeline (tagovÃ¡nÃ­ session).
    
- **Capacity-level settings:** Capacity admin mÅ¯Å¾e povolit Äi zakÃ¡zat tvorbu custom poolÅ¯/workspaces, pÅ™Ã­padnÄ› i starter pool.
    

---

## 3. Domains (DomÃ©ny ve Fabric)

- **LogickÃ© seskupenÃ­ dat:** MapovÃ¡nÃ­ firemnÃ­ organizaÄnÃ­ struktury na Fabric â€” domÃ©na = skupina workspace (napÅ™. region, oddÄ›lenÃ­).
    
- **Role:**
    
    - **Fabric admin:** SprÃ¡va (tvorba/mazÃ¡nÃ­) domÃ©n, jmenovÃ¡nÃ­ domain adminÅ¯, pÅ™ehled vÅ¡ech domÃ©n.
        
    - **Domain admin:** SprÃ¡va a pÅ™iÅ™azovÃ¡nÃ­ workspace do domÃ©ny, jmenovÃ¡nÃ­ domain contributorÅ¯.
        
    - **Domain contributor:** Workspace admin â€” mÅ¯Å¾e workspace pÅ™iÅ™adit do domÃ©ny.
        
- **DelegovanÃ© nastavenÃ­ tenant:** DefaultnÃ­ sensitivity label a endorsement/certifikace lze povolit na Ãºrovni domÃ©ny.
    

---

## 4. OneLake & OneLake File Explorer

- VeÅ¡kerÃ¡ data z Fabric (lakehouse, warehouse) lze spravovat v centrÃ¡lnÃ­m cloudovÃ©m uloÅ¾iÅ¡ti OneLake.
    
- **File Explorer:** PodobnÄ› jako OneDrive klient, umoÅ¾Åˆuje stÃ¡hnout a prohlÃ­Å¾et obsah OneLake (jenom Delta tabulky z lakehouse/warehouse).
    
    - KQL databÃ¡ze a Power BI semantic modely standardnÄ› nejsou viditelnÃ© v File Explorer aÅ¾ po aktivaci â€OneLake integrationâ€œ v nastavenÃ­ (nutnÃ©, aby byly v reÅ¾imu import, ne direct).
        
- **OneLake integration:** Pro novÃ© tabulky v KQL db a Power BI semantic modelu; existujÃ­cÃ­ tabulky se backfillujÃ­ jen s novou funkcÃ­.
    

---

## 5. Shortcuts & Shortcut Caching

- **Shortcuts:** ReferencovÃ¡nÃ­ externÃ­ch dat (S3, Google Cloud Storage, ADLS Gen2).
    
- **Shortcut caching:** SnÃ­Å¾enÃ­ nÃ¡kladÅ¯ na egress u cloud providerÅ¯ uklÃ¡dÃ¡nÃ­m dat do Azure (caching).
    
    - Pravidla: max 1 GB soubor, retention 1â€“28 dnÅ¯ (po kaÅ¾dÃ©m pÅ™Ã­stupu se prodlouÅ¾Ã­).
        
    - Po 24+ hodinÃ¡ch (nebo nastavenÃ© dobÄ›) neaktivace je cache odstranÄ›na.
        

---

## 6. Apache Airflow Pools

- **OrchestrÃ¡tor:** SlouÅ¾Ã­ ke spouÅ¡tÄ›nÃ­ DAGÅ¯ (workflow, pipeline) â€” Fabric umoÅ¾Åˆuje Å™Ã­dit joby pÅ™es pool (nastavenÃ­ node size, autoscale).
    
- **NENÃ hlavnÃ­m tÃ©matem DP-700**, ale nastavenÃ­ je nutnÃ¡ znÃ¡t.
    

---

## DoporuÄenÃ­

- Pro praktickÃ½ trÃ©nink pouÅ¾Ã­vat hands-on tutoriÃ¡ly a pÅ™Ã­padnÄ› bootcampy.
    
- Kombinovat zdroje: video, dokumentace, Å¾ivÃ© sessions.
    
- SprÃ¡vnÄ› konfigurovat Spark pooly podle reÃ¡lnÃ½ch datovÃ½ch potÅ™eb, nejen podle defaultÅ¯.
    

---

_Tento markdown ti poskytne detailnÃ­ zÃ¡pis k Workspace Settings, Spark poolÅ¯m, domÃ©nÃ¡m, OneLake, shortcutÅ¯m a Airflow pools v Microsoft Fabric pro pÅ™Ã­pravu na DP-700 zkouÅ¡ku._[youtube](https://www.youtube.com/watch?v=-64AAqSavfo)â€‹

1. [https://www.youtube.com/watch?v=-64AAqSavfo](https://www.youtube.com/watch?v=-64AAqSavfo)

---
---

# ğŸš€ CI/CD

# CI/CD v Microsoft Fabric | DP-700 EXAM PREP (Video 3/11)

**TÃ©mata videa dle timeline:**

- Version Control (Git integrace)
    
- Deployment Pipelines
    
- Database Projects
    

---

## 1. Version Control (Git integrace)

- **MoÅ¾nosti:** Lze propojit workspace s Azure DevOps nebo GitHub repozitÃ¡Å™em.
    
- **NastavenÃ­:**
    
    - Na Ãºrovni tenant admina je nutnÃ© povolit integraci s Gitem v admin portÃ¡lu Fabric (napÅ™Ã­klad povolit synchronizaci workspace items s Gitem, mezinÃ¡rodnÃ­ repozitÃ¡Å™e, integrace s GitHubem).
        
    - Na stranÄ› Azure DevOps: je tÅ™eba nastavit organizaci, projekt, repozitÃ¡Å™ a pÅ™idat sprÃ¡vnÃ© uÅ¾ivatele (musÃ­ mÃ­t oprÃ¡vnÄ›nÃ­).
        
    - Konektivita workspace: v nastavenÃ­ workspace se definuje organizace, projekt, repozitÃ¡Å™, branch (pÅ™Ã­padnÄ› sloÅ¾ka/multirepo strategie v Gitu).
        
    - GitHub pÅ™ipojenÃ­ vyÅ¾aduje osobnÃ­ access token.
        
- **Role a oprÃ¡vnÄ›nÃ­:**
    
    - _Admin_: mÅ¯Å¾e pÅ™ipojit workspace, mÄ›nit branch pro vÅ¡echny uÅ¾ivatele, spravovat spojenÃ­.
        
    - _Member/Contributor_: mohou commitovat a pullovat zmÄ›ny, mohou vytvÃ¡Å™et novÃ© workspaces (pokud majÃ­ povoleno).
        
    - _Viewer_: pouze ÄtenÃ­, nemÃ¡ prÃ¡va na git operace.
        
- **Co se verzionuje?**
    
    - **NE verzionuje se:** Å¾Ã¡dnÃ¡ zdrojovÃ¡ data (tabulky, soubory v lakehouse/warehouse, schÃ©mata dat), plÃ¡novaÄe refreshÅ¯.
        
    - **Ano:** struktura data warehouse (create table/view), kÃ³d notebookÅ¯, pipelines atd.
        
    - Pokud nenÃ­ nÄ›co ve version control, nenÃ­ to ani deployovÃ¡no (napÅ™Ã­klad refresh schedule je tÅ™eba nastavit manuÃ¡lnÄ› nebo pÅ™es API).
        

---

## 2. Deployment Pipelines

- **Princip:** UmoÅ¾Åˆuje posouvat poloÅ¾ky mezi rÅ¯znÃ½mi prostÅ™edÃ­mi (bÄ›Å¾nÄ› Dev â†’ Test â†’ Prod, lze nastavit aÅ¾ 10 stages).
    
- **PraktickÃ© pouÅ¾itÃ­:** KopÃ­rovÃ¡nÃ­ notebookÅ¯, pipelines, semantic models atd. mezi workspaces â€“ testovÃ¡nÃ­ a nasazenÃ­.
    
- **Proces mÅ¯Å¾e bÃ½t manuÃ¡lnÃ­ nebo automatizovanÃ½** (API, PowerShell, Azure Pipelines).
    
- **DÅ¯leÅ¾itÃ© koncepty:**
    
    - **Deployment rules:** Lze mÄ›nit propojenÃ¡ data mezi prostÅ™edÃ­mi (napÅ™Ã­klad zmÄ›nit cÃ­lovÃ½ Lakehouse ve vyÅ¡Å¡Ã­m prostÅ™edÃ­).
        
    - **Item pairing:** PÅ™i nasazenÃ­ se propojÃ­ poloÅ¾ky mezi prostÅ™edÃ­mi (dokonce i pÅ™i zmÄ›nÄ› nÃ¡zvu zÅ¯stÃ¡vÃ¡ logickÃ© propojenÃ­).
        
    - **Coverage nenÃ­ 100%:** NejlepÅ¡Ã­ pokrytÃ­ je pro semantic models, pipelines, notebooks.
        

---

## 3. Database Projects

- **Co to je:** SQL Database Project pÅ™edstavuje zpÅ¯sob, jak verzovat a automatizovanÄ› nasazovat strukturu Fabric Data Warehouse.
    
- **Proces:**
    
    - _Workspace s git integracÃ­_: Po commitu database warehouse do Gitu vznikne SQL project (soubor .sql s CREATE TABLE atd.).
        
    - _Pro prÃ¡ci lokÃ¡lnÄ›_: KlonovÃ¡nÃ­ repozitÃ¡Å™e, otevÅ™enÃ­ v VS Code (rozÅ¡Ã­Å™enÃ­ SQL Database Projects).
        
    - _Editace schÃ©matu_: PÅ™idÃ¡vÃ¡nÃ­ tabulek, zmÄ›ny struktury.
        
    - _Build_: VznikÃ¡ DACPAC artifact (reprezentace schÃ©matu, bez dat).
        
    - _Deploy_: PomocÃ­ connection stringu lze nasadit DACPAC zpÄ›t do Fabric (a to i plnÄ› automatizovanÄ› â€“ napÅ™. pomocÃ­ Azure Pipelines).
        
- **VÃ½hoda:** Lze automatizovat celÃ½ CI/CD proces schÃ©matu data warehouse, vÄetnÄ› buildÅ¯, testÅ¯, release steps.
    

---

## ShrnutÃ­: KlÃ­ÄovÃ© poznatky

- SprÃ¡vnÄ› nastavenÃ¡ CI/CD pipeline umoÅ¾Åˆuje:
    
    - verzovÃ¡nÃ­ kÃ³du a struktury datovÃ½ch objektÅ¯ v Gitu (Azure DevOps, GitHub)
        
    - automatizovanÃ©/manaulnÃ­ nasazovÃ¡nÃ­ mezi prostÅ™edÃ­mi pÅ™es deployment pipelines
        
    - deklarativnÃ­ sprÃ¡vu datovÃ½ch warehouse pÅ™es SQL projects (infrastruktura jako kÃ³d)
        
- VÅ¾dy si dej pozor, co je a nenÃ­ ve version control â€“ pouze to, co je verzovÃ¡no, je opravdu automatizovatelnÄ› nasaditelnÃ©!
    

---

_DoporuÄenÃ­: VyzkouÅ¡ej si prakticky Git integraci, deployment pipelines i SQL database projects ve vlastnÃ­m test workspace s Azure DevOps nebo GitHubem._

1. [https://www.youtube.com/watch?v=JhTl_fDZsE0](https://www.youtube.com/watch?v=JhTl_fDZsE0)

---
---

# ğŸš€ Security & Governance

# Konfigurace Å™Ã­zenÃ­ pÅ™Ã­stupu v Microsoft Fabric (DP-700)

**Video:** [Configuring Access Control in Microsoft Fabric | DP-700 EXAM PREP (Video 4 of 11)]  
**Autor:** Learn Microsoft Fabric with Will  
**DÃ©lka:** 28 minut  
**Obsah videa:** BezpeÄnost, sprÃ¡va pÅ™Ã­stupu a governance v Microsoft Fabric

---

## 1. ÃšrovnÄ› Å™Ã­zenÃ­ pÅ™Ã­stupu

Microsoft Fabric umoÅ¾Åˆuje nastavovat pÅ™Ã­stup na nÄ›kolika ÃºrovnÃ­ch:

- **ÃšroveÅˆ workspace** â€“ pÅ™Ã­stup ke vÅ¡em objektÅ¯m v workspace.
    
- **ÃšroveÅˆ poloÅ¾ky (item)** â€“ pÅ™Ã­stup pouze ke konkrÃ©tnÃ­ poloÅ¾ce (napÅ™. datovÃ½ sklad nebo lakehouse).
    
- **ÃšroveÅˆ objektu nebo souboru** â€“ pÅ™Ã­stup ke konkrÃ©tnÃ­mu objektu nebo souboru.
    
- **GranulÃ¡rnÃ­ ÃºroveÅˆ** â€“ Å™Ã¡dek, sloupec, tabulka, soubor.
    

Princip **nejmenÅ¡Ã­ch prÃ¡v ("least privilege")**: dÃ¡vejte vÅ¾dy jen minimÃ¡lnÃ­ nutnÃ¡ prÃ¡va.

---

## 2. Workspace-level Access Control

Role ve workspace:

|Role|PrÃ¡va|
|---|---|
|Admin|VÅ¡echna prÃ¡va.|
|Member|VÄ›tÅ¡ina prÃ¡v, nemÅ¯Å¾e pÅ™idÃ¡vat adminy ani mazat workspace.|
|Contributor|ZÃ¡pis na Ãºrovni poloÅ¾ek, nemÅ¯Å¾e sdÃ­let ani mÄ›nit nÄ›kterÃ© poloÅ¾ky.|
|Viewer|Pouze prohlÃ­Å¾enÃ­ dat (pÅ™es SQL endpoint), nemÅ¯Å¾e spouÅ¡tÄ›t pipeliny.|

Workspace sdÃ­lÃ­te pÅ™es **Manage Access** â†’ definujete uÅ¾ivatele/skupinu a pÅ™iÅ™adÃ­te roli.

---

## 3. Item-level Access Control

- UÅ¾ivatel nebo skupina dostane pÅ™Ã­stup jen ke konkrÃ©tnÃ­ poloÅ¾ce (napÅ™. jen k Data Warehousu).
    
- UÅ¾ivatel nevidÃ­ workspace samotnÃ½, jen item pÅ™es **OneLake Catalog**.
    
- Bez dalÅ¡Ã­ch zaÅ¡krtnutÃ½ch prÃ¡v = pouze â€readâ€œ â€“ tedy pÅ™Ã­stup k samotnÃ© skladbÄ›, ne datÅ¯m v tabulkÃ¡ch.
    

**DalÅ¡Ã­ volby pÅ™i sdÃ­lenÃ­:**

- Read all data using SQL â€“ ÄtenÃ­ vÅ¡ech dat pÅ™es T-SQL.
    
- Read all OneLake data â€“ ÄtenÃ­ pÅ™es Spark, pipeliny, externÃ­ nÃ¡stroje.
    
- Build report on semantic model â€“ tvorba reportÅ¯.
    

---

## 4. GranulÃ¡rnÃ­ Å™Ã­zenÃ­ pÅ™Ã­stupu

KaÅ¾dÃ½ typ engine (Lakehouse, Data Warehouse) mÃ¡ vlastnÃ­ moÅ¾nosti:

|Typ|Metoda|Endpoint|
|---|---|---|
|ObjektovÃ©|OneLake Data Access / Grant Select|Lakehouse/Spark/T-SQL|
|Å˜Ã¡dkovÃ© (RLS)|Security Policy + TVF|T-SQL (DW/Lakehouse)|
|SloupcovÃ©|Grant Select (columns)|T-SQL|

**Pozor:** VyÅ¡Å¡Ã­ ÃºroveÅˆ pÅ™Ã­stupu (napÅ™. workspace Viewer) pÅ™eplnÃ­ niÅ¾Å¡Ã­ nastavenÃ­.

---

## 5. Implementace Row Level Security (RLS)

## Postup (T-SQL):

1. VytvoÅ™te schema `security` (volitelnÃ©)
    
2. VytvoÅ™te Table Valued Function (TVF), kterÃ¡ filtruje Å™Ã¡dky podle uÅ¾ivatele
    
3. Definujte Security Policy, kterÃ¡ tuto funkci aplikuje na konkrÃ©tnÃ­ tabulku
    

sql

`CREATE FUNCTION security.FilterRowForUser(@salesRep NVARCHAR) RETURNS TABLE AS RETURN SELECT * FROM Sales.Orders WHERE SalesRep = USER_NAME();`

sql

`CREATE SECURITY POLICY SalesOrderFilter ADD FILTER PREDICATE security.FilterRowForUser(SalesRep) ON Sales.Orders WITH (STATE = ON);`

---

## 6. ObjektovÃ¡/sloupcovÃ¡ bezpeÄnost

- **Grant SELECT na konkrÃ©tnÃ­ tabulku nebo sloupce**
    
- SdÃ­lÃ­te s SQL rolÃ­ nebo konkrÃ©tnÃ­m uÅ¾ivatelem (entra ID)
    
- OpÄ›t â€“ bez workspace prÃ¡v
    

sql

`GRANT SELECT ON Sales.Orders TO SalesReps; GRANT SELECT ON Sales.CustomerDetails (CustomerID, Name) TO SalesReps;`

---

## 7. OneLake Data Access (Lakehouse)

- Role-based pÅ™Ã­stup k tabulkÃ¡m/souborÅ¯m
    
- V Lakehouse vytvoÅ™Ã­te roli, pÅ™iÅ™adÃ­te tabulky/soubory, pÅ™idÃ¡te Äleny (ruÄnÄ› nebo podle existujÃ­cÃ­ch prÃ¡v)
    
- Po aktivaci funkce uÅ¾ ji nelze vrÃ¡tit zpÄ›t
    

---

## 8. DynamickÃ© maskovÃ¡nÃ­ dat (Dynamic Data Masking)

ZakrytÃ­ vybranÃ½ch dat pro vybranÃ© uÅ¾ivatele â€“ data zÅ¯stÃ¡vajÃ­ nemÄ›nÄ›na v pozadÃ­.

PouÅ¾itÃ­ v T-SQL (pÅ™i vytvÃ¡Å™enÃ­ Äi ÃºpravÄ› tabulky):

sql

`CREATE TABLE EmployeeData (     FirstName NVARCHAR(100) MASKED WITH (FUNCTION = 'default()') ); ALTER TABLE EmployeeData ALTER COLUMN Email ADD MASKED WITH (FUNCTION = 'email()'); ALTER TABLE EmployeeData ALTER COLUMN Salary ADD MASKED WITH (FUNCTION = 'random(50000, 100000)'); ALTER TABLE EmployeeData ALTER COLUMN Phone ADD MASKED WITH (FUNCTION = 'partial(4,"X",0)');`

Typy masek:

- **default** â€“ univerzÃ¡lnÃ­ maska
    
- **email** â€“ maskuje vÅ¡e kromÄ› prvnÃ­ho znaku a ÄÃ¡sti po @
    
- **random** â€“ generuje nÃ¡hodnÃ© ÄÃ­slo (napÅ™. pro plat)
    
- **partial** â€“ viditelnÃ½ prefix/padding/suffix
    

**Pozor:** MaskovÃ¡nÃ­ nenÃ­ bezpeÄnostnÃ­ opatÅ™enÃ­ â€“ lze obejÃ­t chytrÃ½mi dotazy.

---

## 9. Data Governance (oznaÄovÃ¡nÃ­ a endorsement)

- **Sensitivity label:** Ochrana informacÃ­, spravovÃ¡no v Purview, nastavitelnÃ© na poloÅ¾kÃ¡ch v topbar/settings
    
- **Endorsement:**
    
    - Promoted â€“ pÅ™ipravenÃ© k sdÃ­lenÃ­/reuse
        
    - Certified â€“ splÅˆuje firemnÃ­ standardy (pouze urÄenÃ¡ skupina mÅ¯Å¾e certifikovat)
        
    - Master data â€“ core datovÃ½ zdroj (jen admin skupina)
        

---

## KlÃ­ÄovÃ© frÃ¡ze pro zkouÅ¡ku DP-700

- **Certified:** SplÅˆuje standardy kvality organizace
    
- **Master data:** HlavnÃ­ zdroj dat organizace
    
- **Promoted:** PÅ™ipraveno k sdÃ­lenÃ­
    

---

> DalÅ¡Ã­ DP-700 studijnÃ­ materiÃ¡ly najdeÅ¡ na fabricdojo nebo playlistu Learn Microsoft Fabric.[youtube](https://www.youtube.com/watch?v=pFvVAZCyYhc)â€‹

---

1. [https://www.youtube.com/watch?v=pFvVAZCyYhc](https://www.youtube.com/watch?v=pFvVAZCyYhc)

---
---

# ğŸš€ Orchestration

# Orchestration in Microsoft Fabric | DP-700 (Video 5/11) [youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹

## TÃ©mata videa podle sylabu DP-700

- Orchestrate processes: kdy pouÅ¾Ã­t pipeline vs. notebook, orchestraÄnÃ­ patterny, parametry, dynamickÃ© vÃ½razy.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- Triggery: plÃ¡novanÃ© a event-based, vÄetnÄ› Real-Time Hub scÃ©nÃ¡Å™Å¯.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- Ingest a transform batch data: ingest pomocÃ­ pipelines (Copy Data, metadataâ€‘driven pÅ™Ã­stup).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

---

## 1. Data Pipelines â€“ zÃ¡kladnÃ­ koncepty

## Co je data pipeline ve Fabricu

- Data pipeline je orchestrÃ¡tor, kterÃ½ spouÅ¡tÃ­ rÅ¯znÃ© Fabric assety (notebooky, Spark jobs, KQL DB, data warehouses, semantic model refresh) i externÃ­ sluÅ¾by (Azure Functions, Databricks, REST/HTTP, webhooks).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- Pipelines jsou postavenÃ© jako DAG (directed acyclic graph) â€“ propojenÃ© aktivity s definovanÃ½mi zÃ¡vislostmi a podmÃ­nkami, jak na sebe navazujÃ­.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

## Aktivity v pipeline

TypickÃ© aktivity, kterÃ© pro DP-700 potÅ™ebujeÅ¡ znÃ¡t:[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹

- Copy Data â€“ hlavnÃ­ nÃ¡stroj pro ingest dat.
    
- Notebook activity â€“ spuÅ¡tÄ›nÃ­ Spark notebooku z pipeline.
    
- Dataflow Gen2 activity â€“ spuÅ¡tÄ›nÃ­ dataflow.
    
- Script activity â€“ vykonÃ¡nÃ­ T-SQL nebo jinÃ©ho skriptu.
    
- Semantic model refresh activity â€“ Å™Ã­zenÃ½ refresh modelu.
    
- Invoke pipeline â€“ volÃ¡nÃ­ jinÃ© pipeline (parentâ€“child pattern).
    
- Web/REST/HTTP aktivity â€“ volÃ¡nÃ­ API a web endpointÅ¯.
    
- Azure Activities â€“ volÃ¡nÃ­ Azure Functions, Databricks notebookÅ¯ a dalÅ¡Ã­ch sluÅ¾eb.
    
- NotifikaÄnÃ­ aktivity â€“ Office 365 a Teams pro alerty pÅ™i ÃºspÄ›chu/chybÄ›.
    

---

## 2. Copy Data â€“ ingesce dat

## Zdroje pro Copy Data

Copy Data aktivita obsluhuje vÄ›tÅ¡inu scÃ©nÃ¡Å™Å¯ batch ingesce:[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹

- Azure zdroje (Blob, Data Lake, Azure SQL, Synapse, atd.).
    
- SQL Server onâ€‘prem pÅ™es onâ€‘prem data gateway (dÅ¯leÅ¾itÃ© pro hybridnÃ­ scÃ©nÃ¡Å™e).
    
- REST konektor â€“ GET/POST na API, podporuje zÃ¡kladnÃ­ pagination (u sloÅ¾itÄ›jÅ¡Ã­ch API je lepÅ¡Ã­ pÅ™ejÃ­t do notebooku).
    
- HTTP konektor â€“ staÅ¾enÃ­ dat z otevÅ™enÃ½ch webovÃ½ch endpointÅ¯.
    

## CÃ­le pro Copy Data

- Lakehouse (files area) pro souborovÃ¡ data.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- Lakehouse/warehouse tabulky pro tabulkovÃ¡ data.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- ExternÃ­ cÃ­le â€“ napÅ™. Azure SQL Database (Fabric orchestruje ETL, ale cÃ­l je mimo Fabric).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

## JednoduchÃ½ scÃ©nÃ¡Å™

- NejzÃ¡kladnÄ›jÅ¡Ã­ pipeline mÅ¯Å¾e obsahovat jedinou Copy Data aktivitu: vezmi data ze zdroje a uloÅ¾ do Fabricu.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- V UI nastavÃ­Å¡ pÅ™ipojenÃ­, relativnÃ­ URL/soubor, formÃ¡t dat (CSV/JSON/Parquet atd.), mapovÃ¡nÃ­ schÃ©matu a cÃ­lovou destinaci.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

---

## 3. PropojovÃ¡nÃ­ aktivit a Å™Ã­zenÃ­ toku

## PodmÃ­nÄ›nÃ© napojenÃ­ aktivit

KaÅ¾dÃ© propojenÃ­ mezi aktivitami mÃ¡ podmÃ­nku, kdy se dalÅ¡Ã­ krok spustÃ­:[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹

- On Success â€“ bÄ›Å¾nÃ½ scÃ©nÃ¡Å™; dalÅ¡Ã­ aktivita se spustÃ­ jen pÅ™i ÃºspÄ›chu.
    
- On Fail â€“ dalÅ¡Ã­ krok se spustÃ­ jen pÅ™i selhÃ¡nÃ­ (napÅ™. notifikace, kompenzaÄnÃ­ job).
    
- On Completion â€“ spustÃ­ se vÅ¾dy (bez ohledu na vÃ½sledek); vhodnÃ© pro cleanup.
    
- On Skip â€“ dalÅ¡Ã­ aktivita se spustÃ­ pouze, pokud pÅ™edchozÃ­ byla pÅ™eskoÄena.
    

PÅ™Ã­klad miniâ€‘DAGu:[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹

- Copy Data (ingesce) â†’ On Success â†’ Script/Transform â†’ On Success â†’ Semantic model refresh.
    
- Semantic model refresh â†’ On Fail â†’ Odeslat Teams/O365 notifikaci.
    

## AktivnÃ­ vs. neaktivnÃ­ aktivity

- Aktivitu lze pÅ™epnout na â€Inactiveâ€œ (deaktivovat), takÅ¾e se pÅ™i bÄ›hu pipeline pÅ™eskoÄÃ­.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- V UI je zaÅ¡edlÃ¡ a ve vÃ½sledcÃ­ch bÄ›hu uvidÃ­Å¡ status â€Inactiveâ€œ, coÅ¾ je ideÃ¡lnÃ­ pÅ™i ladÄ›nÃ­ dlouhÃ½ch pipeline (doÄasnÄ› vypneÅ¡ ÄÃ¡st grafu).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

---

## 4. Metadataâ€‘driven pipelines (bez hardâ€‘codu)

## ProblÃ©m hardâ€‘codu

- Pokud v Copy Data zadÃ¡Å¡ natvrdo relativnÃ­ URL/tabulku, pipeline umÃ­ typicky jen jeden dataset (napÅ™. jednu CSV nebo jednu tabulku).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- V praxi chceÅ¡ Äasto zpracovat desÃ­tky tabulek/endpointÅ¯ z jednoho zdroje bez psanÃ­ 25 rÅ¯znÃ½ch pipeline.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

## Metadata a jejich umÃ­stÄ›nÃ­

Metadata mÅ¯Å¾eÅ¡ drÅ¾et:[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹

- V tabulce ve Fabric Warehouse/Fabric SQL.
    
- V externÃ­ SQL databÃ¡zi.
    
- V souborech (JSON/CSV) v OneLake.
    

TypickÃ© sloupce metadat: nÃ¡zev zdrojovÃ© tabulky, schÃ©ma, cÃ­lovÃ¡ tabulka, relativnÃ­ URL, typ souboru, pÅ™Ã­padnÄ› dalÅ¡Ã­ parametry.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹

## Pattern: Lookup + ForEach + Copy Data

1. Lookup/Script aktivita naÄte metadata (napÅ™. 25 Å™Ã¡dkÅ¯ = 25 tabulek).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
2. VÃ½sledek pÅ™edÃ¡Å¡ do ForEach aktivity.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
3. UvnitÅ™ ForEach je jedna Copy Data aktivita, kde Source/Relative URL a cÃ­lovÃ© nÃ¡zvy bereÅ¡ dynamicky z `item()` (napÅ™. `@item().SourcePath`, `@item().DestinationTable`).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

VÃ½hody:[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹

- PÅ™idÃ¡nÃ­ dalÅ¡Ã­ tabulky = pÅ™idÃ¡Å¡ Å™Ã¡dek do metadata tabulky, pipeline se nemÄ›nÃ­.
    
- ÃšdrÅ¾ba je pouze v â€instrukÄnÃ­â€œ metadata tabulce, logika orchestraci zÅ¯stÃ¡vÃ¡ stabilnÃ­.
    

---

## 5. Parentâ€“child architektura pipelines

## Kdy to pouÅ¾Ã­t

- KdyÅ¾ potÅ™ebujeÅ¡ v rÃ¡mci ForEach pro kaÅ¾dou tabulku provÃ©st komplexnÄ›jÅ¡Ã­ workflow: ingest â†’ transform (silver) â†’ gold â†’ semantic model refresh, pÅ™Ã­padnÄ› dalÅ¡Ã­ skripty.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- NechceÅ¡ mÃ­t obrovskou pipeline se stovkami propojenÃ½ch aktivit.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

## Parent pipeline

- NaÄte metadata (Lookup/Script).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- ForEach pÅ™es jednotlivÃ© Å™Ã¡dky metadat.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- UvnitÅ™ ForEach pouÅ¾ije Invoke pipeline aktivitu (doporuÄenÃ¡ â€Legacyâ€œ varianta, pokud potÅ™ebujeÅ¡ vracet hodnoty z child).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- V Invoke pipeline nastavÃ­Å¡ parametry, kterÃ© pÅ™edÃ¡Å¡ child pipeline (napÅ™. `SourceDirectory`, `SourceFileName`, `DestinationTableName`, `ExpectedColumnNames`).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

## Child pipeline

- MÃ¡ definovanÃ© pipeline parameters, na kterÃ© parent posÃ­lÃ¡ hodnoty.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- V aktivitÃ¡ch pouÅ¾Ã­vÃ¡Å¡ `@pipeline().parameters.ParamName` (napÅ™. v Copy Data jako zdroj/cÃ­l).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- Child pipeline mÅ¯Å¾e obsahovat dalÅ¡Ã­ ForEach, Copy Data, skripty, transformace a semantic model refresh â€“ vÅ¡e znovupouÅ¾itelnÃ© pro rÅ¯znÃ© parent pipelines.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

VÃ½hody:[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹

- PÅ™ehlednÄ›jÅ¡Ã­ a znovupouÅ¾itelnÃ© orchestrace.
    
- MoÅ¾nost vracet stav/ hodnoty z child do parent (s Legacy Invoke activity).
    

---

## 6. Notebook orchestrace pomocÃ­ notebookutils

## Kdy orchestraci dÄ›lat v notebooku

- KdyÅ¾ chceÅ¡ orchestraci ÄistÄ› v rÃ¡mci Spark prostÅ™edÃ­ a pracovat s jednou sdÃ­lenou Spark session.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- KdyÅ¾ tvÃ© workflow je â€notebook firstâ€œ a nepotÅ™ebujeÅ¡ zapojit tolik jinÃ½ch asset typÅ¯ jako v pipeline.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

## Notebookutils â€“ modul notebook

- Knihovna `notebookutils` obsahuje Å™adu modulÅ¯ (files, credentials, atd.), pro orchestrace je klÃ­ÄovÃ½ modul `notebook`.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- Ten umoÅ¾Åˆuje spouÅ¡tÄ›nÃ­ dalÅ¡Ã­ch notebookÅ¯ z jednoho orchestrujÃ­cÃ­ho notebooku.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

ZÃ¡kladnÃ­ pattern:[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹

- ImportujeÅ¡ modul (napÅ™. `from notebookutils import notebook as nb`).
    
- PouÅ¾Ã­vÃ¡Å¡ `nb.run_multiple(...)` pro spuÅ¡tÄ›nÃ­ vÃ­ce notebookÅ¯.
    

## ParalelnÃ­ bÄ›h notebookÅ¯

- `run_multiple` mÅ¯Å¾e vzÃ­t jednoduchÃ½ python list nÃ¡zvÅ¯ notebookÅ¯.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- VÅ¡echny notebooky v seznamu se spustÃ­ paralelnÄ› (poÅ™adÃ­ nehraje roli).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- VhodnÃ© pro nezÃ¡vislÃ© datovÃ© Ãºlohy (napÅ™. rÅ¯znÃ© domÃ©ny).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

## DAG pro notebook orchestrace

- MÃ­sto listu mÅ¯Å¾eÅ¡ `run_multiple` pÅ™edat DAG (Python dict) se strukturou:[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
    - `activities`: list objektÅ¯, kaÅ¾dÃ½ definuje jeden notebook (`name`, `path` + volitelnÃ© `timeoutPerCellInSeconds`, `retry`, `retryIntervalInSeconds`, `dependencies`).
        
- `dependencies` Å™Ã­kÃ¡, po kterÃ½ch aktivitÃ¡ch se konkrÃ©tnÃ­ notebook spustÃ­ (stejnÃ½ princip jako zÃ¡vislosti v pipeline).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- PouÅ¾ij `validate_dag(...)` pro kontrolu, Å¾e DAG je validnÃ­, a volbu `display_dag_via_graphviz=True` pro vizuÃ¡lnÃ­ zobrazenÃ­ grafu.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

## VÃ½hoda sdÃ­lenÃ© Spark session

- OrchestrujÃ­cÃ­ notebook mÅ¯Å¾e spouÅ¡tÄ›t dalÅ¡Ã­ Spark notebooky ve stejnÃ© Spark session, takÅ¾e sdÃ­lÃ­Å¡ cache, nastavenÃ© promÄ›nnÃ©, knihovny atd.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- V minulosti to byla velkÃ¡ vÃ½hoda proti pipelines, ale nynÃ­ majÃ­ pipelines â€session tagsâ€œ, takÅ¾e vÃ­c notebookÅ¯ spuÅ¡tÄ›nÃ½ch z pipeline mÅ¯Å¾e bÄ›Å¾et na stejnÃ© session.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

---

## 7. Triggery v Microsoft Fabric

## Schedule triggery

- Lze je nastavit pro: Data Pipelines, notebooky, Dataflow Gen2.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- DefinujeÅ¡ start time, end time a time zone (defaultnÄ› UTC).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

DoporuÄenÃ½ pÅ™Ã­stup:[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹

- Triggery nastavovat primÃ¡rnÄ› na pipelines a z nich spouÅ¡tÄ›t notebooky/dataflows, aby byla orchestrace centralizovanÃ¡ a lÃ©pe monitorovatelnÃ¡.
    

## Eventâ€‘based triggery (Blob Storage)

- Pro Data Pipelines existuje event-based trigger, kterÃ½ reaguje na udÃ¡losti v Azure Blob Storage (napÅ™. novÃ½ soubor, zmÄ›na).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- V konfiguraci zvolÃ­Å¡ pipeline, storage account a typ udÃ¡losti, na kterou se mÃ¡ reagovat.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

Useâ€‘case:[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹

- Fileâ€‘driven ingesce â€“ upload souboru do Blobu automaticky spustÃ­ ingest pipeline ve Fabricu (napÅ™. nÃ¡hrada za ADF/Synapse patterns).
    

## Real-Time Hub triggery (preview)

- Real-Time Hub pÅ™idÃ¡vÃ¡ dalÅ¡Ã­ typy eventÅ¯, kterÃ© mohou spouÅ¡tÄ›t Fabric artefakty:[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
    - Job events â€“ zmÄ›ny stavu jobÅ¯ (vytvoÅ™enÃ­, success, fail).
        
    - OneLake events â€“ udÃ¡losti nad soubory/sloÅ¾kami v OneLake.
        
    - Workspace item events â€“ zmÄ›ny nad poloÅ¾kami ve workspace.
        
- Tyto eventy lze pouÅ¾Ã­t pro spuÅ¡tÄ›nÃ­ Data Activator (Activator alerts), Event Streams nebo Data Pipelines.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

---

## 8. Semantic Models â€“ orchestrace refreshÅ¯

## Auto refresh (Direct Lake)

- U Direct Lake semantic modelÅ¯ lze zapnout auto refresh â€“ zmÄ›ny v OneLake datech se automaticky projevÃ­ v modelu pÅ™i dotazovÃ¡nÃ­.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- JednoduchÃ©, ale z hlediska kontrolovanÃ©ho ETL mÅ¯Å¾e bÃ½t riskantnÃ­ (bÄ›hem bÄ›hu pipeline mohou bÃ½t nÄ›kterÃ© tabulky uÅ¾ po ETL, jinÃ© jeÅ¡tÄ› ne).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

## Å˜Ã­zenÃ½ refresh pÅ™es pipeline

- V semantic model settings mÅ¯Å¾eÅ¡ auto refresh vypnout a nastavit scheduled refresh (hlavnÄ› pro Import).[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- AlternativnÄ› pouÅ¾ijeÅ¡ â€Semantic model refreshâ€œ aktivitu v pipeline:[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
    - Nejprve probÄ›hne ingest/transform (bronze/silver/gold) do tabulek.
        
    - Po ÃºspÄ›chu vÅ¡ech krokÅ¯ spustÃ­Å¡ refresh semantic modelu.
        

VÃ½hoda:[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹

- UÅ¾ivatelÃ© vÅ¾dy vidÃ­ konzistentnÃ­ pohled â€“ semantic model se aktualizuje aÅ¾ po kompletnÃ­m dokonÄenÃ­ ETL.
    

## Semantic Link â€“ refresh z notebooku

- PomocÃ­ Semantic Link (Python knihovna) mÅ¯Å¾eÅ¡ programovÄ› refreshovat semantic model (napÅ™. metodou `refresh_dataset`) pÅ™Ã­mo z notebooku.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- UmoÅ¾Åˆuje orchestraci ÄistÄ› z notebook orchestrace, pokud nechceÅ¡ pouÅ¾Ã­t pipeline aktivitu.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

---

## 9. Co si odnÃ©st pro DPâ€‘700 a praxi

- Pro orchestrace ve Fabricu pouÅ¾Ã­vej primÃ¡rnÄ› Data Pipelines, kterÃ© dokÃ¡Å¾ou spouÅ¡tÄ›t rÅ¯znÃ© Fabric a Azure assety, Å™Ã­dit tok, retry a notifikace.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- Stav pipeline navrhuj metadataâ€‘driven (Lookup â†’ ForEach â†’ Copy Data) a pro komplexnÄ›jÅ¡Ã­ logiku pouÅ¾Ã­vej parentâ€“child pattern s Invoke pipeline.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- Notebook orchestrace pÅ™es `notebookutils` se hodÃ­, pokud chceÅ¡ orchestraci uvnitÅ™ notebookovÃ©ho/Spark svÄ›ta, zejmÃ©na se sdÃ­lenou session.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- Triggery (schedule, event-based, Real-Time Hub) pouÅ¾ij pro automatizaci procesÅ¯ â€“ batch plÃ¡novÃ¡nÃ­, fileâ€‘based ingesci a realâ€‘time scÃ©nÃ¡Å™e.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    
- Semantic model refresh integruj do orchestracÃ­ (pipeline nebo notebook), abys mÄ›l plnou kontrolu nad tÃ­m, kdy jsou reporty aktualizovanÃ©.[youtube](https://www.youtube.com/watch?v=U7t9j95d1WA)â€‹
    

1. [https://www.youtube.com/watch?v=U7t9j95d1WA](https://www.youtube.com/watch?v=U7t9j95d1WA)
2. [https://www.skool.com/microsoft-fabric/classroom/4a13f708?md=555a311ce05147178dd7bff365229b62](https://www.skool.com/microsoft-fabric/classroom/4a13f708?md=555a311ce05147178dd7bff365229b62)

---
---

# ğŸš€ Decision Guides (plus Shortcuts & Mirroring)
# Choosing the right Fabric items | DP-700 (Video 6/11) [youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹

## TÃ©mata videa (podle sylabu)

- Ingest and transform batch data: vÃ½bÄ›r vhodnÃ©ho data store, volba nÃ¡stroje pro transformaci, shortcuts, mirroring.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- ZamÄ›Å™enÃ­ na rozhodovacÃ­ prÅ¯vodce (Decision Guides) v dokumentaci Fabricu.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    

---

## 1. Volba data store: Lakehouse vs Warehouse vs Eventhouse

## ZÃ¡kladnÃ­ pÅ™ehled

- HlavnÃ­ analytickÃ© datovÃ© ÃºloÅ¾iÅ¡tÄ› ve Fabricu: Lakehouse, Warehouse, Eventhouse (KQL DB).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- DoporuÄenÃ½ zdroj pro uÄenÃ­: â€Fabric data store decision guideâ€œ v oficiÃ¡lnÃ­ dokumentaci (tabulka srovnÃ¡vajÃ­cÃ­ tyto tÅ™i moÅ¾nosti).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    

## KlÃ­ÄovÃ© rozhodovacÃ­ faktory

1. **Skillset tÃ½mu**
    
    - Lakehouse: orientace na Spark â€“ PySpark, Spark SQL, Spark kÃ³d; typickÃ½ scÃ©nÃ¡Å™: migrace z Databricks, existujÃ­cÃ­ Spark codebase.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - Warehouse: orientace na Tâ€‘SQL a klasickÃ½ Microsoft BI/SQL svÄ›t â€“ databÃ¡zovÃ­ vÃ½vojÃ¡Å™i, BI tÃ½m.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - Eventhouse (KQL): realâ€‘time a timeâ€‘series scÃ©nÃ¡Å™e, KQL dovednosti, streamovÃ¡nÃ­ a operace nad ÄasovÃ½mi Å™adami.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
2. **Typ dat**
    
    - Lakehouse:
        
        - VhodnÃ½ pro **unstructured** data (obrÃ¡zky, zvuk, video) i structured/semiâ€‘structured data.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
            
        - MÃ¡ file area + spravovanÃ© Delta tables.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
            
    - Warehouse:
        
        - PrimÃ¡rnÄ› **structured** data (tabulky/sloupce); novÄ› podpora JSON sloupcÅ¯, ale poÅ™Ã¡d tabulkovÃ½ svÄ›t.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
            
    - Eventhouse:
        
        - FlexibilnÃ­ pro unstructured, semiâ€‘structured (JSON) i structured data, se silnou podporou timeâ€‘series a geospatial analÃ½z.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
            
3. **Read vs Write operace**
    
    - ÄŒtenÃ­ (read): dnes lze relativnÄ› snadno ÄÃ­st z Lakehouse i Warehouse z rÅ¯znÃ½ch prostÅ™edÃ­ (Spark, Tâ€‘SQL, semantic models).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - ZÃ¡pis (write):
        
        - ZÃ¡pis do Lakehouse â†’ nejpohodlnÄ›jÅ¡Ã­ pÅ™es Spark engine (PySpark, Spark SQL, R).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
            
        - ZÃ¡pis do Warehouse â†’ nejvÃ­c dÃ¡vÃ¡ smysl pÅ™es Tâ€‘SQL (INSERT/CTAS/ETL skripty).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
            
4. **Semantic Models**
    
    - Semantic model mÅ¯Å¾e ÄÃ­st jak z Lakehouse (SQL endpoint), tak z Warehouse; pro DPâ€‘700 nenÃ­ volba zÃ¡sadnÃ­, spÃ­Å¡ architektonickÃ¡ preference.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - Eventhouse mÃ¡ vlastnÃ­ realâ€‘time dashboarding artefakty, proto je semantickÃ© vrstvÄ› trochu stranou.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
5. **DalÅ¡Ã­ vlastnosti (mimo hlavnÃ­ tabulku)**
    
    - Warehouse podporuje **multiâ€‘table transactions**, Lakehouse ne.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - Eventhouse/KQL je primÃ¡rnÄ› pro timeâ€‘series a geospatial analÃ½zy, proto se v DPâ€‘700 ÄasovÃ© Å™ady typicky mapujÃ­ na Eventhouse.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
6. **Konfigurovatelnost a sprÃ¡va**
    
    - Lakehouse: vÃ­ce moÅ¾nostÃ­ ladÄ›nÃ­ (Delta nastavenÃ­, partitioning, Spark konfigurace), â€vÃ­c pod kapotouâ€œ v rukou data inÅ¾enÃ½ra.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - Warehouse: mÃ©nÄ› moÅ¾nostÃ­ lowâ€‘level administrace â€“ vÄ›tÅ¡inu optimalizacÃ­ spravuje Fabric za tebe (vÃ½jimkou je napÅ™. Vâ€‘Order).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
7. **Git & CI/CD**
    
    - Warehouse: lepÅ¡Ã­ integrace s Git/DevOps â€“ SQL Database Projects, vÃ­ce zmÄ›n je trackovÃ¡no ve verzi.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - Lakehouse: vÃ­c custom postâ€‘deployment skriptÅ¯ (vytvoÅ™enÃ­/hydratace tabulek) a vlastnÃ­ deployment proces.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        

---

## 2. Volba nÃ¡stroje pro ingest a transformaci (Pipeline vs Dataflow vs Spark vs Tâ€‘SQL)

## PÅ™ehled rozhodovacÃ­ tabulky

PosuzovanÃ© nÃ¡stroje: Data Pipeline, Dataflow Gen2, Spark (notebooky), Tâ€‘SQL.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹

HlavnÃ­ kritÃ©ria: use case, mnoÅ¾stvÃ­ transformacÃ­, skillset, rozhranÃ­ (code vs low/noâ€‘code), zdroje a cÃ­le.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹

## Use case a mÃ­ra transformacÃ­

- **Data Pipeline**
    
    - PrimÃ¡rnÄ› pro **ingest + orchestration**, ne pro tÄ›Å¾kÃ© transformace.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - Podporuje lehkÃ© transformace (mapovÃ¡nÃ­, zÃ¡kladnÃ­ filtry), ale na komplexnÃ­ business logiku uÅ¾ ne.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
- **Dataflow Gen2 (Power Query, M)**
    
    - Low/noâ€‘code ETL v UI, vhodnÃ© pro analytickÃ©/BI tÃ½my.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - FlexibilnÃ­ transformace (joiny, filtry, vÃ½poÄty) bez psanÃ­ kÃ³du v Pythonu/Tâ€‘SQL.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
- **Spark (PySpark, Spark SQL)**
    
    - MaximÃ¡lnÃ­ flexibilita, full code, vhodnÃ© pro nÃ¡roÄnÃ© transformace nad velkÃ½m objemem dat.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - TypickÃ© pro data inÅ¾enÃ½ry/pythoniÅ¡tÄ› a scÃ©nÃ¡Å™e pÅ™evzatÃ© z Databricks.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
- **Tâ€‘SQL (Warehouse)**
    
    - PlnohodnotnÃ© SQL transformace (CTAS, MERGE, window functions atd.).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - VhodnÃ© pro tÃ½my s tradiÄnÃ­m SQL backgroundem.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        

## Skillset a â€minimize development effortâ€œ

- FrÃ¡ze v zadÃ¡nÃ­ typu **â€Å™eÅ¡enÃ­ mÃ¡ minimalizovat vÃ½vojovÃ© ÃºsilÃ­â€œ** vÄ›tÅ¡inou tlaÄÃ­ k **low/noâ€‘code nÃ¡strojÅ¯m**:[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
    - Dataflow Gen2, Data Pipeline.
        
    - PÅ™Ã­padnÄ› **Shortcuts** nebo **Mirroring**, kterÃ© eliminujÃ­ klasickÃ© ETL ÃºplnÄ›.
        
- Spark/Tâ€‘SQL naopak znamenajÃ­ programovÃ¡nÃ­ a vyÅ¡Å¡Ã­ vÃ½vojovÃ© ÃºsilÃ­ (jen vhodnÃ©, kdyÅ¾ se vÃ½slovnÄ› opÃ­rajÃ­ o skills tÃ½mu).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    

## Zdroje a cÃ­le â€“ na co si dÃ¡t pozor v DPâ€‘700 otÃ¡zkÃ¡ch

- **Onâ€‘premises data**
    
    - KlÃ­ÄovÃ½ signÃ¡l pro: **Data Pipeline** nebo **Dataflow Gen2** (pÅ™es onâ€‘prem Data Gateway).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
- **SpecifickÃ© cÃ­le**
    
    - Ingest do Warehouse â†’ Tâ€‘SQL, Data Pipeline, Dataflow; Spark je sloÅ¾itÄ›jÅ¡Ã­ cesta.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
- **ADLS Gen2, S3, GCS**
    
    - Lze ingestovat tÃ©mÄ›Å™ vÅ¡emi nÃ¡stroji, ale Äasto to mÅ¯Å¾e bÃ½t otÃ¡zka na **Shortcuts** nebo **Mirroring** mÃ­sto klasickÃ©ho ETL.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        

---

## 3. Shortcuts (externÃ­ i internÃ­)

## Co jsou Shortcuts

- Shortcut je **referenÄnÃ­ odkaz** na data uloÅ¾enÃ¡ jinde â€“ externÄ› nebo v jinÃ©m Fabric assetu (Lakehouse/Warehouse v OneLake).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- UmoÅ¾nÃ­ pracovat s daty â€jako kdyby byla v tvÃ©m Lakehouseâ€œ, ale fyzicky je nemusÃ­Å¡ pÅ™esouvat.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    

## PodporovanÃ© externÃ­ zdroje

- Amazon S3.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- Amazon S3 compatible (Cloudflare R2 apod.).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- ADLS Gen2 (Azure Data Lake Storage).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- Dataverse (Power Apps, Dynamics 365 data).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- Google Cloud Storage.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    

VytvoÅ™enÃ­: v Lakehouse â†’ Get data â†’ New shortcut â†’ vybrat zdroj a objekt (vÄ›tÅ¡inou sloÅ¾ku).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹

## InternÃ­ Shortcuts

- Lze shortcutovat data v rÃ¡mci OneLake (jinÃ½ Lakehouse, Warehouse) do aktuÃ¡lnÃ­ho Lakehouse.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- UmoÅ¾Åˆuje sdÃ­let data mezi tÃ½my/workspaces bez duplikace a ETL.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    

## Podpora Apache Iceberg

- NovÄ› (preview) lze pomocÃ­ shortcut pÅ™ipojit i **Apache Iceberg** soubory (typicky Snowflake uloÅ¾enÃ½ v externÃ­m storage).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- Ve spojenÃ­ se Snowflake lze buÄ shortcutovat Iceberg files, nebo pouÅ¾Ã­t mirroring (viz dÃ¡le).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    

## Shortcut caching (pÅ™ipomenutÃ­ z pÅ™edchozÃ­ho videa)

- Workspace nastavenÃ­, kterÃ© vytvÃ¡Å™Ã­ cache dat z externÃ­ch cloud storage (S3, S3 compatible, GCS) v Azure, aby se snÃ­Å¾ily egress poplatky.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- Pravidla:[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
    - Cache se smaÅ¾e, pokud nebyla pÅ™Ã­stupnÃ¡ â‰¥ 24 hodin.
        
    - Soubory > 1 GB se do cache nedÃ¡vajÃ­.
        
    - NenÃ­ k dispozici pro ADLS Gen2 (uÅ¾ je v Azure).
        

---

## 4. Mirroring databÃ¡zÃ­ do Fabricu

## Co je Mirroring

- Mirroring vytvoÅ™Ã­ **near realâ€‘time repliku** podporovanÃ© databÃ¡ze ve Fabricu, aniÅ¾ bys psal klasickÃ© ETL.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- VÃ½sledek je samostatnÃ½ â€Mirroredâ€œ artefakt ve workspace, se kterÃ½m pak pracujeÅ¡ jako s Fabric databÃ¡zÃ­.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    

## PodporovanÃ© zdroje (stav ve videu)

- Azure Cosmos DB.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- Azure SQL Database (GA).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- Azure SQL Managed Instance (preview).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- Mirrored Snowflake (GA) â€“ mirror tabulek ze Snowflake.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- Azure Databricks Unity Catalog (metadata mirroring, spÃ­Å¡ jako pÅ™ehled + shortcut pod kapotou).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- Fabric SQL Database â†’ automatickÃ½ mirror do mirrored SQL DB (OLTP â†’ Delta pro analytiku).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    

## Open Mirroring (generic mirroring â€“ preview)

- â€Mirrored database (preview)â€œ je obecnÃ½ framework, do kterÃ©ho mohou rÅ¯znÃ­ poskytovatelÃ© databÃ¡zÃ­ napsat konektor.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- Princip:
    
    - Fabric poskytne landing zone.
        
    - ZdrojovÃ½ systÃ©m sem zapisuje Parquet soubory ve specifickÃ©m formÃ¡tu, kde se kÃ³dovÄ› oznaÄuje insert/update/delete.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - Fabric pak z tÄ›chto souborÅ¯ prÅ¯bÄ›Å¾nÄ› sklÃ¡dÃ¡ mirror.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
- V DPâ€‘700 se to pravdÄ›podobnÄ› neobjevÃ­ (preview), ale koncept je dÅ¯leÅ¾itÃ½ do budoucna.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    

## Unity Catalog mirroring (Databricks)

- Jde o **metadata mirroring** â€“ zrcadlÃ­ Unity Catalog (tabulky, schÃ©mata), ne nutnÄ› vÅ¡echna data.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- Pod povrchem funguje vÃ­ce jako kombinace metadat a shortcuts neÅ¾ klasickÃ½ mirror vÅ¡ech dat.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    

## Jak to vypadÃ¡ ve workspace

- Ve Fabric workspace uvidÃ­Å¡ vÃ­ce rÅ¯znÃ½ch mirrored artefaktÅ¯ (Cosmos DB, Azure SQL, Snowflake, Databricks Unity Catalog, Fabric SQL DB mirror).[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    
- Fabric SQL DB mÃ¡ automatickÃ½ mirror do mirrored SQL DB, coÅ¾ zpÅ™Ã­stupnÃ­ OLTP data pro analytickÃ© scÃ©nÃ¡Å™e bez vlastnÃ­ho ETL.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
    

---

## 5. ShrnutÃ­ pro DPâ€‘700 (rozhodovacÃ­ mindset)

- **VÃ½bÄ›r data store:**
    
    - Lakehouse â†’ Spark skills, unstructured data, vysokÃ¡ konfigurovatelnost.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - Warehouse â†’ Tâ€‘SQL skills, structured data, lepÅ¡Ã­ Git/CIâ€‘CD integrace, multiâ€‘table transakce.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - Eventhouse â†’ realâ€‘time, timeâ€‘series, geospatial scÃ©nÃ¡Å™e, KQL.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
- **VÃ½bÄ›r nÃ¡stroje pro ingest/transformace:**
    
    - Orchestrace + lehkÃ© transformace â†’ Data Pipeline.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - Low/noâ€‘code ETL â†’ Dataflow Gen2.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - Codeâ€‘heavy, velkÃ¡ data â†’ Spark.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - SQLâ€‘centrickÃ© transformace â†’ Tâ€‘SQL ve Warehouse.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
- **Minimalizace vÃ½voje:**
    
    - Hledej Dataflow/Pipeline/Shortcuts/Mirroring mÃ­sto Spark/Tâ€‘SQL, pokud otÃ¡zka mluvÃ­ o â€minimalizaci development effortâ€œ.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
- **Shortcuts vs Mirroring:**
    
    - Shortcuts â†’ pouze referenÄnÃ­ pÅ™Ã­stup k datÅ¯m (externÃ­ nebo internÃ­), bez replikace.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        
    - Mirroring â†’ near realâ€‘time kopie databÃ¡ze ve Fabricu, bez klasickÃ©ho ETL.[youtube](https://www.youtube.com/watch?v=lPCBGOStKU4)â€‹
        

1. [https://www.youtube.com/watch?v=lPCBGOStKU4](https://www.youtube.com/watch?v=lPCBGOStKU4)
2. [https://www.skool.com/microsoft-fabric/classroom/4a13f708?md=54a9efe4a6374b95b1363dccda31254c](https://www.skool.com/microsoft-fabric/classroom/4a13f708?md=54a9efe4a6374b95b1363dccda31254c)
---
---

# ğŸš€ Hands-on: T-SQL
# Tâ€‘SQL & Dimensional Modeling in Fabric | DPâ€‘700 (Video 7/11) [youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹

## CÃ­l videa a pÅ™edpoklady

- Video pÅ™edpoklÃ¡dÃ¡ solidnÃ­ zÃ¡klady Tâ€‘SQL (SELECT/WHERE/GROUP BY/HAVING/INSERT/UPDATE/DELETE, JOINy, UNION/UNION ALL, datovÃ© typy, views, stored procedures, funkce).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- ZamÄ›Å™enÃ­: Tâ€‘SQL v Fabric Data Warehouse, dimenzionÃ¡lnÃ­ modelovÃ¡nÃ­ a zabezpeÄenÃ­ dat z pohledu DPâ€‘700.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

---

## 1. Tvorba tabulek a ingesce dat ve Fabric DW

## ZÃ¡kladnÃ­ zpÅ¯soby vytvoÅ™enÃ­/zaplÅˆovÃ¡nÃ­ tabulek

- `CREATE TABLE` â€“ klasickÃ© vytvoÅ™enÃ­ prÃ¡zdnÃ© tabulky, ale ve Fabric DW nelze pÅ™i vytvoÅ™enÃ­ definovat PK ani identity.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- `COPY INTO` â€“ velmi rychlÃ¡ ingesce CSV/Parquet z ADLS Gen2 do existujÃ­cÃ­ tabulky, podporuje Trusted Workspace Access a rÅ¯znÃ© volby (file type, header row, date format atd.).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- `INSERT INTO ... SELECT ... FROM ...` â€“ vloÅ¾enÃ­ dat z jednÃ© tabulky do jinÃ© (napÅ™. staging â†’ silver).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- `SELECT ... INTO NewTable FROM SourceTable` â€“ vytvoÅ™enÃ­ novÃ© tabulky a naplnÄ›nÃ­ daty v jednom kroku.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- `CREATE TABLE NewTable AS SELECT ...` (CTAS) â€“ takÃ© kombinuje vytvoÅ™enÃ­ + naplnÄ›nÃ­, uÅ¾iteÄnÃ© pro derivovanÃ©/aggregate tabulky.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

## PoznÃ¡mky k pouÅ¾itÃ­

- V ukÃ¡zkÃ¡ch se pouÅ¾Ã­vÃ¡ schema napÅ™. `dbo` (raw) a `silver` (ÄistÄ›jÅ¡Ã­ vrstva), pÅ™iÄemÅ¾ se ukazuje fullâ€‘load scÃ©nÃ¡Å™ (Å¾Ã¡dnÃ¡ incremental logika).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- `COPY INTO` z ADLS Gen2 je ve Fabricu prezentovÃ¡no jako jeden z nejrychlejÅ¡Ã­ch zpÅ¯sobÅ¯ hromadnÃ©ho naÄtenÃ­ velkÃ½ch souborÅ¯.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

---

## 2. Primary Key constraints ve Fabric DW

## Specifika PK v Fabricu

- PK nelze definovat v `CREATE TABLE`, musÃ­ se pouÅ¾Ã­t `ALTER TABLE ... ADD CONSTRAINT ... PRIMARY KEY`.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- Primary key je vÅ¾dy:
    
    - nonclustered,
        
    - **NOT ENFORCED** (nekontroluje unikÃ¡tnost hodnot pÅ™i zÃ¡pisu).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
        

## DÅ¯sledky

- PK constraint slouÅ¾Ã­ hlavnÄ› pro:
    
    - plÃ¡novÃ¡nÃ­ dotazÅ¯ a optimalizaci pod kapotou,
        
    - dokumentaci modelu (vztahy mezi tabulkami).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
        
- Lze vloÅ¾it duplicity do PK sloupce; zodpovÄ›dnost za Äistotu dat (unikÃ¡tnost) je na ETL/modelerovi, ne na engine DW.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

---

## 3. Surrogate keys v dimenzionÃ¡lnÃ­m modelu

## Pojmy

- **Natural key** â€“ klÃ­Ä ze zdrojovÃ©ho systÃ©mu (napÅ™. `ProductID`, `EmployeeID`), kterÃ½ uÅ¾ivatelÃ© znajÃ­.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- **Surrogate key** â€“ novÃ½, v analytickÃ©m prostÅ™edÃ­ generovanÃ½ klÃ­Ä (typicky integer), nezÃ¡vislÃ½ na business datech zdroje.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

## ProÄ surrogate key

- Podpora SCD Type 2 â€“ vÃ­ce Å™Ã¡dkÅ¯ se stejnÃ½m natural key (historie), ale jinÃ© surrogate key â†’ unikÃ¡tnÃ­ vazba na fakta.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- Odolnost vÅ¯Äi zmÄ›nÃ¡m ve zdrojovÃ½ch systÃ©mech (zmÄ›na natural key, slouÄenÃ­ systÃ©mÅ¯ apod.).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

## GenerovÃ¡nÃ­ surrogate key bez identity

- Identity sloupce nejsou ve Fabric DW podporovanÃ©, proto se pouÅ¾Ã­vajÃ­ workarounds:[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
    - VytvoÅ™it staging tabulku (`staging.UpdatedProducts`).
        
    - NajÃ­t maximum existujÃ­cÃ­ho surrogate key z produkÄnÃ­ dimenze (napÅ™. `@MaxProductSurrogateKey = MAX(ProductSurrogateKey)` nebo 0, pokud prÃ¡zdnÃ©).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
        
    - PÅ™i vklÃ¡dÃ¡nÃ­ z `staging` pouÅ¾Ã­t `ROW_NUMBER()` pÅ™es staging data a pÅ™iÄÃ­st k max hodnotÄ› â†’ novÃ½m Å™Ã¡dkÅ¯m se pÅ™idÄ›lÃ­ unikÃ¡tnÃ­ klÃ­Äe (max+1, max+2,â€¦).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
        
- VÃ½sledkem je sekvence surrogate key, kterÃ¡ pokraÄuje, i kdyÅ¾ load bÄ›Å¾Ã­ po dÃ¡vkÃ¡ch.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

---

## 4. DimenzionÃ¡lnÃ­ modelovÃ¡nÃ­ v Tâ€‘SQL

## Role Tâ€‘SQL v medailonku / gold vrstvÄ›

- DimenzionÃ¡lnÃ­ model (star schema) bÃ½vÃ¡ ve Fabric architektuÅ™e Äasto realizovÃ¡n ve **Warehouse** jako â€goldâ€œ vrstva.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- Tâ€‘SQL zde Å™eÅ¡Ã­ hlavnÄ›: tvorbu dimenzÃ­ a fact tabulek, join logiku, SCD, klÃ­Äe a referenÄnÃ­ integritu v analytickÃ©m kontextu.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

## Joins a referential integrity

- Pro DPâ€‘700 je dÅ¯leÅ¾itÃ©:
    
    - rozumÄ›t left/inner/right/full outer joinÅ¯m,
        
    - chÃ¡pat dopad na poÄet Å™Ã¡dkÅ¯ a NULL hodnoty,
        
    - umÄ›t pracovat s **referential integrity violations** (napÅ™. fakta s klÃ­Äi, kterÃ© nemajÃ­ zÃ¡znam v dimenzi).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
        
- PÅ™Ã­klad:
    
    - Dimenze `DimCustomers` mÃ¡ customer IDs 1â€“4, fakta `FactOrders` majÃ­ objednÃ¡vky pro zÃ¡kaznÃ­ky 1,2,4.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
        
    - Left join na dimenzi zachovÃ¡ vÅ¡echny zÃ¡kaznÃ­ky (1â€“4), inner join vyÅ™adÃ­ zÃ¡kaznÃ­ka 3 (bez objednÃ¡vek), full outer join vrÃ¡tÃ­ vÅ¡echna fakta i dimenze a je vhodnÃ½ pro diagnostiku datovÃ½ch nesouladÅ¯.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
        

## ZÃ¡kladnÃ­ postup tvorby fact tabulky

1. NaÄÃ­st/aktualizovat dimenze a vygenerovat surrogate keys.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
2. FaktovÃ¡ staging tabulka obsahuje natural keys (produkt, zÃ¡kaznÃ­k, prodejna).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
3. PomocÃ­ joinÅ¯ na dimenze nahradit natural keys za surrogate keys a vytvoÅ™it finÃ¡lnÃ­ fact tabulku, kterou naÄteÅ¡ do DW.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

- Pokud by se pouÅ¾Ã­valy jen natural keys, riziko duplicit/zmÄ›n by destabilizovalo relace faktÅ¯ a dimenzÃ­, zvlÃ¡Å¡Å¥ pÅ™i SCD Type 2.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

---

## 5. Slowly Changing Dimensions (SCD) â€“ hlavnÄ› Type 2

## SCD Type 2 â€“ struktura tabulky

- Dimenze SCD2 typicky obsahuje:[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
    - `SurrogateKey` â€“ unikÃ¡tnÃ­ Å™Ã¡dek pro kaÅ¾dou historickou verzi.
        
    - `NaturalKey` â€“ ID ze zdroje (stÃ¡le stejnÃ© pro danou entitu).
        
    - Business atributy (jmÃ©no, adresa, atd.).
        
    - `ValidFrom` a `ValidTo` â€“ ÄasovÃ¡ platnost Å™Ã¡dku.
        
- ÄŒasto `ValidTo` = velkÃ© datum (napÅ™. 9999â€‘12â€‘31) nebo NULL pro aktuÃ¡lnÄ› platnÃ½ Å™Ã¡dek; nÄ›kterÃ© implementace pÅ™idÃ¡vajÃ­ i `IsCurrent` (1/0).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

## Update flow SCD Type 2 (zjednoduÅ¡enÄ›)

PÅ™Ã­klad: zÃ¡kaznice zmÄ›nÃ­ pÅ™Ã­jmenÃ­.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹

1. NajÃ­t aktuÃ¡lnÃ­ Å™Ã¡dek danÃ©ho `NaturalKey` (napÅ™. CustomerID).
    
2. **UzavÅ™Ã­t** stÃ¡vajÃ­cÃ­ Å™Ã¡dek aktualizacÃ­ `ValidTo` na datum zmÄ›ny (load date).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
3. VloÅ¾it novÃ½ Å™Ã¡dek se stejnÃ½m `NaturalKey`, novÃ½mi atributy (napÅ™. novÃ© pÅ™Ã­jmenÃ­), `ValidFrom = LoadDate`, `ValidTo = â€futureâ€œ`.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

- DvÄ› po sobÄ› jdoucÃ­ verze majÃ­ konzistentnÃ­ Å™etÄ›zec (`ValidTo` starÃ©ho = `ValidFrom` novÃ©ho), coÅ¾ umoÅ¾Åˆuje ÄasovÃ© analÃ½zy (stav entity k libovolnÃ©mu datu).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

---

## 6. ZabezpeÄenÃ­ ve Fabric Data Warehouse (RLS, OLS, CLS, Dynamic Masking)

## Row-Level Security (RLS)

TÅ™Ã­krokovÃ½ pattern:[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹

1. VytvoÅ™it schema (napÅ™. `SECURITY`).
    
2. VytvoÅ™it **tableâ€‘valued function**, kterÃ¡ vracÃ­ filtrovanÃ½ set Å™Ã¡dkÅ¯ na zÃ¡kladÄ› pÅ™ihlÃ¡Å¡enÃ©ho uÅ¾ivatele (napÅ™. `WHERE SalesRep = USER_NAME()`).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
3. VytvoÅ™it **SECURITY POLICY**, kterÃ¡ pÅ™idÃ¡ tento filter predicate na konkrÃ©tnÃ­ tabulku.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

- Funguje tak, Å¾e dotazujÃ­cÃ­ uÅ¾ivatel vidÃ­ jen â€vÃ½Å™ezâ€œ dat podle definovanÃ© logiky funkce.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

## Object-Level Security (OLS)

- PÅ™edpoklad: uÅ¾ivatel mÃ¡ itemâ€‘level pÅ™Ã­stup k DW (napÅ™. `VIEW`).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- Potom lze pomocÃ­ `GRANT SELECT ON TableName TO Role/User` dÃ¡t pÅ™Ã­stup jen k vybranÃ½m tabulkÃ¡m (ne ke vÅ¡em objektÅ¯m DW).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

## Column-Level Security (CLS)

- StejnÃ½ princip jako OLS, ale na Ãºrovni sloupcÅ¯: `GRANT SELECT (Column1, Column2) ON TableName TO Role/User`.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- UmoÅ¾Åˆuje zobrazit jen necitlivÃ© sloupce (napÅ™. ID a datum vytvoÅ™enÃ­ ÃºÄtu), ostatnÃ­ jsou pro danÃ©ho uÅ¾ivatele nepÅ™Ã­stupnÃ©.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

## Dynamic Data Masking

- UmoÅ¾Åˆuje maskovat citlivÃ¡ data pÅ™i zobrazenÃ­, bez fyzickÃ© Ãºpravy uloÅ¾enÃ½ch hodnot.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- DÃ¡ se nastavit pÅ™i `CREATE TABLE` (sloupec `MASKED WITH (FUNCTION = ...)`) nebo pÅ™es ALTER.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

PodporovanÃ© funkce:[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹

- `DEFAULT` â€“ generickÃ¡ maska pro rÅ¯znÃ© datovÃ© typy (napÅ™. nahrazenÃ­ hvÄ›zdiÄkami).
    
- `EMAIL` â€“ zobrazÃ­ ÄÃ¡st emailu, zbytek zamaskuje (lokÃ¡lnÃ­ ÄÃ¡st + domÃ©na).
    
- `RANDOM` â€“ pro ÄÃ­selnÃ© hodnoty; definuje se interval `<start, end>`.
    
- `PARTIAL` â€“ zobrazÃ­ X znakÅ¯ na zaÄÃ¡tku, Y na konci a mezi nimi maskovacÃ­ vzor (napÅ™. â€****â€œ).
    

DÅ¯leÅ¾itÃ© upozornÄ›nÃ­:

- MaskovÃ¡nÃ­ ovlivÅˆuje **pouze zobrazenÃ­**; uÅ¾ivatel s dostateÄnÃ½mi oprÃ¡vnÄ›nÃ­mi mÅ¯Å¾e masku obejÃ­t sofistikovanÃ½mi dotazy.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- Proto se mÃ¡ **vÅ¾dy kombinovat** s RLS/CLS/OLS â€“ samotnÃ© DDM nenÃ­ plnohodnotnÃ¡ bezpeÄnostnÃ­ bariÃ©ra.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

---

## 7. Co z toho je klÃ­ÄovÃ© pro DPâ€‘700

- Znalost rÅ¯znÃ½ch Tâ€‘SQL zpÅ¯sobÅ¯ vytvoÅ™enÃ­ a naplnÄ›nÃ­ tabulek ve Fabric DW (`CREATE TABLE`, `COPY INTO`, `INSERT INTO...SELECT`, `SELECT INTO`, `CTAS`).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- PochopenÃ­ specifik PK ve Fabricu (ALTER TABLE, nonclustered, not enforced) a schopnost vysvÄ›tlit, proÄ se surrogate keys pouÅ¾Ã­vajÃ­ v dimenzionÃ¡lnÃ­ch modelech.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- PraktickÃ¡ orientace v joins a jejich dopadu na dimenzionÃ¡lnÃ­ model (dim/fact, referential integrity, SCD Type 2 pattern).[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    
- PÅ™ehled o RLS, OLS, CLS a dynamic data masking v syntaxi Tâ€‘SQL v prostÅ™edÃ­ Fabric Data Warehouse.[youtube](https://www.youtube.com/watch?v=O_py6ey94L8)â€‹
    

1. [https://www.youtube.com/watch?v=O_py6ey94L8](https://www.youtube.com/watch?v=O_py6ey94L8)
2. [https://www.skool.com/microsoft-fabric/classroom/4a13f708?md=6db397d9a85740ef954720a69d7ede88](https://www.skool.com/microsoft-fabric/classroom/4a13f708?md=6db397d9a85740ef954720a69d7ede88)
---
---

# ğŸš€ Hands-on: Spark
# Data Loading & Spark v Microsoft Fabric | DPâ€‘700 (Video 8/11) [youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹

## CÃ­l videa a kontext

- Fokus: Spark engine, Fabric notebooks, vytvÃ¡Å™enÃ­ a naÄÃ­tÃ¡nÃ­ tabulek v Lakehouse, zÃ¡klady transformacÃ­ a full vs incremental loading.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
- PÅ™edpoklad: znÃ¡Å¡ zÃ¡klady Pythonu, PySpark a Fabric/Spark prostÅ™edÃ­ (video neuÄÃ­ Python/Spark od nuly).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    

---

## 1. Fabric notebooks â€“ co musÃ­Å¡ umÄ›t

## PodporovanÃ© jazyky a parametry

- Fabric notebook dnes podporuje: Spark (PySpark, Spark SQL), pure Python notebooky a Tâ€‘SQL notebooky (preview).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
- Parametrizace notebooku:
    
    - Libovolnou buÅˆku mÅ¯Å¾eÅ¡ oznaÄit jako â€parameter cellâ€œ, kde definujeÅ¡ promÄ›nnÃ© a defaultnÃ­ hodnoty.
        
    - PÅ™i orchestrace (pipeline, `notebookutils.notebook.run_multiple`) lze tyto parametry pÅ™epsat a dÄ›lat notebook dynamickÃ½.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
        

## `notebookutils` â€“ klÃ­ÄovÃ© moduly

- Python balÃ­k od Microsoftu, spoleÄnÃ½ pro Spark i pure Python notebooky.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
- HlavnÃ­ oblasti:
    
    - `files` â€“ prÃ¡ce se souborovÃ½m systÃ©mem (pÅ™esuny, mazÃ¡nÃ­, atd.), API podobnÃ© shell pÅ™Ã­kazÅ¯m.
        
    - `notebook` â€“ spouÅ¡tÄ›nÃ­ notebookÅ¯ (`run_multiple` atd.).
        
    - `credentials` â€“ ÄtenÃ­ secretÅ¯ z Azure Key Vault (`credentials.get_secret`).
        
    - `lakehouse` â€“ pomocnÃ© funkce pro prÃ¡ci s Delta/Lakehouse (psanÃ­ tabulek i mimo PySpark).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
        

---

## 2. Tvorba tabulek v Lakehouse pomocÃ­ Spark

## Spark SQL

- MÅ¯Å¾eÅ¡ psÃ¡t SQL v Spark contextu (Spark SQL) a vytvÃ¡Å™et tabulky v Lakehouse podobnÄ› jako v Tâ€‘SQL.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
- VÃ½hoda: znÃ¡mÃ¡ SQL syntax + sÃ­la Spark enginu (distribuovanÃ© zpracovÃ¡nÃ­).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    

## PySpark + DeltaTable (Delta Lake knihovna)

- PÅ™Ã­stup pÅ™es `DeltaTable` API (import `DeltaTable`, typy z `pyspark.sql.types`).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
- TypickÃ½ postup:
    
    - DefinujeÅ¡ schÃ©ma (`StructType` + `StructField`), vÄetnÄ› typÅ¯ sloupcÅ¯.
        
    - PouÅ¾ijeÅ¡ `DeltaTable.createOrReplace(spark)...` s nÃ¡zvem tabulky a definovanÃ½mi sloupci.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
        
- VÃ½sledek: Delta tabulka v Lakehouse (managed v â€Tablesâ€œ ÄÃ¡sti), se kterou dÃ¡le pracujeÅ¡ pÅ™es Spark SQL nebo DataFrames.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    

---

## 3. Transformace a ÄiÅ¡tÄ›nÃ­ dat v PySpark

## Co bys mÄ›l ovlÃ¡dat pro DPâ€‘700

- ZÃ¡kladnÃ­ operace nad DataFrame:[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
    - ÄŒtenÃ­ dat (`spark.read`), zÃ¡pis (`df.write`).
        
    - Filtrace (`filter`/`where`), vÃ½bÄ›r a tvorba sloupcÅ¯ (`select`, `withColumn`).
        
    - GroupBy + agregace.
        
    - Joiny v PySpark (inner/left/right/full).
        
- DetailnÃ­ techniky ÄiÅ¡tÄ›nÃ­ a pokroÄilÃ© transformace jsou pokrytÃ© v jinÃ½ch kurzech (Spark sÃ©rie, DPâ€‘600), ale pro DPâ€‘700 je dÅ¯leÅ¾itÃ© bÃ½t s tÄ›mito zÃ¡klady komfortnÃ­.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    

---

## 4. Full vs Incremental loading â€“ teorie

## CÃ­l data inÅ¾enÃ½ra

- UdrÅ¾et **source system** a **analytical system (Fabric)** v synchronu: mÃ­t v Fabricu kopii dat, kterÃ¡ vÄ›rnÄ› odrÃ¡Å¾Ã­ stav zdrojovÃ½ch systÃ©mÅ¯ pro reporting/ML/semantic models.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    

## MoÅ¾nosti synchronizace

1. **Database Mirroring**
    
    - NejjednoduÅ¡Å¡Ã­ cesta, pokud je podporovanÃ¡ (Azure SQL, Snowflake, Cosmos DB, Azure SQL MI v preview).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
        
    - Fabric se starÃ¡ o near realâ€‘time replikaci; ETL logiku minimalizujeÅ¡.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
        
2. **Full load (full refresh)**
    
    - PÅ™i kaÅ¾dÃ©m bÄ›hu naÄteÅ¡ celÃ½ dataset z patÅ™iÄnÃ©ho zdroje a cÃ­lovou tabulku pÅ™epÃ­Å¡eÅ¡ (drop & replace / overwrite).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
        
    - VÃ½hody: jednoduchost, snadnÃ¡ implementace v rÅ¯znÃ½ch nÃ¡strojÃ­ch (Dataflow Gen2, Copy jobs, Spark notebooks, Data Pipeline s overwrite).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
        
    - NevÃ½hody: vysokÃ© vyuÅ¾itÃ­ kapacity a nÃ¡kladÅ¯ u velkÃ½ch tabulek, zejmÃ©na pÅ™i ÄastÃ©m spouÅ¡tÄ›nÃ­.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
        
3. **Incremental load**
    
    - NaÄÃ­tÃ¡Å¡ pouze zmÄ›nÄ›nÃ¡ data (insert/update/delete) od poslednÃ­ho bÄ›hu â€“ â€zmÄ›ny mezi dvÄ›ma snapshotyâ€œ.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
        
    - VÃ½hody: menÅ¡Ã­ objem dat, rychlejÅ¡Ã­ bÄ›hy, Ãºspora kapacity.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
        
    - NevÃ½hody: sloÅ¾itÄ›jÅ¡Ã­ implementace (sledovÃ¡nÃ­ watermarku, logiky merge, mazÃ¡nÃ­ atd.).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
        

## Podpora v nÃ¡strojÃ­ch (stav ve videu)

- Dataflow Gen2 â€“ ÄÃ¡steÄnÃ¡/pÅ™edbÄ›Å¾nÃ¡ podpora incremental load (omezenÃ­ podle cÃ­le).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
- Copy activity â€“ omezenÃ© moÅ¾nosti incremental podle cÃ­le a konfigurace.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
- Spark notebooks â€“ plnÃ¡ flexibilita pro full i incremental load (Deltalake + merge).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
- Data Pipelines â€“ full load pÅ™es overwrite bÄ›Å¾nÃ½, incremental logika primÃ¡rnÄ› pÅ™es Spark/Delta/notebooky, ne ÄistÄ› v Copy.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    

---

## 5. Full load v Spark notebooku (Lakehouse)

## PÅ™Ã­klad: naÄtenÃ­ CSV a full overwrite

1. NaÄti CSV soubor do DataFrame (napÅ™. `HubSpotContactsTest.csv` z files area Lakehouse).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
2. ZapiÅ¡ DataFrame jako Delta tabulku:
    
    - `df.write.format("delta").mode("overwrite").saveAsTable("HubSpotContacts")` â€“ full load do managed table (Tables).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
        
    - AlternativnÄ› `df.write.format("delta").mode("overwrite").save(path)` â€“ zÃ¡pis na explicitnÃ­ cestu (unmanaged v â€Filesâ€œ).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
        

- `saveAsTable` nepotÅ™ebuje path (implicitnÄ› jde do Lakehouse tables), `save` vyÅ¾aduje plnou cestu, ale je univerzÃ¡lnÄ›jÅ¡Ã­ (pro managed i unmanaged tabulky).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    

---

## 6. Incremental load s pomocÃ­ Spark SQL MERGE

## ScÃ©nÃ¡Å™

- MÃ¡Å¡ existujÃ­cÃ­ Delta tabulku `HubSpotContacts` a novÃ½ dataset zmÄ›n v CSV (`HubSpotContactsUpdates.csv`).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    

## Kroky

1. NaÄÃ­st updates do DataFrame (`updatesDf`).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
2. VytvoÅ™it doÄasnÃ½ view: `updatesDf.createOrReplaceTempView("ContactUpdates")`.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
3. PouÅ¾Ã­t Spark SQL `MERGE`:[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
    - `MERGE INTO HubSpotContacts AS target`
        
    - `USING ContactUpdates AS source`
        
    - `ON target.CustomerID = source.CustomerID`
        
    - `WHEN MATCHED THEN UPDATE SET *` (nebo explicitnÃ­ seznam sloupcÅ¯).
        
    - `WHEN NOT MATCHED THEN INSERT *`.
        

- Spark vypÃ­Å¡e souhrn: poÄet updatovanÃ½ch, vloÅ¾enÃ½ch, smazanÃ½ch Å™Ã¡dkÅ¯ (v pÅ™Ã­kladu jsou jen updaty).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
- `MERGE` je v dobÄ› videa pÅ™irozenÃ½ pro Spark svÄ›t, Tâ€‘SQL varianta je pro Fabric roadmapu, ale zatÃ­m vyÅ¾aduje ruÄnÃ­ implementaci.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    

---

## 7. Incremental load s DeltaTable API (PySpark)

## AlternativnÃ­ pÅ™Ã­stup

- MÃ­sto Spark SQL pouÅ¾Ã­vÃ¡Å¡ pÅ™Ã­mo `DeltaTable` objekt:[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    

1. NaÄti cÃ­lovou Delta tabulku:
    
    - `deltaTable = DeltaTable.forName(spark, "HubSpotContacts")` (nebo `forPath` s cestou).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
        
2. NaÄti updates do `updatesDf`.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
3. Zavolej `deltaTable.alias("target").merge(updatesDf.alias("source"), "target.CustomerID = source.CustomerID")` a pÅ™idej:
    
    - `.whenMatchedUpdateAll()`
        
    - `.whenNotMatchedInsertAll()`
        
    - `.execute()`.
        

- FunkÄnÄ› podobnÃ© jako Spark SQL `MERGE`, ale plnÄ› v Python/PySpark stylu (lepÅ¡Ã­, pokud mÃ¡Å¡ sloÅ¾itÄ›jÅ¡Ã­ logiku v kÃ³du).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    

---

## 8. Co je dÅ¯leÅ¾itÃ© pro DPâ€‘700 (Spark ÄÃ¡st)

- RozumÄ›t roli Fabric notebookÅ¯: multiâ€‘language, parametry, `notebookutils` (files, notebook orchestrace, credentials, lakehouse).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
- UmÄ›t aspoÅˆ na konceptuÃ¡lnÃ­ Ãºrovni vytvoÅ™it a naplnit Delta tabulku v Lakehouse pomocÃ­ Spark SQL a PySpark + DeltaTable.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
- VysvÄ›tlit rozdÃ­l mezi full load a incremental load a uvÃ©st, jak incremental load implementujeÅ¡ v Spark (MERGE, DeltaTable).[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    
- VnÃ­mat, Å¾e pro nÃ¡roÄnÄ›jÅ¡Ã­ incremental scÃ©nÃ¡Å™e je Spark/Delta v Fabricu nejflexibilnÄ›jÅ¡Ã­ volba oproti ÄistÄ› lowâ€‘code nÃ¡strojÅ¯m.[youtube](https://www.youtube.com/watch?v=sV-dFllAJws)â€‹
    

1. [https://www.youtube.com/watch?v=sV-dFllAJws](https://www.youtube.com/watch?v=sV-dFllAJws)
2. [https://www.skool.com/microsoft-fabric/classroom/4a13f708?md=95ee8f3fe032443689e3cd6e0939a3ec](https://www.skool.com/microsoft-fabric/classroom/4a13f708?md=95ee8f3fe032443689e3cd6e0939a3ec)
---
---

# ğŸš€ Real-time systems
# Realâ€‘Time Intelligence v Microsoft Fabric | DPâ€‘700 (Video 9/11) [youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹

## CÃ­le videa a kontext

- TÃ©ma: realâ€‘time systÃ©my ve Fabricu â€“ Eventstreams, Spark Structured Streaming, Eventhouse, KQL Database a Kusto Query Language (KQL).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- CÃ­l: umÄ›t rozliÅ¡it batch vs realâ€‘time, znÃ¡t realtime komponenty Fabricu a zÃ¡klady KQL pro DPâ€‘700.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    

---

## 1. Batch vs realâ€‘time systÃ©my

- Batch processing = vÅ¡e, co uÅ¾ z DPâ€‘700 znÃ¡Å¡: Data Pipelines, Dataflows, notebooky spouÅ¡tÄ›nÃ© na plÃ¡n; dÄ›lajÃ­ historickou analÃ½zu s urÄitou latencÃ­ mezi vznikem dat a analÃ½zou.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- Realâ€‘time systÃ©my zpracujÃ­ data kontinuÃ¡lnÄ› (stream), majÃ­ malou latenci a vyplatÃ­ se pro specifickÃ© scÃ©nÃ¡Å™e (senzory, logy, bezpeÄnost, fraud, online produkty).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    

PÅ™Ã­klady, kde se realâ€‘time vyplatÃ­:[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹

- Cyberâ€‘physical / IoT: logistika, doprava, prÅ¯mysl, zemÄ›dÄ›lstvÃ­.
    
- DigitÃ¡lnÃ­ aplikace: finanÄnÃ­ fraud detection, kyberbezpeÄnost, aplikaÄnÃ­ logy.
    
- Big tech: web/app telemetry, UX optimalizace, realâ€‘time doporuÄovÃ¡nÃ­.
    

---

## 2. Realtime stack ve Fabricu â€“ pÅ™ehled

- Batch nÃ¡stroje: Data Pipelines, Dataflows, Spark batch, Warehouse, Lakehouse â€“ poÅ™Ã¡d zÃ¡klad pro vÄ›tÅ¡inu scÃ©nÃ¡Å™Å¯.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- Realâ€‘time nÃ¡stroje:
    
    - **Eventstreams** â€“ nÃ­zkokÃ³dovÃ½ streamâ€‘ingest + jednoduchÃ© transformace + zÃ¡pis do cÃ­lovÃ½ch ÃºloÅ¾iÅ¡Å¥.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        
    - **Spark Structured Streaming** â€“ plnÄ› kÃ³dovÃ½ streaming nad Sparkem, vhodnÃ½ pro komplexnÄ›jÅ¡Ã­ transformace.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        
    - **Eventhouse** â€“ kontejner pro KQL databÃ¡ze.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        
    - **KQL Database** â€“ realtime analytickÃ© ÃºloÅ¾iÅ¡tÄ› pro logy/telemetrii.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        
    - **KQL dashboards** a dalÅ¡Ã­ vizualizace nad KQL.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        

DoplÅˆky: alerting, monitoring a optimalizace (KQL i Eventstreams), dÅ¯leÅ¾itÃ© pro DPâ€‘700, ale ve videu nejsou stÅ™edobodem.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹

---

## 3. Eventstreams â€“ zdroje, transformace, cÃ­le

## Zdroje (sources)

- Azure PaaS pro streaming:
    
    - Azure Event Hubs.
        
    - Azure IoT Hub.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        
- Cloud DB s CDC (change data capture):
    
    - Azure SQL Database.
        
    - Azure Cosmos DB.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        
- TÅ™etÃ­ strany: Kafka, Google Pub/Sub, Amazon Kinesis apod.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- Fabric/Azure event triggery: zmÄ›ny v OneLake, workspace events a dalÅ¡Ã­ Fabric udÃ¡losti.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- Custom endpoint: Eventstream poskytne vlastnÃ­ HTTP endpoint, kam mÅ¯Å¾eÅ¡ pÅ™Ã­mo postovat eventy (napÅ™. z aplikace nebo zaÅ™Ã­zenÃ­).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- Sample data: Fabric nabÃ­zÃ­ vzorovÃ© streamy (napÅ™. bike sharing, taxi), vhodnÃ© na trÃ©nink.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    

## Transformace (operations)

DostupnÃ© operace nad streamem:[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹

- Aggregate â€“ agregace nad ÄasovÃ½m oknem (napÅ™. AVG, SUM za minutu).
    
- Group By + Windows â€“ agregace podle klÃ­Äe + ÄasovÃ¡ okna (tumbling, hopping, sliding, snapshot, session).
    
- Expand â€“ rozbalenÃ­ seznamÅ¯/array do jednotlivÃ½ch Å™Ã¡dkÅ¯.
    
- Filter â€“ filtrovÃ¡nÃ­ eventÅ¯ dle podmÃ­nek.
    
- Join â€“ join dvou streamÅ¯ na spoleÄnÃ½ klÃ­Ä.
    
- Union â€“ vertikÃ¡lnÃ­ spojenÃ­ dvou streamÅ¯ se stejnÃ½m schÃ©matem.
    
- Manage Fields â€“ vÃ½bÄ›r sloupcÅ¯ a zmÄ›na datovÃ½ch typÅ¯ (klÃ­ÄovÃ© pro sprÃ¡vnÃ© agregace a Ãºsporu dat).
    

## CÃ­le (destinations)

- Custom endpoint â€“ zpÄ›tnÃ© posÃ­lÃ¡nÃ­ dat do jinÃ© aplikace/sluÅ¾by.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- Fabric data stores:
    
    - Lakehouse (souborovÃ¡/tabulkovÃ¡ podoba, napÅ™. pro historii nebo dalÅ¡Ã­ zpracovÃ¡nÃ­).
        
    - Eventhouse (KQL databÃ¡ze, primÃ¡rnÃ­ realtime analytickÃ© ÃºloÅ¾iÅ¡tÄ›).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        
- Derived stream â€“ vÃ½stup z jednoho Eventstreamu se pouÅ¾ije jako vstup do jinÃ©ho (Å™etÄ›zenÃ­ streamÅ¯).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- Activator â€“ definice alertÅ¯ nad streamem (podmÃ­nky typu â€hodnota > Xâ€œ).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    

## PraktickÃ½ pÅ™Ã­klad UI â€“ bike sharing

- Source: sample dataset â€Bicyclesâ€œ (bike sharing v LondÃ½nÄ›) s atributy jako `BikePointId`, ulice, ÄtvrÅ¥, `NbBikes`, `NbEmptyDocks`.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- Jedna vÄ›tev: pÅ™Ã­mÃ½ zÃ¡pis (direct ingestion) do KQL tabulky v Eventhouse bez transformacÃ­.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- DruhÃ¡ vÄ›tev: `Manage Fields` (vÃ½bÄ›r jen nÄ›kolika sloupcÅ¯ + `current_time` pÅ™es `system.timestamp`) â†’ `Filter` na `NbBikes = 0` â†’ zÃ¡pis do tabulky `EmptyRacks` v KQL DB.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    

---

## 4. Time window typy v Eventstreams (Group By)

CÃ­l: definovat, nad jakÃ½m ÄasovÃ½m Ãºsekem se poÄÃ­tajÃ­ agregace.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹

- **Tumbling window**
    
    - PevnÃ¡ dÃ©lka, okna se nepÅ™ekrÃ½vajÃ­.
        
    - PÅ™Ã­klad: prÅ¯mÄ›rnÃ¡ teplota v mÃ­stnosti za kaÅ¾dou hodinu (24 hodnot za den).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        
- **Hopping window**
    
    - PevnÃ¡ dÃ©lka, okna se pÅ™ekrÃ½vajÃ­ (definuje se window size + hop size).
        
    - PÅ™Ã­klad: 60s okno, 30s hop â†’ novÃ½ agregÃ¡t kaÅ¾dÃ½ch 30s, data se ÄÃ¡steÄnÄ› pÅ™ekrÃ½vajÃ­; vÃ­ce granularnÃ­ sledovÃ¡nÃ­ trendu.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        
- **Sliding window**
    
    - PevnÃ¡ dÃ©lka, okno se â€posouvÃ¡â€œ pÅ™es vÅ¡echny moÅ¾nÃ© pozice (Å¾Ã¡dnÃ½ explicitnÃ­ hop).
        
    - ÄŒasto se kombinuje s filtrem (napÅ™. emit event pouze, pokud v poslednÃ­ch 10s > 300 udÃ¡lostÃ­).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        
- **Snapshot window**
    
    - Agregace nad â€burstâ€œ dat, kterÃ¡ dorazÃ­ se stejnÃ½m timestampem (jednorÃ¡zovÃ½ snapshot).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        
- **Session window**
    
    - PromÄ›nnÃ¡ dÃ©lka, neâ€‘pÅ™ekrÃ½vajÃ­cÃ­ se okna; okno reprezentuje â€sessionâ€œ (napÅ™. nÃ¡vÅ¡tÄ›vu webu od pÅ™Ã­chodu po odchod).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        

PÅ™Ã­klad z taxi dat:[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹

- Source: â€Yellow Taxiâ€œ sample (vysokÃ¡ datovÃ¡ frekvence).
    
- `Manage Fields`: pÅ™evod `VendorId`, `PassengerCount`, `FareAmount` ze stringu na ÄÃ­sla (nutnÃ© pro agregace).
    
- TÅ™i rÅ¯znÃ© Group By uzly:
    
    - Hopping window â€“ SUM fare amount per `VendorId`, window 60s, hop 30s.
        
    - Tumbling window â€“ SUM fare per `VendorId` kaÅ¾dÃ½ch 60s.
        
    - Sliding window â€“ COUNT Å™Ã¡dkÅ¯ v 10s oknÄ› + filtr COUNT > 300 â†’ vÃ½stup jen pÅ™i detekci â€peakâ€œ provozu.
        

---

## 5. Spark Structured Streaming ve Fabricu

## Koncept

- Spark Structured Streaming = souÄÃ¡st Apache Spark; ve Fabricu dostupnÃ½ v Spark notebooks.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- Stream je reprezentovanÃ½ jako **unbounded table** â€“ novÃ© eventy = novÃ© Å™Ã¡dky; API vychÃ¡zÃ­ ze Spark SQL / DataFrame API, takÅ¾e kÃ³d pro batch a streaming je podobnÃ½.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    

## ZÃ¡kladnÃ­ pattern

- V kÃ³du se liÅ¡Ã­ hlavnÄ› `read` a `write`:[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
    - Batch: `spark.read` / `df.write`.
        
    - Streaming: `spark.readStream` / `df.writeStream`.
        

PÅ™Ã­klad (zjednoduÅ¡enÄ›):[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹

- `spark.readStream` z Azure Event Hubs (config connection string, event hub name).
    
- Definice schÃ©matu.
    
- Transformace nad DataFrame (select/withColumn/filter/aggregations).
    
- `df.writeStream` do cÃ­le (napÅ™. lakehouse).
    

## Eventstreams vs Spark Structured Streaming

Kdy preferovat Eventstreams:[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹

- Low/noâ€‘code poÅ¾adavek.
    
- Zdroj je podporovanÃ½ konektor eventstreamu.
    
- Transformace jsou relativnÄ› jednoduchÃ© (filter, group by, jednoduchÃ¡ okna, zmÄ›na typÅ¯).
    
- ChceÅ¡ snadno streamovat do KQL DB, Activator, dalÅ¡Ã­ch Eventstreams.
    

Kdy preferovat Spark Structured Streaming:[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹

- MÃ¡Å¡ existujÃ­cÃ­ Spark/Spark Streaming kÃ³d (napÅ™. z jinÃ©ho cloudu).
    
- TÃ½m je â€codeâ€‘heavyâ€œ a preferuje unit testing, robustnÃ­ CI/CD.
    
- PotÅ™ebujeÅ¡ komplexnÄ›jÅ¡Ã­ transformace nebo vlastnÃ­ logiku, kterÃ¡ pÅ™ekraÄuje moÅ¾nosti GUI Eventstreams.
    
- ChceÅ¡ streamovat primÃ¡rnÄ› do Lakehouse a dÃ¡le to zpracovat Sparkem, pÅ™iÄemÅ¾ KQL pouÅ¾ijeÅ¡ jen pÅ™es shortcut/mirroring.
    

---

## 6. Eventhouse a KQL Database

## Eventhouse

- Eventhouse = kontejner na vÃ­ce KQL databÃ¡zÃ­ (organizace a sprÃ¡va).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- UmoÅ¾Åˆuje nastavit minimÃ¡lnÃ­ spotÅ™ebu (min consumption) â€“ kontrola nÃ¡kladÅ¯ na realtime workload.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- MÅ¯Å¾e mÃ­t pluginy (napÅ™. Python language extension pro KQL, novÄ›jÅ¡Ã­ schopnosti).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    

## KQL Database â€“ co tam najdeÅ¡

- ÃšloÅ¾iÅ¡tÄ› pro realtime/log data, na kterÃ¡ dotazujeÅ¡ pÅ™es Kusto Query Language.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- UI prvky:
    
    - Tvorba novÃ½ch KQL tabulek, materializovanÃ½ch views, funkcÃ­, update policies.
        
    - Get data z OneLake (Lakehouse tables) formou shortcuts â€“ napÅ™. pro referenÄnÃ­ tabulky senzorÅ¯.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        
    - Data policies:
        
        - Retention â€“ jak dlouho data drÅ¾et (napÅ™. 30 dnÃ­ vs unlimited).
            
        - Caching â€“ hot vs cold cache (rychlost vs cena).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
            
- OneLake integration:
    
    - Lze zapnout globÃ¡lnÄ› pro DB nebo per table.
        
    - ZpÅ™Ã­stupnÃ­ data pÅ™es OneLake pro dalÅ¡Ã­ nÃ¡stroje (shortcuts, crossâ€‘engine scÃ©nÃ¡Å™e).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        
- Struktura v levÃ©m panelu:
    
    - Tables â€“ KQL tabulky (napÅ™. plnÄ›nÃ© Eventstreamem).
        
    - Shortcuts â€“ odkazy na tabulky z Lakehouse apod.
        
    - Materialized views â€“ pÅ™edpoÄÃ­tanÃ© agregace.
        
    - Functions â€“ opakovanÄ› pouÅ¾itelnÃ© kousky KQL logiky.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
        

---

## 7. ZÃ¡klady KQL pro DPâ€‘700 (konceptuÃ¡lnÄ›)

(Ve videu je velkÃ½ blok praktickÃ½ch KQL ukÃ¡zek â€“ Basics, Filtering, Aggregates, Management commands.)[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹

KlÃ­ÄovÃ© oblasti, kterÃ© je potÅ™eba znÃ¡t:[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹

- ZÃ¡kladnÃ­ syntaxe: `TableName | take`, `project`, `extend`, `where`, `order by`.
    
- FiltrovÃ¡nÃ­: rÅ¯znÃ© formy `where` (relace, in, contains, between), prÃ¡ce s datetime, textovÃ½mi funkcemi.
    
- Agregace: `summarize` (COUNT, SUM, AVG, MIN, MAX, percentily, atd.) + groupovÃ¡nÃ­ podle jednoho Äi vÃ­ce sloupcÅ¯.
    
- Joiny: `join`, `union`, `lookup` na jinÃ© tabulky / shortcuts.
    
- Window funkce: `summarize` s `bin()`, time windowing v KQL (jinÃ© API neÅ¾ v Eventstreams, ale podobnÃ© koncepty).
    
- Management commands: vytvÃ¡Å™enÃ­ tabulek, materializovanÃ½ch views, update policies, kontrola schÃ©matu a metadat.
    

---

## 8. Co si odnÃ©st pro DPâ€‘700 (realâ€‘time ÄÃ¡st)

- RozumÄ›t rozdÃ­lu batch vs realtime a vÄ›dÄ›t, kdy se realâ€‘time vyplatÃ­ (typickÃ© scÃ©nÃ¡Å™e a domÃ©ny).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- ZnÃ¡t roli Eventstreams: jakÃ© zdroje umÃ­, jakÃ© jednoduchÃ© transformace zvlÃ¡dnou a kam zapisujÃ­ data (Lakehouse, Eventhouse/KQL, Activator).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- UmÄ›t vysvÄ›tlit typy ÄasovÃ½ch oken (tumbling, hopping, sliding, snapshot, session) a jejich typickÃ© useâ€‘casy.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- VÄ›dÄ›t, kdy pouÅ¾Ã­t Spark Structured Streaming mÃ­sto Eventstreams (komplexita transformacÃ­, existujÃ­cÃ­ kÃ³d, preferovanÃ½ stack).[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    
- Orientovat se v pojmech Eventhouse, KQL Database, KQL queries, materializovanÃ© views, retention/caching policy a OneLake integration.[youtube](https://www.youtube.com/watch?v=ZGCAPLtj-bI)â€‹
    

1. [https://www.youtube.com/watch?v=ZGCAPLtj-bI](https://www.youtube.com/watch?v=ZGCAPLtj-bI)
2. [https://www.skool.com/microsoft-fabric/classroom/4a13f708?md=6e7d10aea3f641c89011e5155558a835](https://www.skool.com/microsoft-fabric/classroom/4a13f708?md=6e7d10aea3f641c89011e5155558a835)
---
---

# ğŸš€ Monitor & Optimize Solutions
# Monitor & Optimize Solutions v Microsoft Fabric | DPâ€‘700 (Video 10/11) [youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹

## Struktura videa a mindset

- Video pokrÃ½vÃ¡ celou sekci 3 DPâ€‘700: monitorovÃ¡nÃ­, errorâ€‘handling a optimalizaci napÅ™Ã­Ä Fabricem (globÃ¡lnÃ­ nÃ¡stroje, data processing tools, datovÃ¡ ÃºloÅ¾iÅ¡tÄ›, semantic models).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- Jde hlavnÄ› o â€run & improveâ€œ fÃ¡zi: sledovÃ¡nÃ­ produkÄnÃ­ch Å™eÅ¡enÃ­, Å™eÅ¡enÃ­ chyb a postupnÃ© zlepÅ¡ovÃ¡nÃ­ vÃ½konu a nÃ¡kladÅ¯.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    

---

## 1. Fabricâ€‘wide monitorovÃ¡nÃ­

## Monitoring Hub (tenant level)

- CentrÃ¡lnÃ­ pÅ™ehled bÄ›hÅ¯ Fabric artefaktÅ¯ (pipelines, Dataflow Gen2, notebooks, Spark Job Definitions, semantic model refreshes atd.).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- U kaÅ¾dÃ©ho bÄ›hu vidÃ­Å¡: stav (Succeeded/Failed/Running), typ itemu, start/end time, workspace, autora; filtrujeÅ¡ napÅ™. jen na â€Failedâ€œ a kliknutÃ­m se dostaneÅ¡ do detailu konkrÃ©tnÃ­ho nÃ¡stroje (napÅ™. pipeline run detail, semantic model refresh log).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    

## Capacity Metrics App (capacity level)

- Power BI app + semantic model pro sledovÃ¡nÃ­ **compute** (CU usage, throttling, overages) a **storage** v rÃ¡mci jednÃ© capacity (napÅ™. F64).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- KlÃ­ÄovÃ© koncepty:
    
    - Throttling â€“ pokud CU > 100% delÅ¡Ã­ dobu, Fabric zaÄne odmÃ­tat nejdÅ™Ã­v interaktivnÃ­ Ãºlohy (UX), pak i background joby (pipelines, refresh).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
    - Overages / burndown â€“ pÅ™i pÅ™etÃ­Å¾enÃ­ si â€pÅ¯jÄujeÅ¡â€œ CU z budoucÃ­ch intervalÅ¯, coÅ¾ se zobrazuje v burndown grafech.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
- App mÅ¯Å¾eÅ¡ ruÄnÄ› refreshovat a stavÄ›t na nÃ­ vlastnÃ­ reporty pÅ™es underlying semantic model.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    

## Workspace Monitoring (preview)

- NovÃ© nastavenÃ­ ve workspace: zapne se â€workspace monitoringâ€œ, Fabric vytvoÅ™Ã­ speciÃ¡lnÃ­ **monitoring Eventhouse** + KQL DB pro logy.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- Podporuje napÅ™.: Eventhouse (monitoring jinÃ½ch KQL DB), mirrored DB, semantic models, GraphQL operations; logy se zapisujÃ­ do KQL tabulek (raw logs, semantic model logs, mirror logs atd.).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- PlacenÃ¡ funkcionalita (navÃ­c ke standardnÃ­m nÃ¡kladÅ¯m), spÃ­Å¡ budoucÃ­ smÄ›r; do DPâ€‘700 se pravdÄ›podobnÄ› promÃ­tne jen na Ãºrovni â€existuje a co dÄ›lÃ¡â€œ.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    

---

## 2. Data Pipelines â€“ monitoring, chyby, optimalizace

## Monitoring a debugging

- ZaÄÃ­nÃ¡ v Monitoring Hubu â†’ kliknutÃ­m na bÄ›h pipeline pÅ™ejdeÅ¡ do **Pipeline run detail**.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- VidÃ­Å¡ stav kaÅ¾dÃ© aktivity, ForEach loopÅ¯, zÃ¡vislosti; chyby typicky: pÅ™ipojenÃ­, struktura dat, chybnÃ½ vÃ½raz.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- Pane â€Inputs/Outputsâ€œ u aktivit: ukazuje konkrÃ©tnÃ­ JSON vstup/vÃ½stup, klÃ­ÄovÃ© pro ladÄ›nÃ­ dynamickÃ½ch vÃ½razÅ¯ (napÅ™. `item().WorkspaceId`) a zmÄ›nÄ›nÃ© struktury.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    

## Odolnost a vÃ½kon (design time)

- **Retry** (Copy Data, Notebook activity): nastavÃ­Å¡ poÄet pokusÅ¯ + interval (napÅ™. 1 retry po 30 s) pro zvlÃ¡dnutÃ­ pÅ™echodnÃ½ch chyb (network, API vÃ½padek).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- **Copy Data â€“ Settings**:
    
    - Intelligent throughput (4â€“256) â€“ kolik CPU copy job dostane (rychlost vs CU).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
    - Degree of copy parallelism â€“ kolik paralelnÃ­ch vlÃ¡ken se pouÅ¾ije; default 128, ale mÅ¯Å¾eÅ¡ ladit.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
    - Fault tolerance â€“ skip invalid rows/files; vhodnÃ© u Å¡pinavÃ½ch dat, ale musÃ­Å¡ logovat, co bylo pÅ™eskoÄeno.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
    - Logging â€“ detailnÃ­ logy do Blob storage.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        

## Notifikace a architektura

- PodmÃ­nky propojenÃ­ aktivit (On Fail) Äasto vedou do notifikaÄnÃ­ch aktivit (Office 365, Teams, pÅ™Ã­padnÄ› webhook â†’ Slack/API).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- Best practice: nespouÅ¡tÄ›t notifikaci u kaÅ¾dÃ© drobnÃ© aktivity; radÄ›ji parentâ€“child architektura a centralizovanÃ¡ notifikace v parent pipeline.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    

---

## 3. Dataflow Gen2 â€“ monitoring a optimalizace

## Monitoring

- ChybnÃ½ refresh se poznÃ¡ podle ikony chyby vedle poslednÃ­ho refresh time.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- KonkrÃ©tnÃ­ detaily: **Refresh history** â†’ seznam bÄ›hÅ¯, kaÅ¾dÃ½ mÃ¡ detail se stavem jednotlivÃ½ch tabulek a chybou (napÅ™. mismatch datovÃ½ch typÅ¯ pÅ™i write).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    

## OptimalizaÄnÃ­ techniky

- **Fast copy**
    
    - V settings zapneÅ¡ Fast copy, pak pro konkrÃ©tnÃ­ query â†’ â€Enable fast copyâ€œ.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
    - Ingest bÄ›Å¾Ã­ pÅ™es infrastrukturu Copy Data activity (pipeline engine), typicky levnÄ›jÅ¡Ã­/rychlejÅ¡Ã­ neÅ¾ bÄ›Å¾nÃ½ Dataflow.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
- **Staging**
    
    - Dataflow naÄte data ze zdroje â†’ zapÃ­Å¡e do staging Lakehouse/Warehouse â†’ provede transformace â†’ zapÃ­Å¡e do cÃ­le.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
    - VÃ½hodnÃ© u velkÃ½ch dat a mnoha transformacÃ­; u malÃ½ch dat pÅ™inÃ¡Å¡Ã­ spÃ­Å¡ overhead.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
- **Architektura Dataflows**
    
    - KomplexnÃ­ Dataflow s mnoha tabulkami je lepÅ¡Ã­ rozdÄ›lit na vÃ­ce menÅ¡Ã­ch Dataflow (1 query = 1 Dataflow) a orchestraci Å™eÅ¡it pÅ™es pipelines.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
    - Pokud ani tak vÃ½kon nevyhovuje, zvÃ¡Å¾it Copy activity nebo Spark/Notebook Å™eÅ¡enÃ­ (Äasto niÅ¾Å¡Ã­ CU neÅ¾ Dataflow Gen2).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        

---

## 4. Spark Notebooks & Spark Job Definitions

## Monitoring nÃ¡strojÅ¯ Spark

- **Monitoring Hub** â€“ seznam notebook/SJD bÄ›hÅ¯, stavy, filtr podle typu.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- KliknutÃ­ na bÄ›h â†’ Spark monitoring UI, odkud vede:
    
    - **Monitor run series** â€“ ÄasovÃ¡ Å™ada bÄ›hÅ¯ stejnÃ©ho jobu: duration, bytes read/write, CPU/shuffle metriky, anomÃ¡lie.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
    - **Spark History Server** â€“ web UI Spark enginu: event timeline, seznam jobs/stages/tasks, DAG/graph, diagnostika skews (data/time skew).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        

## Jak to vyuÅ¾Ã­t pro DPâ€‘700

- Monitoring Hub â€“ â€kde zjistÃ­m, jestli Spark job selhal/vyskoÄil Äasem?â€œ.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- Monitor run series â€“ â€kde sleduji, jak se vÃ½kon Spark jobu mÄ›nÃ­ v Äase?â€œ.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- Spark History Server â€“ â€kde najdu nejdetailnÄ›jÅ¡Ã­ pohled na Spark job (stages, DAG, skew)?â€œ.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    

---

## 5. Eventstreams â€“ monitoring

- **Data Insights** â€“ na kartÄ› Eventstreamu vidÃ­Å¡: incoming/outgoing messages (poÄty) a bytes, v Äase (napÅ™. poslednÃ­ hodina).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- **Runtime logs** â€“ tabulka logÅ¯ (Info/Warning/Error) s poÄtem vÃ½skytÅ¯ (napÅ™. 200Ã— output failure za poslednÃ­ch 24h), slouÅ¾Ã­ k detekci problÃ©mÅ¯ se zapisovÃ¡nÃ­m nebo zdrojem.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    

---

## 6. Data Warehouse â€“ monitoring & Vâ€‘Order

## Monitoring DW dotazÅ¯

- **Capacity Metrics App** â€“ pro analÃ½zu CU usage per Warehouse (kdyÅ¾ Å™eÅ¡Ã­Å¡ nÃ¡klady a throttling).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- **Query activity tab** v DW:
    
    - Query runs â€“ seznam vÅ¡ech Tâ€‘SQL dotazÅ¯: text, duration, timestamp, user, session id; moÅ¾nost cancel longâ€‘running query.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
    - Longâ€‘running queries â€“ agregace podle query textu: median duration, run count, last run duration (kandidÃ¡ti na optimalizaci).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
    - Frequently run queries â€“ agregace podle poÄtu bÄ›hÅ¯ (Äasto spouÅ¡tÄ›nÃ© dotazy â†’ taky kandidÃ¡ti na ladÄ›nÃ­).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
- **Query Insights schema** â€“ ÄtyÅ™i views (exec requests/sessions histories, frequently run queries, longâ€‘running queries) pÅ™Ã­stupnÃ© pÅ™es Tâ€‘SQL pro vlastnÃ­ analÃ½zy a reporty.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    

## Vâ€‘Order (optimalizace Delta souborÅ¯ v DW)

- Vâ€‘Order je proprietÃ¡rnÃ­ algoritmus pro optimalizovanÃ½ zÃ¡pis Parquet souborÅ¯ (rychlejÅ¡Ã­ ÄtenÃ­, napÅ™. pro Direct Lake).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- V DW je defaultnÄ› **ON** a platÃ­ pro celÃ½ warehouse. Lze vypnout pÅ™Ã­kazem `ALTER DATABASE CURRENT SET VORDER = OFF`, ale:
    
    - NastavenÃ­ je **nevratnÃ©** (nelze znovu zapnout).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
    - Typicky se zvaÅ¾uje v architekturÃ¡ch s vÃ­ce DW (raw/staging/analytics nebo bronze/silver/gold):
        
        - Raw/staging DW: dÅ¯leÅ¾itÃ¡ rychlost zÃ¡pisu â†’ moÅ¾nÃ¡ vypnout Vâ€‘Order.
            
        - Analytics/Gold DW: dÅ¯leÅ¾itÃ¡ rychlost ÄtenÃ­ (semantic models, reporting) â†’ nechat Vâ€‘Order zapnutÃ½.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
            

---

## 7. Lakehouse & Delta â€“ table maintenance a optimalizace

## Monitoring Lakehouse

- VÃ½kon Spark jobs nad Lakehouse sledujeÅ¡ stejnÃ½mi nÃ¡stroji jako u notebookÅ¯ (Monitoring Hub, Monitor run series, Spark History Server).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    

## Table Maintenance (UI)

- V Lakehouse lze pÅ™es **Maintenance** (rightâ€‘click na tabulce) spouÅ¡tÄ›t ÃºdrÅ¾bu Delta tabulek:
    
    - `OPTIMIZE` â€“ kompakce: sluÄuje malÃ© Parquet soubory do optimÃ¡lnÃ­ velikosti pro Spark, zrychluje ÄtenÃ­.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
    - Apply Vâ€‘Order â€“ aplikuje Vâ€‘Order algoritmus na Delta tabulku (optimalizuje layout pro ÄtenÃ­).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
    - `VACUUM` â€“ fyzicky maÅ¾e starÃ© soubory, kterÃ© uÅ¾ nejsou potÅ™eba pro time travel/transactions (uvolnÄ›nÃ­ mÃ­sta).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        

## KÃ³dovÃ¡ optimalizace

- StejnÃ© operace lze spouÅ¡tÄ›t programovÄ› (PySpark/SQL) pomocÃ­ Delta Lake API (`OPTIMIZE`, `VACUUM`, partitioning) â€“ vhodnÃ© pro pravidelnou ÃºdrÅ¾bu.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- Partitioning: sprÃ¡vnÃ© rozdÄ›lenÃ­ dat (napÅ™. podle data, regionu) vÃ½raznÄ› ovlivnÃ­ scan size a vÃ½kon dotazÅ¯; Å¡patnÃ© partitioning mÅ¯Å¾e naopak uÅ¡kodit (pÅ™Ã­liÅ¡ mnoho malÃ½ch partition).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    

---

## 8. Eventhouse & KQL â€“ monitoring a optimalizace

- Monitoring Eventhouse/KQL DB probÃ­hÃ¡ pÅ™es:
    
    - KQL query monitoring (UI a KQL management commands).
        
    - Workspace monitoring Eventhouse (speciÃ¡lnÃ­ monitorovacÃ­ KQL DB s logy, pokud je zapnut).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        
- Optimalizace KQL dotazÅ¯: prÃ¡ce se strukturou tabulek, vhodnÃ© indexovÃ¡nÃ­ v rÃ¡mci KQL, sprÃ¡vnÃ© vyuÅ¾itÃ­ summarizacÃ­, partitioning / retention a caching politiky (hot vs cold data).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    

---

## 9. Semantic Model refresh â€“ monitoring

- Refresh semantic modelÅ¯ se sleduje v Monitoring Hubu (typ â€Semantic model refreshâ€œ).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- Pro kaÅ¾dÃ½ bÄ›h uvidÃ­Å¡: status, duration, chyby (napÅ™. gateway issue, credential problÃ©m), lze pÅ™idat dalÅ¡Ã­ sloupce (capacity, average duration).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- Pro pokroÄilÃ© scÃ©nÃ¡Å™e lze vyuÅ¾Ã­t:
    
    - Capacity Metrics App (dopad refreshÅ¯ na CU).
        
    - Workspace monitoring (logy semantic modelÅ¯ v KQL DB).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
        

---

## 10. Co je klÃ­ÄovÃ© pro DPâ€‘700 (monitoring & optimalizace)

- VÄ›dÄ›t, kterÃ© nÃ¡stroje pouÅ¾Ã­t na jakÃ© Ãºrovni: Monitoring Hub (vÅ¡echny bÄ›hy), Capacity Metrics (CU & throttling), Workspace Monitoring (realtime logy v KQL), itemâ€‘level UI.[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    
- UmÄ›t popsat zÃ¡kladnÃ­ optimalizaÄnÃ­ pÃ¡ky: retry & copy settings v pipelines, Fast copy/staging v Dataflow Gen2, Spark monitorovacÃ­ nÃ¡stroje, Query Activity & Query Insights v DW, Vâ€‘Order strategie, Delta table maintenance v Lakehouse, a logovÃ¡nÃ­/alerty (Teams/O365/Activator).[youtube](https://www.youtube.com/watch?v=0M4t6ljwZ9A)â€‹
    

1. [https://www.youtube.com/watch?v=0M4t6ljwZ9A](https://www.youtube.com/watch?v=0M4t6ljwZ9A)
2. [https://www.skool.com/microsoft-fabric/classroom/4a13f708?md=430041e3861d421d83a8f3f60bae68a0](https://www.skool.com/microsoft-fabric/classroom/4a13f708?md=430041e3861d421d83a8f3f60bae68a0)
---
---

# ğŸš€ Exam Tips and Tricks
# DPâ€‘700 Exam Tips & Tricks (Video 11/11)skool+1â€‹

## 1. PÅ™ed zkouÅ¡kou â€“ rezervace a forma

- ZkouÅ¡ku rezervuj vÅ¾dy na **osobnÃ­ eâ€‘mail**, aby certifikace zÅ¯stala navÃ¡zanÃ¡ na tebe, ne na zamÄ›stnavatele (firemnÃ­ ÃºÄet lze pozdÄ›ji slouÄit, ale je to zbyteÄnÃ¡ komplikace).[skool](https://www.skool.com/microsoft-fabric/steal-my-exam-technique-to-pass-the-dp-700-first-time-video-11-of-11)â€‹
    
- Pokud mÅ¯Å¾eÅ¡, zvol **test centrum**: odpadÃ¡ instalace proctoring softwaru, problÃ©my s kamerou i riziko pÃ¡du zkouÅ¡ky; domÃ¡cÃ­ forma vyÅ¾aduje instalaci nÃ¡stroje, vyklizenÃ½ stÅ¯l, jeden monitor a je ÄastÄ›jÅ¡Ã­m zdrojem technickÃ½ch potÃ­Å¾Ã­.[skool](https://www.skool.com/microsoft-fabric/steal-my-exam-technique-to-pass-the-dp-700-first-time-video-11-of-11)â€‹
    

---

## 2. Jak se pÅ™ipravovat (obsah + praxe)

- NestaÄÃ­ jen projÃ­t video kurz â€“ DPâ€‘700 poÄÃ­tÃ¡ s **handsâ€‘on zkuÅ¡enostÃ­ ve Fabricu** (pipelines, Lakehouse/Warehouse, Spark, KQL, security, monitoring).learn.microsoft+1â€‹
    
- ZÃ¡klad: projÃ­t znovu celÃ½ kurz, doplnit dokumentacÃ­ na Learn, pouÅ¾Ã­t handsâ€‘on laby (Fabric Dojo, oficiÃ¡lnÃ­ Microsoft moduly, dalÅ¡Ã­ tvÅ¯rci jako Valerie Y., Alexey P., Abu Bakar Ali) a dÄ›lat si poznÃ¡mky z vlastnÃ­ch scÃ©nÃ¡Å™Å¯.learn.microsoft+1â€‹
    

---

## 3. Struktura zkouÅ¡ky a Äas

- DostaneÅ¡ cca **52â€“58 otÃ¡zek** a **100 minut ÄistÃ©ho Äasu** na odpovÄ›di; v tom je typicky **1 case study (8â€“10 otÃ¡zek)**.scribd+1â€‹
    
- Case study mÅ¯Å¾e bÃ½t **na zaÄÃ¡tku nebo na konci**; nelze se k nÃ­ vrÃ¡tit, jakmile ji uzavÅ™eÅ¡, takÅ¾e je nutnÃ© mÃ­t pÅ™edem jasnou strategii pro rozdÄ›lenÃ­ Äasu.scribd+1â€‹
    

---

## 4. Strategie, kdyÅ¾ je case study na ZAÄŒÃTKU

- **Case study**: alokuj ~30 minut (â‰ˆ 2 min na otÃ¡zku) â€“ Äti scÃ©nÃ¡Å™ jen jednou, pak Å™eÅ¡ otÃ¡zky, a snaÅ¾ se skonÄit dÅ™Ã­v, abys zÃ­skal pÃ¡r minut rezervy.[skool](https://www.skool.com/microsoft-fabric/steal-my-exam-technique-to-pass-the-dp-700-first-time-video-11-of-11)â€‹
    
- Zbytek (~70 min) vÄ›nuj **cca 45 ostatnÃ­m otÃ¡zkÃ¡m**, cÃ­l je **1 minuta na otÃ¡zku**:
    
    - Pokud odpovÄ›Ä vÃ­Å¡: odpovÄ›z a jdi dÃ¡l.
        
    - Pokud si nejsi jistÃ½: **tipni, oznaÄ â€Mark for reviewâ€œ**, ale nezdrÅ¾uj se u nÃ­ dÃ©le neÅ¾ minutu.[skool](https://www.skool.com/microsoft-fabric/steal-my-exam-technique-to-pass-the-dp-700-first-time-video-11-of-11)â€‹
        
- PoslednÃ­ch ~10â€“15 min vyuÅ¾ij na nÃ¡vrat k oznaÄenÃ½m otÃ¡zkÃ¡m a teprve teÄ otevÅ™i Learn dokumentaci pro ovÄ›Å™enÃ­ konkrÃ©tnÃ­ho detailu.[skool](https://www.skool.com/microsoft-fabric/steal-my-exam-technique-to-pass-the-dp-700-first-time-video-11-of-11)â€‹
    

---

## 5. Strategie, kdyÅ¾ je case study na KONCI

- PrvnÃ­ch ~70 minut Å™eÅ¡Ã­Å¡ **vÅ¡echny â€bÄ›Å¾nÃ©â€œ otÃ¡zky**:
    
    - CÃ­l: projÃ­t **vÅ¡ech cca 45 otÃ¡zek** do 70. minuty (opÄ›t cca 1 min/otÃ¡zka).[skool](https://www.skool.com/microsoft-fabric/steal-my-exam-technique-to-pass-the-dp-700-first-time-video-11-of-11)â€‹
        
    - Princip: rychlÃ© rozhodnutÃ­, pÅ™Ã­padnÄ› tip + â€Mark for reviewâ€œ, Learn ignoruj aÅ¾ do doby, kdy jsi vidÄ›l vÅ¡echny otÃ¡zky.[skool](https://www.skool.com/microsoft-fabric/steal-my-exam-technique-to-pass-the-dp-700-first-time-video-11-of-11)â€‹
        
- ZbylÃ½ch ~30 minut vÄ›nuj case study (8â€“10 otÃ¡zek); protoÅ¾e se nelze vracet, case study Å™eÅ¡ v kuse a bez spolehÃ¡nÃ­ na to, Å¾e â€se k nÃ­ vrÃ¡tÃ­Å¡ pozdÄ›jiâ€œ.scribd+1â€‹
    

---

## 6. Jak (ne)pouÅ¾Ã­vat Microsoft Learn bÄ›hem zkouÅ¡ky

- Learn mÃ¡Å¡ bÄ›hem DPâ€‘700 povolenÃ½, ale je to **nejÄastÄ›jÅ¡Ã­ past na Äas** â€“ lidÃ© trÃ¡vÃ­ 5â€“10 minut u jednÃ© otÃ¡zky a pak nestihnou zbytek testu.[skool](https://www.skool.com/microsoft-fabric/steal-my-exam-technique-to-pass-the-dp-700-first-time-video-11-of-11)â€‹
    
- DoporuÄenÃ½ pÅ™Ã­stup:
    
    - **PrvnÃ­ prÅ¯chod**: Learn nepouÅ¾Ã­vej, jen odpovÃ­dej / tipuj a znaÄ otÃ¡zky pro review.
        
    - **Review fÃ¡ze**: cÃ­lenÄ› vyhledej 3â€“5 nejspornÄ›jÅ¡Ã­ch otÃ¡zek a pomocÃ­ Learn si ovÄ›Å™ konkrÃ©tnÃ­ syntaxi/feature (ne ÄÃ­st celÃ© ÄlÃ¡nky).[skool](https://www.skool.com/microsoft-fabric/steal-my-exam-technique-to-pass-the-dp-700-first-time-video-11-of-11)â€‹
        

---

## 7. Taktika pro jednotlivÃ© otÃ¡zky

- KaÅ¾dou otÃ¡zku + odpovÄ›di si jednou celÃ© pÅ™eÄti; nezaÄÃ­nej â€pÅ™eskakovatâ€œ text, jinak ti uteÄou podmÃ­nky (poÅ¾adavek na lowâ€‘code, onâ€‘prem, realâ€‘time, minimalizaci nÃ¡kladÅ¯ atd.).[skool](https://www.skool.com/microsoft-fabric/steal-my-exam-technique-to-pass-the-dp-700-first-time-video-11-of-11)â€‹
    
- Pokud jsi **>90% jistÃ½**, odpovÄ›z a pokraÄuj; pokud ne, zvol nejlepÅ¡Ã­ kandidÃ¡t, otÃ¡zku oznaÄ pro review a jdi dÃ¡l â€“ **neexistuje negativnÃ­ bodovÃ¡nÃ­**, takÅ¾e tip je vÅ¾dy lepÅ¡Ã­ neÅ¾ prÃ¡zdnÃ¡ odpovÄ›Ä.reddit+1â€‹
    

---

## 8. Po zkouÅ¡ce â€“ vÃ½sledek a dalÅ¡Ã­ kroky

- VÃ½sledek (pass/fail) se dozvÃ­Å¡ okamÅ¾itÄ›; detailnÃ­ report ukÃ¡Å¾e, ve kterÃ½ch sekcÃ­ch jsi byl pod hranicÃ­ (Å¡kÃ¡la 100â€“1000, pass je 700).shabnamwatson+1â€‹
    
- PÅ™i neÃºspÄ›chu pouÅ¾ij report k identifikaci slabÅ¡Ã­ch oblastÃ­ a zapracuj na nich (dalÅ¡Ã­ handsâ€‘on, dokumentace, cÃ­lenÃ© laby), pak znovu naplÃ¡nuj termÃ­n; pÅ™i ÃºspÄ›chu poÄÃ­tej s **roÄnÃ½m online recertem zdarma**, kterÃ½ ovÄ›Å™uje, Å¾e sledujeÅ¡ novinky ve Fabricu.learn.microsoft+1â€‹
    

1. [https://www.skool.com/microsoft-fabric/steal-my-exam-technique-to-pass-the-dp-700-first-time-video-11-of-11](https://www.skool.com/microsoft-fabric/steal-my-exam-technique-to-pass-the-dp-700-first-time-video-11-of-11)
2. [https://www.youtube.com/playlist?list=PLug2zSFKZmV2Ue5udYFeKnyf1Jj0-y5Gy](https://www.youtube.com/playlist?list=PLug2zSFKZmV2Ue5udYFeKnyf1Jj0-y5Gy)
3. [https://learn.microsoft.com/en-us/credentials/certifications/resources/study-guides/dp-700](https://learn.microsoft.com/en-us/credentials/certifications/resources/study-guides/dp-700)
4. [https://www.scribd.com/document/949100012/DP-700-Q-A](https://www.scribd.com/document/949100012/DP-700-Q-A)
5. [https://www.reddit.com/r/MicrosoftFabric/comments/1l98x7y/passed_dp_700_some_basic_advice/](https://www.reddit.com/r/MicrosoftFabric/comments/1l98x7y/passed_dp_700_some_basic_advice/)
6. [https://shabnamwatson.com/2025/02/05/how-i-passed-dp-700-implementing-data-engineering-solutions-using-microsoft-fabric/](https://shabnamwatson.com/2025/02/05/how-i-passed-dp-700-implementing-data-engineering-solutions-using-microsoft-fabric/)
7. [https://www.youtube.com/watch?v=05rEidzRgkY](https://www.youtube.com/watch?v=05rEidzRgkY)
8. [https://www.skool.com/microsoft-fabric/classroom/4a13f708?md=c1e534c04b364d1aa714cfce4a84fe1c](https://www.skool.com/microsoft-fabric/classroom/4a13f708?md=c1e534c04b364d1aa714cfce4a84fe1c)
9. [https://www.youtube.com/watch?v=KiB4eAeFRsw](https://www.youtube.com/watch?v=KiB4eAeFRsw)
10. [https://www.youtube.com/watch?v=38cLTNoPLu0](https://www.youtube.com/watch?v=38cLTNoPLu0)
11. [https://www.skool.com/microsoft-fabric/passed-dp-900-exam-tips?p=2b8543a6](https://www.skool.com/microsoft-fabric/passed-dp-900-exam-tips?p=2b8543a6)
12. [https://www.exam-labs.com/blog/microsoft-fabric-data-engineering-dp-700-a-streamlined-certification-guide-for-2025](https://www.exam-labs.com/blog/microsoft-fabric-data-engineering-dp-700-a-streamlined-certification-guide-for-2025)
13. [https://www.youtube.com/channel/UCrvoIYkzS-RvCEb0x7wfmwQ/about](https://www.youtube.com/channel/UCrvoIYkzS-RvCEb0x7wfmwQ/about)
14. [https://testpreptraining.com/blog/microsoft-dp-700-study-guide-exam-preparation-resources/](https://testpreptraining.com/blog/microsoft-dp-700-study-guide-exam-preparation-resources/)
15. [https://www.reddit.com/r/MicrosoftFabric/comments/1mw4vxg/from_scratch_data_engineer_beginner_to_passing/](https://www.reddit.com/r/MicrosoftFabric/comments/1mw4vxg/from_scratch_data_engineer_beginner_to_passing/)
16. [https://www.reddit.com/r/MicrosoftFabric/comments/1ijcxn5/tips_guide_and_resources/](https://www.reddit.com/r/MicrosoftFabric/comments/1ijcxn5/tips_guide_and_resources/)
17. [https://sqlbits.com/attend/the-agenda-2025/thursday/From_Zero_to_DP-700_in_a_Day_Get_Ready_for_Fabric_Data_Engineer_Associate_Certification](https://sqlbits.com/attend/the-agenda-2025/thursday/From_Zero_to_DP-700_in_a_Day_Get_Ready_for_Fabric_Data_Engineer_Associate_Certification)
18. [https://www.youtube.com/watch?v=jTDSP7KBavI](https://www.youtube.com/watch?v=jTDSP7KBavI)
19. [https://www.youtube.com/watch?v=XECqSfKmtCk](https://www.youtube.com/watch?v=XECqSfKmtCk)
20. [https://www.examtopics.com/discussions/microsoft/view/154905-exam-dp-700-topic-2-question-3-discussion/](https://www.examtopics.com/discussions/microsoft/view/154905-exam-dp-700-topic-2-question-3-discussion/)
21. [https://www.linkedin.com/posts/learnmicrosoftfabric_dp700-microsoftfabric-dataengineering-activity-7285311090819743744-YUQ-](https://www.linkedin.com/posts/learnmicrosoftfabric_dp700-microsoftfabric-dataengineering-activity-7285311090819743744-YUQ-)