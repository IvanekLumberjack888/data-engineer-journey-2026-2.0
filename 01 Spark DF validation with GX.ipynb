{"cells":[{"cell_type":"markdown","source":["# Spark dataframe validation with Great Expectations\n","Created by Will Needham, [Learn Microsoft Fabric](https://youtube.com/@learnmicrosoftfabric) \n","\n","**Goal: show you a simple way to setup Great Expectations to perform validation of a Spark DataFrame.** \n","\n","_Note: the approach shown in this notebook is what I would call 'GX Lite'. GX is a vast library with lots of different features, but it can be overwhelming for beginners. I have developed the approach below to strip out a lot of the complexity and make it as easy as possible to get started with GX. Once you get the basics, it would be worthwhile learning about getting up Data Sources, Expectation Suites, Checkpoints etc, as these unlock more of the GX advanced features, like Actions, Data Docs etc._\n","\n","In the example, we are validating Spark Dataframe objects. The idea is to validate Spark dataframe after we perform some transformation/ cleaning on a dataset, before we write it to a new layer of our pipeline.\n","\n","## Prerequisites\n","This notebook assumes you have run the first notebook, and have a Lakehouse table named 'raw_customers'.  \n","\n","## Define Lakehouse table name to be validated \n","We make use of a parameter cell in Fabric to be able to parameterize the notebook (i.e. so we can embed this validation notebook into a Fabric Data Pipeline)"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5ae1229b-216d-4a40-993a-34e525b45c80"},{"cell_type":"code","source":["table_name_to_be_validated = 'raw_customers'\n","output_table_name = 'validated_customers'"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"tags":["parameters"]},"id":"f741460b-cdd8-493f-9dbf-6ea43320c0d2"},{"cell_type":"markdown","source":["## Install GX (if not installed at the workspace level)"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"170b6fd9-9d06-4581-b9de-41ef6e592b95"},{"cell_type":"code","source":["%pip install --q great_expectations"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"f98b3b92-113e-473c-8fb6-952c7336cae5"},{"cell_type":"markdown","source":["## Get, transform/clean a Lakehouse table\n","I define a parsing function just to show where in the workflow you would use this. Actual parsing/ cleaning has not been implemented, this is dependent on your data/ requirements. "],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"cf56062e-b8a0-4828-abf9-09d9d2f96442"},{"cell_type":"code","source":["def parse_and_clean_df(df): \n","    ''' Input: Spark dataframe in Raw state, \n","    Function: clean and transform your raw DF depending on business logic/ dataset (not implemented in this example) \n","    Return: clean_df (of type Spark Dataframe)\n","    '''\n","    clean_df = df \n","    return clean_df\n","\n","\n","# read in the raw table \n","df = spark.sql(f\"SELECT * FROM Marketing_Preparation.{table_name_to_be_validated}\")\n","\n","# (optionally) clean and parse the dataframe, depending on the dataset/ requirements\n","cleaned_df = parse_and_clean_df(df) "],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"1768157d-15cf-4915-b5c8-1d05deae4dd6"},{"cell_type":"markdown","source":["## Validate the table/ Spark dataframe"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e987c538-635e-4fc8-96c4-b9f222036845"},{"cell_type":"code","source":["from datetime import datetime \n","import great_expectations as gx\n","\n","# initialize a GX spark dataframe dataset for validation, passing in your cleaned_df\n","gx_df = gx.dataset.sparkdf_dataset.SparkDFDataset(cleaned_df)\n","\n","# add expectations to the dataset\n","gx_df.expect_column_to_exist('SubscriptionDate')\n","gx_df.expect_column_to_exist('record_creation_date')\n","gx_df.expect_column_values_to_be_between(column='SubscriptionDate', min_value=datetime.strptime('2020-01-01', '%Y-%m-%d'))\n","gx_df.expect_column_values_to_be_between(column='SubscriptionDate', max_value=datetime.now())\n","gx_df.expect_column_values_to_match_regex('Email', regex='^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$')\n","\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"37af9791-714e-498f-863c-1ac3c4999211"},{"cell_type":"markdown","source":["## Run the validator"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"bb88fddf-f0fb-4d40-92d5-c8f60519c590"},{"cell_type":"code","source":["#run validation\n","validation_results = gx_df.validate()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8f8f2666-382f-483f-836f-efc6f1cf224c"},{"cell_type":"markdown","source":["## Handle results\n","\n","This section has deliberately been left blank, because hwo you wish to handle the outcome of your validation results is up to you. \n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"2245b783-da5c-4e5f-a458-63eb795fe6d2"},{"cell_type":"code","source":["from pyspark.sql.functions import lit\n","def write_sparkdf_to_lakehouse_table(spark_df, output_table_name) -> None:\n","    ''' Input: file_path_to_be_validated (str), table_name (str)\n","    Function: Reads data from CSV file path, adds a record_creation_date field and writes to Lakehouse table. \n","    Output: None \n","    '''\n","\n","    time_now = datetime.now() \n","    spark_df.withColumn('validation_passed_date', lit(time_now))\n","    output_table_name\n","    spark_df.write.format(\"delta\").mode(\"overwrite\").save(f'Tables/{output_table_name}')\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"6e896af0-cd44-4f6f-9da1-a90373d2f294"},{"cell_type":"code","source":["def handle_success() -> None:\n","    ''' Function to handle a successful validation run\n","    This could include: \n","    1) moving file to a validation_passed folder path\n","    2) write validation results to a central validation results lakehouse \n","    '''\n","    write_sparkdf_to_lakehouse_table(cleaned_df, output_table_name) \n","     \n","\n","def handle_failure() -> None: \n","    ''' Function to handle a failed validation run\n","    This could include: \n","    1) custom logging\n","    2) write validation results to a central validation results lakehouse \n","    '''\n","    pass\n","    \n","if validation_results.success == True: \n","    handle_success() \n","else: \n","    handle_failure() "],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"029eca78-06e7-4050-96c7-a3c0f54a00e9"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"version_major":2,"version_minor":0,"state":{"ec55d9324b7742b08d0e28f67497f7e7":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"9664fe3546c14327ad41c963a97905cc":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"d769897a7a0349aba81565ac0928ad78":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"f332be92594a4ca8a015706c0aa3f453":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"0f505edee6a04c6d90bd4ba0f101f481":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"95236e7d97934783b1e9226e7ab0e999":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_c23fec7ebd284913b806285656366f38","IPY_MODEL_5484dfae2dc74d249630ae3131849ed8","IPY_MODEL_1329965c39134b46bc36883cac93a2dd"],"layout":"IPY_MODEL_f332be92594a4ca8a015706c0aa3f453"}},"1329965c39134b46bc36883cac93a2dd":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 12/12 [00:00&lt;00:00, 346.64it/s]","layout":"IPY_MODEL_0f505edee6a04c6d90bd4ba0f101f481","style":"IPY_MODEL_9664fe3546c14327ad41c963a97905cc"}},"5484dfae2dc74d249630ae3131849ed8":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":12,"max":12,"bar_style":"success","style":"IPY_MODEL_e6c6e1114b8b431eb43616c5d0971fb1","layout":"IPY_MODEL_d769897a7a0349aba81565ac0928ad78"}},"e6c6e1114b8b431eb43616c5d0971fb1":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"c23fec7ebd284913b806285656366f38":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"Calculating Metrics: 100%","layout":"IPY_MODEL_ec55d9324b7742b08d0e28f67497f7e7","style":"IPY_MODEL_1ad1a0ff38304cd4861b49beb1c6f605"}},"1ad1a0ff38304cd4861b49beb1c6f605":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}}}}},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"trident":{"lakehouse":{"default_lakehouse":"3c20705f-253f-43bc-919c-93c43249d795","default_lakehouse_name":"Marketing_Preparation","default_lakehouse_workspace_id":"df965fe8-d3ab-4be8-95c6-d22af89fb11c"}}},"nbformat":4,"nbformat_minor":5}